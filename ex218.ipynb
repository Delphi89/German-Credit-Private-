{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch Version:  1.1.0\n",
      "Torchvision Version:  0.3.0\n",
      "Using 2 NVIDIA 1080TI GPUs!\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as Data\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from torch.utils import data\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import cProfile, pstats, io\n",
    "from pstats import SortKey\n",
    "from random import randint\n",
    "\n",
    "\n",
    "print(\"PyTorch Version: \",torch.__version__)\n",
    "print(\"Torchvision Version: \",torchvision.__version__)\n",
    "\n",
    "if os.path.exists(\"checkpoint.pt\"):\n",
    "    os.remove(\"checkpoint.pt\")\n",
    "\n",
    "torch.manual_seed(1)   # reproducible\n",
    "\n",
    "OPTIMIZATION_PLUGIN = 'Bayesian' # 'Bayesian' or 'Scikit' or 'GradDescent'\n",
    "#Bayesian requires: $ conda install -c conda-forge bayesian-optimization\n",
    "\n",
    "GET_STATS = False\n",
    "GPU_SELECT = 2 # can be 0, 1, 2 (both)\n",
    "PARALLEL_PROCESSES = 2\n",
    "TRIALS = 50\n",
    "RANDOM_STARTS = 500\n",
    "LR  = 1e-5                    # learning rate\n",
    "SCI_LR =  1e-5\n",
    "LR2 = 1e-5\n",
    "SCI_MM = 0.5                  # momentum - used only with SGD optimizer\n",
    "MM = 0.5\n",
    "L_FIRST = 24                  # initial number of channels\n",
    "KERNEL_X = 24\n",
    "patience = 21                 # if validation loss not going down, wait \"patience\" number of epochs\n",
    "accuracy = 0\n",
    "MaxCredit = -800\n",
    "\n",
    "pr = cProfile.Profile()\n",
    "\n",
    "if GET_STATS:\n",
    "    pr.enable()\n",
    "    \n",
    "\n",
    "if GPU_SELECT == 2:\n",
    "    if torch.cuda.device_count() > 1:\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        print(\"Using\", torch.cuda.device_count(), \"NVIDIA 1080TI GPUs!\")\n",
    "\n",
    "if GPU_SELECT == 1:\n",
    "    device = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")    \n",
    "    print(\"Using one (the second) NVIDIA 1080TI GPU!\")\n",
    "\n",
    "if GPU_SELECT == 0:\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")       \n",
    "    print(\"Using one (the first) NVIDIA 1080TI GPU!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from early_stopping import EarlyStopping\n",
    "from dataset import dataset\n",
    "\n",
    "\n",
    "early_stopping = EarlyStopping(patience=patience, verbose=True)  # initialize the early_stopping object\n",
    "\n",
    "# Counter for the execution time\n",
    "start = torch.cuda.Event(enable_timing=True)\n",
    "end = torch.cuda.Event(enable_timing=True)\n",
    "\n",
    "start.record()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if OPTIMIZATION_PLUGIN == 'Scikit' :\n",
    "    from skopt import gp_minimize\n",
    "    from sklearn.datasets import load_boston\n",
    "    from sklearn.ensemble import GradientBoostingRegressor\n",
    "    from sklearn.model_selection import cross_val_score\n",
    "    from skopt.space import Real, Integer\n",
    "    from skopt.utils import use_named_args\n",
    "    from skopt.plots import plot_convergence\n",
    "    from functools import partial\n",
    "    from skopt.plots import plot_evaluations\n",
    "    from skopt import gp_minimize, forest_minimize, dummy_minimize, gbrt_minimize\n",
    "    from skopt.plots import plot_objective\n",
    "    from sklearn.preprocessing import LabelEncoder\n",
    "    from sklearn.preprocessing import CategoricalEncoder\n",
    "    from skopt.space import Real, Categorical, Integer\n",
    "    from sklearn.externals.joblib import Parallel, delayed\n",
    "\n",
    "    #SCI_LR = Categorical(categories=[1e-1, 3e-1, 5e-1, 7e-1, 1e-2, 3e-2, 5e-2, 7e-2, 1e-3, 3e-3, 5e-3, 7e-3, 1e-4, 3e-4, 0.1, 0.2, 0.3, 0.01, 0.02, 0.03, 0.04, 0.05, 0.06, 0.07, 0.08, 0.09, 0.001, 0.0001, 1e-5],name= 'SCI_LR')\n",
    "    SCI_LR = Categorical(categories=[1e-1, 3e-1, 5e-1, 7e-1, 1e-2, 3e-2, 5e-2, 7e-2, 0.1, 0.2, 0.3, 0.01, 0.02, 0.03, 0.04, 0.05, 0.06, 0.07, 0.08, 0.09, 0.001],name= 'SCI_LR')\n",
    "    SCI_MM = Categorical(categories=[0.001, 0.01, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 0.99, 0.999], name='SCI_MM')\n",
    "    SCI_REGULARIZATION = Categorical(categories=[0.0001, 0.0003, 0.0007, 0.001, 0.003, 0.007, 0.01, 0.03, 0.07, 0.1, 0.3, 0.7], name='SCI_REGULARIZATION')\n",
    "    SCI_EPOCHS = Categorical(categories=[2000, 1000], name='SCI_EPOCHS')\n",
    "    SCI_optimizer = Categorical(categories=['Adam', 'Adadelta', 'SGD', 'Adagrad', 'AMSGrad', 'AdamW'],name='SCI_optimizer') #\n",
    "    SCI_loss_type = Categorical(categories=['CrossEntropyLoss', 'MultiMarginLoss','NLLLoss'],name='SCI_loss_type') # \n",
    "    SCI_BATCH_SIZE = Categorical(categories=[4, 8, 12, 16, 24, 32, 48, 64, 96, 128, 160, 192, 224, 256], name='SCI_BATCH_SIZE')\n",
    "    SCI_DROPOUT = Categorical(categories=[0, 0.01, 0.03, 0.07, 0.1, 0.13, 0.17, 0.2, 0.23, 0.27, 0.3, 0.33, 0.37, 0.4] , name = 'SCI_DROPOUT')\n",
    "    SCI_RELU = Categorical(categories=['True', 'False'] , name = 'SCI_RELU')\n",
    "    SCI_BIAS = Categorical(categories=['True', 'False'] , name = 'SCI_BIAS')\n",
    "    SCI_L_SECOND = Categorical(categories=[2, 4, 6, 8, 12, 16, 20, 24, 32, 48, 64], name='SCI_L_SECOND')\n",
    "    SCI_BN_MOMENTUM = Categorical(categories=[0, 0.01, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 0.99] , name = 'SCI_BN_MOMENTUM') \n",
    "    SCI_SGD_MOMENTUM = Categorical(categories=[0, 0.01, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 0.99] , name = 'SCI_SGD_MOMENTUM') \n",
    "\n",
    "    dimensions = [SCI_BATCH_SIZE, SCI_MM, SCI_REGULARIZATION, SCI_optimizer, SCI_LR, SCI_loss_type, SCI_DROPOUT, SCI_RELU, SCI_BIAS, SCI_L_SECOND, SCI_EPOCHS, SCI_BN_MOMENTUM, SCI_SGD_MOMENTUM]\n",
    "\n",
    "    @use_named_args(dimensions = dimensions)\n",
    "\n",
    "    def objective(SCI_BATCH_SIZE, SCI_MM, SCI_REGULARIZATION, SCI_optimizer, SCI_LR, SCI_loss_type, SCI_DROPOUT, SCI_RELU, SCI_BIAS, SCI_L_SECOND, SCI_EPOCHS, SCI_BN_MOMENTUM, SCI_SGD_MOMENTUM):\n",
    "        global device  \n",
    "\n",
    "        loss_func = nn.CrossEntropyLoss()\n",
    "\n",
    "        def create_loss(LOSS):   \n",
    "            if LOSS == 'CrossEntropyLoss':\n",
    "                loss_func = nn.CrossEntropyLoss()\n",
    "            if LOSS == 'NLLLoss':\n",
    "                loss_func = nn.NLLLoss()\n",
    "            else:\n",
    "                loss_func = nn.MultiMarginLoss()\n",
    "            return loss_func\n",
    "\n",
    "        MM = float(str(SCI_MM))\n",
    "        REGULARIZATION = float(str(SCI_REGULARIZATION))\n",
    "        optimizer = str(SCI_optimizer)\n",
    "        LR = float(str(SCI_LR))\n",
    "        train_losses = []         # to track the training loss as the model trains\n",
    "        output = 0\n",
    "        loss = 0\n",
    "        accuracy = 0\n",
    "        early_stopping.counter = 0\n",
    "        early_stopping.best_score = None\n",
    "        early_stopping.early_stop = False\n",
    "        early_stopping.verbose = False  \n",
    "        TEST_RESULTS = torch.zeros(1,2)\n",
    "\n",
    "    \n",
    "        loss_type = create_loss(SCI_loss_type)\n",
    "        \n",
    "        \n",
    "        \n",
    "        from cnn_model import CNN6      \n",
    "        cnn = CNN6(L_FIRST, SCI_L_SECOND, KERNEL_X, SCI_BIAS, SCI_BN_MOMENTUM, SCI_RELU, SCI_DROPOUT, dataset.CLASSES)     \n",
    "    \n",
    "        if GPU_SELECT == 2:\n",
    "            if torch.cuda.device_count() > 1:\n",
    "                cnn = nn.DataParallel(cnn,device_ids=[0, 1], dim=0) \n",
    "            cnn = cnn.cuda()\n",
    "        if GPU_SELECT == 1:\n",
    "            cnn.to(device)  \n",
    "        if GPU_SELECT == 0:\n",
    "            cnn.to(device)        \n",
    "\n",
    "        cnn.apply(CNN6.weights_reset)\n",
    "        cnn.share_memory()\n",
    "     \n",
    "\n",
    "        \n",
    "        from adamw import AdamW\n",
    "        \n",
    "        \n",
    "        if SCI_optimizer == 'Adam':\n",
    "            optimizer = optim.Adam(cnn.parameters(), lr=LR, betas=(0.9, 0.99), weight_decay=REGULARIZATION)\n",
    "        if SCI_optimizer == 'AMSGrad':\n",
    "            optimizer = optim.Adam(cnn.parameters(), lr=LR, betas=(0.9, 0.99), weight_decay=REGULARIZATION, amsgrad=True)\n",
    "        if SCI_optimizer == 'AdamW':\n",
    "            optimizer = AdamW(cnn.parameters(), lr=LR, betas=(0.9, 0.99), weight_decay = REGULARIZATION)            \n",
    "        if SCI_optimizer == 'SGD':\n",
    "            optimizer = optim.SGD(cnn.parameters(), lr=LR, momentum=SCI_SGD_MOMENTUM, weight_decay=REGULARIZATION)\n",
    "        if SCI_optimizer == 'Adadelta':\n",
    "            optimizer = optim.Adadelta(cnn.parameters(), lr=LR, weight_decay=REGULARIZATION)\n",
    "        if SCI_optimizer == 'Adagrad':\n",
    "            optimizer = optim.Adagrad(cnn.parameters(), lr=LR, weight_decay=REGULARIZATION)\n",
    "    \n",
    "        from Utillities import Utillities\n",
    "        Utillities.listing(optimizer, SCI_SGD_MOMENTUM, SCI_BN_MOMENTUM, SCI_L_SECOND, SCI_LR, SCI_RELU, SCI_BIAS, SCI_loss_type, REGULARIZATION, SCI_BATCH_SIZE, SCI_DROPOUT, SCI_LINEARITY)\n",
    "    \n",
    "        #SCI_BATCH_SIZE = 1\n",
    "        # Data Loader for easy mini-batch return in training\n",
    "        SCI_BATCH_SIZE = int(SCI_BATCH_SIZE)\n",
    "        train_loader = Data.DataLoader(dataset = dataset.train_dataset, batch_size = SCI_BATCH_SIZE, shuffle = False, num_workers = 0, drop_last=True, pin_memory=True)\n",
    "        validation_loader = Data.DataLoader(dataset = dataset.validation_dataset, batch_size = SCI_BATCH_SIZE, shuffle = False, num_workers = 0, drop_last=True, pin_memory=True)    \n",
    "        test_loader = Data.DataLoader(dataset = dataset.test_dataset, batch_size = SCI_BATCH_SIZE, shuffle = False, num_workers = 0, pin_memory=True)\n",
    "    \n",
    "        for epoch in range(SCI_EPOCHS):\n",
    "            loss = None        \n",
    "            cnn.train().cuda()\n",
    "            for step, (train_data, train_target) in enumerate(train_loader):   \n",
    "                train_data, train_target = train_data.to(device), train_target.to(device)\n",
    "                output, temp = cnn(train_data)                # forward pass: compute predicted outputs by passing inputs to the model     \n",
    "                loss = loss_func(output, train_target)\n",
    "                train_losses.append(loss.item())              # record training loss \n",
    "                loss.backward()                               # backward pass: compute gradient of the loss with respect to model parameters\n",
    "                optimizer.zero_grad()\n",
    "                optimizer.step()                              # perform a single optimization step (parameter update)\n",
    "      \n",
    "            cnn.eval().cuda()                 # switch to evaluation (no change) mode           \n",
    "            valid_loss = 0\n",
    "            accuracy = 0\n",
    "            with torch.no_grad():\n",
    "                for step, (validation_data, validation_target) in enumerate(validation_loader):\n",
    "                    validation_data, validation_target = validation_data.to(device), validation_target.to(device)\n",
    "                    output, temp = cnn(validation_data)            # forward pass: compute predicted outputs by passing inputs to the model\n",
    "                    valid_loss += loss_func(output, validation_target).item()\n",
    "                    ps = torch.exp(output)\n",
    "                    equality = (validation_target[0].data == ps.max(dim=1)[1])\n",
    "                    accuracy += equality.type(torch.FloatTensor).mean()      \n",
    "               \n",
    "            train_losses = []\n",
    "            early_stopping(valid_loss, cnn)\n",
    "       \n",
    "            if early_stopping.early_stop:\n",
    "                if os.path.exists('checkpoint.pt'):\n",
    "                    print(\"Loaded the model with the lowest Validation Loss!\")\n",
    "                    #nn.load_state_dict(torch.load('checkpoint.pt', map_location=\"cuda:1\"))  # Choose whatever GPU device number you want\n",
    "                    cnn.load_state_dict(torch.load('checkpoint.pt', map_location=\"cuda:1\"))  # Choose whatever GPU device number you want\n",
    "                    cnn.to(device)\n",
    "                break\n",
    "      \n",
    "        cnn.eval()\n",
    "        class_correct = list(0. for i in range(1000))\n",
    "        class_total = list(0. for i in range(1000))\n",
    "        with torch.no_grad():\n",
    "            for (test_data, test_target) in test_loader:\n",
    "                test_data, test_target = test_data.to(device), test_target.to(device)\n",
    "                outputs, temp = cnn(test_data)\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                c = (predicted == test_target).squeeze()\n",
    "                for i in range(test_target.size(0)):\n",
    "                    label = test_target[i]\n",
    "                    class_correct[label] += c[i].item()\n",
    "                    class_total[label] += 1\n",
    "\n",
    "        for i in range(dataset.CLASSES):\n",
    "            TEST_RESULTS[0,i] = class_correct[i] / dataset.TESTED_ELEMENTS[i]\n",
    "            print('Class: ',i,' accuracy: ', TEST_RESULTS[0,i])\n",
    "            print('Class: ',i,' correct: ', class_correct[i])\n",
    "        percent = (TEST_RESULTS[0,0]+TEST_RESULTS[0,1])/2\n",
    "        print('Final percentage: ',percent)\n",
    "    \n",
    "        CreditCost = int((1 - TEST_RESULTS[0,0]) * dataset.TESTED_ELEMENTS[0] + (1 - TEST_RESULTS[0,1]) * dataset.TESTED_ELEMENTS[1] * 5)\n",
    "    \n",
    "        if TEST_RESULTS[0,0] == 0 or TEST_RESULTS[0,1] == 0 :\n",
    "            CreditCost = CreditCost + 300\n",
    "    \n",
    "        print('Last epoch: ', epoch)\n",
    "        print('Credit Cost: ',CreditCost)\n",
    "    \n",
    "        if os.path.exists('checkpoint.pt'):  \n",
    "            os.remove('checkpoint.pt') \n",
    "\n",
    "        print()\n",
    "        torch.cuda.empty_cache()\n",
    "        print()\n",
    "        \n",
    "        return CreditCost\n",
    "    \n",
    "    #   not working    #res_gp = gp_minimize(objective, dimensions=dimensions, n_calls=TRIALS, random_state=1, verbose=True, acq_func='gp_hedge', acq_optimizer='auto', n_jobs=1)\n",
    "    #res_gp = forest_minimize(objective, dimensions=dimensions, base_estimator='RF', n_calls=TRIALS, n_random_starts=RANDOM_STARTS, acq_func='EI', x0=None, y0=None, random_state=None, verbose=True, callback=None, n_points=10000, xi=0.01, kappa=1.96, n_jobs=128)\n",
    "    res_gp = gbrt_minimize(objective, dimensions=dimensions, base_estimator='ET', n_calls=TRIALS+RANDOM_STARTS, n_random_starts=RANDOM_STARTS, acq_func='LCB', x0=None, y0=None, random_state=None, verbose=True, callback=None, n_points=100, xi=0.01, kappa=1.96, n_jobs=1)\n",
    "    #res_gp = dummy_minimize(objective, dimensions=dimensions, n_calls=TRIALS, x0=None, y0=None, random_state=None, verbose=True, callback=None)      \n",
    "\n",
    "    \"Best score=%.4f\" % res_gp.fun\n",
    "    print(\"\"\"Best parameters: - optimization=%d\"\"\" % (res_gp.x[0]))\n",
    "  \n",
    "    print(res_gp)\n",
    "    plot_convergence(res_gp)\n",
    "    #plot_evaluations(res_gp)\n",
    "    #plot_objective(res_gp)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   | SCI_BA... | SCI_BIAS  | SCI_BN... | SCI_DR... | SCI_EP... | SCI_LI... |  SCI_LR   | SCI_L_... |  SCI_MM   | SCI_RE... | SCI_RELU  | SCI_SG... | SCI_lo... | SCI_op... |\n",
      "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Optimization:  Adagrad (\n",
      "Parameter Group 0\n",
      "    initial_accumulator_value: 0\n",
      "    lr: 0.08264\n",
      "    lr_decay: 0\n",
      "    weight_decay: 0.377\n",
      ")\n",
      "Batch Normalization Momentum:  0.0\n",
      "Nodes:  12\n",
      "LR:  0.08264\n",
      "RELU:  True\n",
      "BIAS:  False\n",
      "Loss Type:  1\n",
      "REGULARIZATION:  0.377\n",
      "BATCH_SIZE:  55\n",
      "Dropout:  0.09\n",
      "Final Linear Layers:  1\n",
      "valid_loss:  0.6929689049720764\n",
      "average loss: 0.692969\n",
      "valid_loss:  0.6931432485580444\n",
      "valid_loss:  0.6931471824645996\n",
      "valid_loss:  0.6931474208831787\n",
      "valid_loss:  0.6931474208831787\n",
      "valid_loss:  0.6931474208831787\n",
      "valid_loss:  0.6931474208831787\n",
      "valid_loss:  0.6931474208831787\n",
      "valid_loss:  0.6931474208831787\n",
      "valid_loss:  0.6931474208831787\n",
      "valid_loss:  0.6931474208831787\n",
      "valid_loss:  0.6931474208831787\n",
      "valid_loss:  0.6931474208831787\n",
      "valid_loss:  0.6931474208831787\n",
      "valid_loss:  0.6931474208831787\n",
      "valid_loss:  0.6931474208831787\n",
      "valid_loss:  0.6931474208831787\n",
      "valid_loss:  0.6931474208831787\n",
      "valid_loss:  0.6931474208831787\n",
      "valid_loss:  0.6931474208831787\n",
      "valid_loss:  0.6931474208831787\n",
      "valid_loss:  0.6931474208831787\n",
      "Class:  0  accuracy:  tensor(1.)\n",
      "Class:  0  correct:  499.0  of  tensor(499.)\n",
      "Class:  1  accuracy:  tensor(0.)\n",
      "Class:  1  correct:  0.0  of  tensor(100.)\n",
      "Final percentage:  tensor(0.5000)\n",
      "Last epoch:  21\n",
      "Credit Cost:  -800\n",
      "\n",
      "\n",
      "Best Score So Far:  -800\n",
      "| \u001b[0m 1       \u001b[0m | \u001b[0m-800.0   \u001b[0m | \u001b[0m 55.71   \u001b[0m | \u001b[0m 2.433   \u001b[0m | \u001b[0m 0.000113\u001b[0m | \u001b[0m 0.0907  \u001b[0m | \u001b[0m 1.147e+0\u001b[0m | \u001b[0m 1.276   \u001b[0m | \u001b[0m 0.08264 \u001b[0m | \u001b[0m 12.37   \u001b[0m | \u001b[0m 0.397   \u001b[0m | \u001b[0m 0.3772  \u001b[0m | \u001b[0m 1.834   \u001b[0m | \u001b[0m 0.6784  \u001b[0m | \u001b[0m 1.611   \u001b[0m | \u001b[0m 6.26    \u001b[0m |\n",
      "Optimization:  Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.99)\n",
      "    eps: 1e-08\n",
      "    lr: 0.32229\n",
      "    weight_decay: 0.485\n",
      ")\n",
      "Batch Normalization Momentum:  0.41\n",
      "Nodes:  31\n",
      "LR:  0.32229\n",
      "RELU:  False\n",
      "BIAS:  False\n",
      "Loss Type:  1\n",
      "REGULARIZATION:  0.485\n",
      "BATCH_SIZE:  7\n",
      "Dropout:  0.17\n",
      "Final Linear Layers:  1\n",
      "valid_loss:  0.6925366520881653\n",
      "average loss: 0.692537\n",
      "valid_loss:  0.6931467652320862\n",
      "valid_loss:  0.6931474208831787\n",
      "valid_loss:  0.6931474208831787\n",
      "valid_loss:  0.6931474208831787\n",
      "valid_loss:  0.6931474208831787\n",
      "valid_loss:  0.6931474208831787\n",
      "valid_loss:  0.6931474208831787\n",
      "valid_loss:  0.6931474208831787\n",
      "valid_loss:  0.6931307315826416\n",
      "valid_loss:  0.6931456327438354\n",
      "valid_loss:  0.6931473612785339\n",
      "valid_loss:  0.6931442022323608\n",
      "valid_loss:  0.6931474208831787\n",
      "valid_loss:  0.6931449770927429\n",
      "valid_loss:  0.6931418776512146\n",
      "valid_loss:  0.6931498050689697\n",
      "valid_loss:  0.6931169629096985\n",
      "valid_loss:  0.6931555271148682\n",
      "valid_loss:  0.6931549906730652\n",
      "valid_loss:  0.6931483745574951\n",
      "valid_loss:  0.6931508779525757\n",
      "Class:  0  accuracy:  tensor(0.4629)\n",
      "Class:  0  correct:  231.0  of  tensor(499.)\n",
      "Class:  1  accuracy:  tensor(0.4900)\n",
      "Class:  1  correct:  49.0  of  tensor(100.)\n",
      "Final percentage:  tensor(0.4765)\n",
      "Last epoch:  21\n",
      "Credit Cost:  -523\n",
      "\n",
      "\n",
      "Best Score So Far:  -523\n",
      "| \u001b[95m 2       \u001b[0m | \u001b[95m-523.0   \u001b[0m | \u001b[95m 7.396   \u001b[0m | \u001b[95m 2.334   \u001b[0m | \u001b[95m 0.4131  \u001b[0m | \u001b[95m 0.1676  \u001b[0m | \u001b[95m 1.14e+03\u001b[0m | \u001b[95m 1.592   \u001b[0m | \u001b[95m 0.3223  \u001b[0m | \u001b[95m 31.05   \u001b[0m | \u001b[95m 0.3138  \u001b[0m | \u001b[95m 0.4847  \u001b[0m | \u001b[95m 2.744   \u001b[0m | \u001b[95m 0.8857  \u001b[0m | \u001b[95m 1.254   \u001b[0m | \u001b[95m 1.234   \u001b[0m |\n",
      "Optimization:  Adadelta (\n",
      "Parameter Group 0\n",
      "    eps: 1e-06\n",
      "    lr: 0.27983\n",
      "    rho: 0.9\n",
      "    weight_decay: 0.584\n",
      ")\n",
      "Batch Normalization Momentum:  0.1\n",
      "Nodes:  11\n",
      "LR:  0.27983\n",
      "RELU:  True\n",
      "BIAS:  False\n",
      "Loss Type:  3\n",
      "REGULARIZATION:  0.584\n",
      "BATCH_SIZE:  25\n",
      "Dropout:  0.13\n",
      "Final Linear Layers:  2\n",
      "valid_loss:  0.6999166011810303\n",
      "average loss: 0.699917\n",
      "valid_loss:  0.697110652923584\n",
      "valid_loss:  0.6991409063339233\n",
      "valid_loss:  0.7002363801002502\n",
      "valid_loss:  0.6999586820602417\n",
      "valid_loss:  0.6984359622001648\n",
      "valid_loss:  0.698154091835022\n",
      "valid_loss:  0.697733998298645\n",
      "valid_loss:  0.6964089870452881\n",
      "valid_loss:  0.694814920425415\n",
      "valid_loss:  0.6933615207672119\n",
      "valid_loss:  0.6925797462463379\n",
      "valid_loss:  0.6934002041816711\n",
      "valid_loss:  0.6943367123603821\n",
      "valid_loss:  0.6928589344024658\n",
      "valid_loss:  0.6920561790466309\n",
      "valid_loss:  0.6940817832946777\n",
      "valid_loss:  0.6939594745635986\n",
      "valid_loss:  0.6946712732315063\n",
      "valid_loss:  0.6946775913238525\n",
      "valid_loss:  0.6952154636383057\n",
      "valid_loss:  0.6956944465637207\n",
      "valid_loss:  0.6960071921348572\n",
      "valid_loss:  0.695663332939148\n",
      "valid_loss:  0.6952231526374817\n",
      "valid_loss:  0.6942570805549622\n",
      "valid_loss:  0.6934106349945068\n",
      "valid_loss:  0.6931694149971008\n",
      "valid_loss:  0.6931517720222473\n",
      "valid_loss:  0.6931479573249817\n",
      "valid_loss:  0.6931473612785339\n",
      "valid_loss:  0.6931473612785339\n",
      "valid_loss:  0.6931473612785339\n",
      "valid_loss:  0.6931474208831787\n",
      "valid_loss:  0.6931474208831787\n",
      "valid_loss:  0.6931474208831787\n",
      "valid_loss:  0.6931474208831787\n",
      "Loaded the model with the lowest Validation Loss!\n",
      "Class:  0  accuracy:  tensor(0.7335)\n",
      "Class:  0  correct:  366.0  of  tensor(499.)\n",
      "Class:  1  accuracy:  tensor(0.2600)\n",
      "Class:  1  correct:  26.0  of  tensor(100.)\n",
      "Final percentage:  tensor(0.4967)\n",
      "Last epoch:  36\n",
      "Credit Cost:  -503\n",
      "\n",
      "\n",
      "Best Score So Far:  -503\n",
      "| \u001b[95m 3       \u001b[0m | \u001b[95m-503.0   \u001b[0m | \u001b[95m 25.06   \u001b[0m | \u001b[95m 2.748   \u001b[0m | \u001b[95m 0.09736 \u001b[0m | \u001b[95m 0.1263  \u001b[0m | \u001b[95m 1.958e+0\u001b[0m | \u001b[95m 2.594   \u001b[0m | \u001b[95m 0.2798  \u001b[0m | \u001b[95m 11.47   \u001b[0m | \u001b[95m 0.6861  \u001b[0m | \u001b[95m 0.5843  \u001b[0m | \u001b[95m 1.036   \u001b[0m | \u001b[95m 0.7426  \u001b[0m | \u001b[95m 3.957   \u001b[0m | \u001b[95m 5.482   \u001b[0m |\n",
      "Optimization:  Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.99)\n",
      "    eps: 1e-08\n",
      "    lr: 0.12223\n",
      "    weight_decay: 0.475\n",
      ")\n",
      "Batch Normalization Momentum:  0.1\n",
      "Nodes:  5\n",
      "LR:  0.12223\n",
      "RELU:  True\n",
      "BIAS:  False\n",
      "Loss Type:  2\n",
      "REGULARIZATION:  0.475\n",
      "BATCH_SIZE:  38\n",
      "Dropout:  0.13\n",
      "Final Linear Layers:  1\n",
      "valid_loss:  0.6930168867111206\n",
      "average loss: 0.693017\n",
      "valid_loss:  0.6931989789009094\n",
      "valid_loss:  0.6931041479110718\n",
      "valid_loss:  0.6931445002555847\n",
      "valid_loss:  0.6931421756744385\n",
      "valid_loss:  0.6931531429290771\n",
      "valid_loss:  0.6931480169296265\n",
      "valid_loss:  0.6931467652320862\n",
      "valid_loss:  0.6931470036506653\n",
      "valid_loss:  0.6931473612785339\n",
      "valid_loss:  0.6931472420692444\n",
      "valid_loss:  0.6931474208831787\n",
      "valid_loss:  0.6931474208831787\n",
      "valid_loss:  0.6931474208831787\n",
      "valid_loss:  0.6931474208831787\n",
      "valid_loss:  0.6931474208831787\n",
      "valid_loss:  0.6931474208831787\n",
      "valid_loss:  0.6931474208831787\n",
      "valid_loss:  0.6931474208831787\n",
      "valid_loss:  0.6931474208831787\n",
      "valid_loss:  0.6931474208831787\n",
      "valid_loss:  0.6931474208831787\n",
      "Class:  0  accuracy:  tensor(1.)\n",
      "Class:  0  correct:  499.0  of  tensor(499.)\n",
      "Class:  1  accuracy:  tensor(0.)\n",
      "Class:  1  correct:  0.0  of  tensor(100.)\n",
      "Final percentage:  tensor(0.5000)\n",
      "Last epoch:  21\n",
      "Credit Cost:  -800\n",
      "\n",
      "\n",
      "Best Score So Far:  -503\n",
      "| \u001b[0m 4       \u001b[0m | \u001b[0m-800.0   \u001b[0m | \u001b[0m 38.78   \u001b[0m | \u001b[0m 2.571   \u001b[0m | \u001b[0m 0.1022  \u001b[0m | \u001b[0m 0.1344  \u001b[0m | \u001b[0m 1.909e+0\u001b[0m | \u001b[0m 1.878   \u001b[0m | \u001b[0m 0.1222  \u001b[0m | \u001b[0m 5.901   \u001b[0m | \u001b[0m 0.02033 \u001b[0m | \u001b[0m 0.4752  \u001b[0m | \u001b[0m 1.421   \u001b[0m | \u001b[0m 0.2629  \u001b[0m | \u001b[0m 2.47    \u001b[0m | \u001b[0m 1.32    \u001b[0m |\n",
      "Optimization:  SGD (\n",
      "Parameter Group 0\n",
      "    dampening: 0\n",
      "    lr: 0.28082\n",
      "    momentum: 0.51\n",
      "    nesterov: False\n",
      "    weight_decay: 0.375\n",
      ")\n",
      "Batch Normalization Momentum:  0.58\n",
      "Nodes:  14\n",
      "LR:  0.28082\n",
      "RELU:  False\n",
      "BIAS:  True\n",
      "Loss Type:  3\n",
      "REGULARIZATION:  0.375\n",
      "BATCH_SIZE:  75\n",
      "Dropout:  0.21\n",
      "Final Linear Layers:  2\n",
      "valid_loss:  0.6909441351890564\n",
      "average loss: 0.690944\n",
      "valid_loss:  0.693195104598999\n",
      "valid_loss:  0.6931498050689697\n",
      "valid_loss:  0.6931474208831787\n",
      "valid_loss:  0.6931474208831787\n",
      "valid_loss:  0.6931474208831787\n",
      "valid_loss:  0.6931474208831787\n",
      "valid_loss:  0.6931474208831787\n",
      "valid_loss:  0.6931474208831787\n",
      "valid_loss:  0.6931474208831787\n",
      "valid_loss:  0.6931474208831787\n",
      "valid_loss:  0.6931474208831787\n",
      "valid_loss:  0.6931474208831787\n",
      "valid_loss:  0.6931474208831787\n",
      "valid_loss:  0.6931474208831787\n",
      "valid_loss:  0.6931474208831787\n",
      "valid_loss:  0.6931474208831787\n",
      "valid_loss:  0.6931474208831787\n",
      "valid_loss:  0.6931474208831787\n",
      "valid_loss:  0.6931474208831787\n",
      "valid_loss:  0.6931474208831787\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid_loss:  0.6931474208831787\n",
      "Class:  0  accuracy:  tensor(1.)\n",
      "Class:  0  correct:  499.0  of  tensor(499.)\n",
      "Class:  1  accuracy:  tensor(0.)\n",
      "Class:  1  correct:  0.0  of  tensor(100.)\n",
      "Final percentage:  tensor(0.5000)\n",
      "Last epoch:  21\n",
      "Credit Cost:  -800\n",
      "\n",
      "\n",
      "Best Score So Far:  -503\n",
      "| \u001b[0m 5       \u001b[0m | \u001b[0m-800.0   \u001b[0m | \u001b[0m 75.19   \u001b[0m | \u001b[0m 1.292   \u001b[0m | \u001b[0m 0.5834  \u001b[0m | \u001b[0m 0.2099  \u001b[0m | \u001b[0m 1.102e+0\u001b[0m | \u001b[0m 2.238   \u001b[0m | \u001b[0m 0.2808  \u001b[0m | \u001b[0m 14.43   \u001b[0m | \u001b[0m 0.05085 \u001b[0m | \u001b[0m 0.3752  \u001b[0m | \u001b[0m 2.321   \u001b[0m | \u001b[0m 0.5097  \u001b[0m | \u001b[0m 3.824   \u001b[0m | \u001b[0m 4.513   \u001b[0m |\n",
      "Optimization:  AdamW (\n",
      "Parameter Group 0\n",
      "    betas: (0.9, 0.99)\n",
      "    eps: 1e-08\n",
      "    lr: 0.37173\n",
      "    weight_decay: 0.508\n",
      ")\n",
      "Batch Normalization Momentum:  0.14\n",
      "Nodes:  12\n",
      "LR:  0.37173\n",
      "RELU:  False\n",
      "BIAS:  True\n",
      "Loss Type:  3\n",
      "REGULARIZATION:  0.508\n",
      "BATCH_SIZE:  116\n",
      "Dropout:  0.24\n",
      "Final Linear Layers:  1\n",
      "valid_loss:  0.6868631839752197\n",
      "average loss: 0.686863\n",
      "valid_loss:  0.6916953921318054\n",
      "valid_loss:  0.6928483247756958\n",
      "valid_loss:  0.6930755376815796\n",
      "valid_loss:  0.6931338906288147\n",
      "valid_loss:  0.6931442618370056\n",
      "valid_loss:  0.6931465864181519\n",
      "valid_loss:  0.6931471824645996\n",
      "valid_loss:  0.6931473612785339\n",
      "valid_loss:  0.6931473612785339\n",
      "valid_loss:  0.6931474208831787\n",
      "valid_loss:  0.6931474208831787\n",
      "valid_loss:  0.6931474208831787\n",
      "valid_loss:  0.6931474208831787\n",
      "valid_loss:  0.6931474208831787\n",
      "valid_loss:  0.6931474208831787\n",
      "valid_loss:  0.6931474208831787\n",
      "valid_loss:  0.6931474208831787\n",
      "valid_loss:  0.6931474208831787\n",
      "valid_loss:  0.6931474208831787\n",
      "valid_loss:  0.6931474208831787\n",
      "valid_loss:  0.6931474208831787\n",
      "Class:  0  accuracy:  tensor(1.)\n",
      "Class:  0  correct:  499.0  of  tensor(499.)\n",
      "Class:  1  accuracy:  tensor(0.)\n",
      "Class:  1  correct:  0.0  of  tensor(100.)\n",
      "Final percentage:  tensor(0.5000)\n",
      "Last epoch:  21\n",
      "Credit Cost:  -800\n",
      "\n",
      "\n",
      "Best Score So Far:  -503\n",
      "| \u001b[0m 6       \u001b[0m | \u001b[0m-800.0   \u001b[0m | \u001b[0m 116.0   \u001b[0m | \u001b[0m 1.274   \u001b[0m | \u001b[0m 0.1379  \u001b[0m | \u001b[0m 0.2422  \u001b[0m | \u001b[0m 1.398e+0\u001b[0m | \u001b[0m 1.494   \u001b[0m | \u001b[0m 0.3717  \u001b[0m | \u001b[0m 12.43   \u001b[0m | \u001b[0m 0.7503  \u001b[0m | \u001b[0m 0.5082  \u001b[0m | \u001b[0m 2.758   \u001b[0m | \u001b[0m 0.6174  \u001b[0m | \u001b[0m 3.245   \u001b[0m | \u001b[0m 3.09    \u001b[0m |\n",
      "Optimization:  SGD (\n",
      "Parameter Group 0\n",
      "    dampening: 0\n",
      "    lr: 0.05475\n",
      "    momentum: 0.23\n",
      "    nesterov: False\n",
      "    weight_decay: 0.405\n",
      ")\n",
      "Batch Normalization Momentum:  0.42\n",
      "Nodes:  30\n",
      "LR:  0.05475\n",
      "RELU:  True\n",
      "BIAS:  False\n",
      "Loss Type:  3\n",
      "REGULARIZATION:  0.405\n",
      "BATCH_SIZE:  37\n",
      "Dropout:  0.29\n",
      "Final Linear Layers:  2\n",
      "valid_loss:  0.679300844669342\n",
      "average loss: 0.679301\n",
      "valid_loss:  0.6888383030891418\n",
      "valid_loss:  0.6835177540779114\n",
      "valid_loss:  0.6849504113197327\n",
      "valid_loss:  0.6922730207443237\n",
      "valid_loss:  0.6926926374435425\n",
      "valid_loss:  0.692760169506073\n",
      "valid_loss:  0.6922895908355713\n",
      "valid_loss:  0.6923801898956299\n",
      "valid_loss:  0.6927081346511841\n",
      "valid_loss:  0.69295334815979\n",
      "valid_loss:  0.6929702758789062\n",
      "valid_loss:  0.692993700504303\n",
      "valid_loss:  0.6931328773498535\n",
      "valid_loss:  0.6931336522102356\n",
      "valid_loss:  0.6931334733963013\n",
      "valid_loss:  0.6931408047676086\n",
      "valid_loss:  0.6931424140930176\n",
      "valid_loss:  0.6931450366973877\n",
      "valid_loss:  0.6931458711624146\n",
      "valid_loss:  0.6931465268135071\n",
      "valid_loss:  0.6931465268135071\n",
      "Class:  0  accuracy:  tensor(0.5872)\n",
      "Class:  0  correct:  293.0  of  tensor(499.)\n",
      "Class:  1  accuracy:  tensor(0.5400)\n",
      "Class:  1  correct:  54.0  of  tensor(100.)\n",
      "Final percentage:  tensor(0.5636)\n",
      "Last epoch:  21\n",
      "Credit Cost:  -436\n",
      "\n",
      "\n",
      "Best Score So Far:  -436\n",
      "| \u001b[95m 7       \u001b[0m | \u001b[95m-436.0   \u001b[0m | \u001b[95m 37.47   \u001b[0m | \u001b[95m 2.783   \u001b[0m | \u001b[95m 0.4238  \u001b[0m | \u001b[95m 0.2895  \u001b[0m | \u001b[95m 1.663e+0\u001b[0m | \u001b[95m 2.859   \u001b[0m | \u001b[95m 0.05475 \u001b[0m | \u001b[95m 30.48   \u001b[0m | \u001b[95m 0.45    \u001b[0m | \u001b[95m 0.4049  \u001b[0m | \u001b[95m 1.812   \u001b[0m | \u001b[95m 0.2347  \u001b[0m | \u001b[95m 3.701   \u001b[0m | \u001b[95m 4.436   \u001b[0m |\n",
      "Optimization:  Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.99)\n",
      "    eps: 1e-08\n",
      "    lr: 0.36433\n",
      "    weight_decay: 0.651\n",
      ")\n",
      "Batch Normalization Momentum:  0.32\n",
      "Nodes:  20\n",
      "LR:  0.36433\n",
      "RELU:  False\n",
      "BIAS:  False\n",
      "Loss Type:  1\n",
      "REGULARIZATION:  0.651\n",
      "BATCH_SIZE:  4\n",
      "Dropout:  0.16\n",
      "Final Linear Layers:  2\n",
      "valid_loss:  0.6931461095809937\n",
      "average loss: 0.693146\n",
      "valid_loss:  0.6931474208831787\n",
      "valid_loss:  0.6931474208831787\n",
      "valid_loss:  0.6931474208831787\n",
      "valid_loss:  0.6931474208831787\n",
      "valid_loss:  0.6931474208831787\n",
      "valid_loss:  0.6931484937667847\n",
      "valid_loss:  0.6931463479995728\n",
      "valid_loss:  0.6931466460227966\n",
      "valid_loss:  0.6931407451629639\n",
      "valid_loss:  0.6931411027908325\n",
      "valid_loss:  0.6931478381156921\n",
      "valid_loss:  0.6931517124176025\n",
      "valid_loss:  0.69315505027771\n",
      "valid_loss:  0.6931473016738892\n",
      "valid_loss:  0.6931613087654114\n",
      "valid_loss:  0.693138837814331\n",
      "valid_loss:  0.6931528449058533\n",
      "valid_loss:  0.693152129650116\n",
      "valid_loss:  0.69316565990448\n",
      "valid_loss:  0.6931362748146057\n",
      "valid_loss:  0.6931416392326355\n",
      "Class:  0  accuracy:  tensor(0.6673)\n",
      "Class:  0  correct:  333.0  of  tensor(499.)\n",
      "Class:  1  accuracy:  tensor(0.4700)\n",
      "Class:  1  correct:  47.0  of  tensor(100.)\n",
      "Final percentage:  tensor(0.5687)\n",
      "Last epoch:  21\n",
      "Credit Cost:  -430\n",
      "\n",
      "\n",
      "Best Score So Far:  -430\n",
      "| \u001b[95m 8       \u001b[0m | \u001b[95m-430.0   \u001b[0m | \u001b[95m 4.356   \u001b[0m | \u001b[95m 2.228   \u001b[0m | \u001b[95m 0.3234  \u001b[0m | \u001b[95m 0.1581  \u001b[0m | \u001b[95m 1.886e+0\u001b[0m | \u001b[95m 2.068   \u001b[0m | \u001b[95m 0.3643  \u001b[0m | \u001b[95m 20.7    \u001b[0m | \u001b[95m 0.01679 \u001b[0m | \u001b[95m 0.6506  \u001b[0m | \u001b[95m 2.375   \u001b[0m | \u001b[95m 0.9873  \u001b[0m | \u001b[95m 1.515   \u001b[0m | \u001b[95m 1.821   \u001b[0m |\n",
      "Optimization:  SGD (\n",
      "Parameter Group 0\n",
      "    dampening: 0\n",
      "    lr: 0.28749\n",
      "    momentum: 0.24\n",
      "    nesterov: False\n",
      "    weight_decay: 0.018\n",
      ")\n",
      "Batch Normalization Momentum:  0.07\n",
      "Nodes:  5\n",
      "LR:  0.28749\n",
      "RELU:  True\n",
      "BIAS:  False\n",
      "Loss Type:  3\n",
      "REGULARIZATION:  0.018\n",
      "BATCH_SIZE:  119\n",
      "Dropout:  0.23\n",
      "Final Linear Layers:  3\n",
      "valid_loss:  0.693080484867096\n",
      "average loss: 0.693080\n",
      "valid_loss:  0.693281888961792\n",
      "valid_loss:  0.6933025121688843\n",
      "valid_loss:  0.6929852962493896\n",
      "valid_loss:  0.6930405497550964\n",
      "valid_loss:  0.6935926079750061\n",
      "valid_loss:  0.6940030455589294\n",
      "valid_loss:  0.6939138174057007\n",
      "valid_loss:  0.6938510537147522\n",
      "valid_loss:  0.6937550902366638\n",
      "valid_loss:  0.6938486099243164\n",
      "valid_loss:  0.6941388249397278\n",
      "valid_loss:  0.6941483616828918\n",
      "valid_loss:  0.6943143606185913\n",
      "valid_loss:  0.6944711804389954\n",
      "valid_loss:  0.69426429271698\n",
      "valid_loss:  0.6943395733833313\n",
      "valid_loss:  0.6941980719566345\n",
      "valid_loss:  0.6943638324737549\n",
      "valid_loss:  0.6946393251419067\n",
      "valid_loss:  0.6945102214813232\n",
      "valid_loss:  0.6945282816886902\n",
      "valid_loss:  0.694533109664917\n",
      "valid_loss:  0.6944880485534668\n",
      "valid_loss:  0.6943581104278564\n",
      "Loaded the model with the lowest Validation Loss!\n",
      "Class:  0  accuracy:  tensor(0.4749)\n",
      "Class:  0  correct:  237.0  of  tensor(499.)\n",
      "Class:  1  accuracy:  tensor(0.5800)\n",
      "Class:  1  correct:  58.0  of  tensor(100.)\n",
      "Final percentage:  tensor(0.5275)\n",
      "Last epoch:  24\n",
      "Credit Cost:  -472\n",
      "\n",
      "\n",
      "Best Score So Far:  -430\n",
      "| \u001b[0m 9       \u001b[0m | \u001b[0m-472.0   \u001b[0m | \u001b[0m 119.6   \u001b[0m | \u001b[0m 2.387   \u001b[0m | \u001b[0m 0.06534 \u001b[0m | \u001b[0m 0.2266  \u001b[0m | \u001b[0m 1.754e+0\u001b[0m | \u001b[0m 3.76    \u001b[0m | \u001b[0m 0.2875  \u001b[0m | \u001b[0m 5.728   \u001b[0m | \u001b[0m 0.02084 \u001b[0m | \u001b[0m 0.01845 \u001b[0m | \u001b[0m 1.056   \u001b[0m | \u001b[0m 0.2437  \u001b[0m | \u001b[0m 3.571   \u001b[0m | \u001b[0m 4.228   \u001b[0m |\n",
      "Optimization:  Adadelta (\n",
      "Parameter Group 0\n",
      "    eps: 1e-06\n",
      "    lr: 0.2288\n",
      "    rho: 0.9\n",
      "    weight_decay: 0.163\n",
      ")\n",
      "Batch Normalization Momentum:  0.12\n",
      "Nodes:  2\n",
      "LR:  0.2288\n",
      "RELU:  False\n",
      "BIAS:  False\n",
      "Loss Type:  3\n",
      "REGULARIZATION:  0.163\n",
      "BATCH_SIZE:  72\n",
      "Dropout:  0.08\n",
      "Final Linear Layers:  3\n",
      "valid_loss:  0.6905131340026855\n",
      "average loss: 0.690513\n",
      "valid_loss:  0.6910443902015686\n",
      "valid_loss:  0.6916096210479736\n",
      "valid_loss:  0.692079484462738\n",
      "valid_loss:  0.6920604109764099\n",
      "valid_loss:  0.6922125220298767\n",
      "valid_loss:  0.6930186748504639\n",
      "valid_loss:  0.6931743025779724\n",
      "valid_loss:  0.6937135457992554\n",
      "valid_loss:  0.6939106583595276\n",
      "valid_loss:  0.693932294845581\n",
      "valid_loss:  0.6941812038421631\n",
      "valid_loss:  0.6945257782936096\n",
      "valid_loss:  0.6950932741165161\n",
      "valid_loss:  0.6953766345977783\n",
      "valid_loss:  0.6960353851318359\n",
      "valid_loss:  0.6964382529258728\n",
      "valid_loss:  0.6973256468772888\n",
      "valid_loss:  0.6975457072257996\n",
      "valid_loss:  0.6985153555870056\n",
      "valid_loss:  0.6983806490898132\n",
      "valid_loss:  0.6994011402130127\n",
      "Class:  0  accuracy:  tensor(0.4289)\n",
      "Class:  0  correct:  214.0  of  tensor(499.)\n",
      "Class:  1  accuracy:  tensor(0.6400)\n",
      "Class:  1  correct:  64.0  of  tensor(100.)\n",
      "Final percentage:  tensor(0.5344)\n",
      "Last epoch:  21\n",
      "Credit Cost:  -465\n",
      "\n",
      "\n",
      "Best Score So Far:  -430\n",
      "| \u001b[0m 10      \u001b[0m | \u001b[0m-465.0   \u001b[0m | \u001b[0m 72.55   \u001b[0m | \u001b[0m 2.676   \u001b[0m | \u001b[0m 0.1229  \u001b[0m | \u001b[0m 0.08376 \u001b[0m | \u001b[0m 1.586e+0\u001b[0m | \u001b[0m 3.899   \u001b[0m | \u001b[0m 0.2288  \u001b[0m | \u001b[0m 2.559   \u001b[0m | \u001b[0m 0.8     \u001b[0m | \u001b[0m 0.1632  \u001b[0m | \u001b[0m 2.606   \u001b[0m | \u001b[0m 0.384   \u001b[0m | \u001b[0m 3.582   \u001b[0m | \u001b[0m 5.475   \u001b[0m |\n",
      "Optimization:  Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: True\n",
      "    betas: (0.9, 0.99)\n",
      "    eps: 1e-08\n",
      "    lr: 0.09803\n",
      "    weight_decay: 0.009\n",
      ")\n",
      "Batch Normalization Momentum:  0.06\n",
      "Nodes:  23\n",
      "LR:  0.09803\n",
      "RELU:  True\n",
      "BIAS:  True\n",
      "Loss Type:  2\n",
      "REGULARIZATION:  0.009\n",
      "BATCH_SIZE:  72\n",
      "Dropout:  0.04\n",
      "Final Linear Layers:  1\n",
      "valid_loss:  0.6919036507606506\n",
      "average loss: 0.691904\n",
      "valid_loss:  0.6928901672363281\n",
      "valid_loss:  0.6937264204025269\n",
      "valid_loss:  0.6936705708503723\n",
      "valid_loss:  0.6932496428489685\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid_loss:  0.6930686235427856\n",
      "valid_loss:  0.6930844187736511\n",
      "valid_loss:  0.693134605884552\n",
      "valid_loss:  0.693139910697937\n",
      "valid_loss:  0.6931332349777222\n",
      "valid_loss:  0.6931442022323608\n",
      "valid_loss:  0.6931478977203369\n",
      "valid_loss:  0.6931496262550354\n",
      "valid_loss:  0.6931477189064026\n",
      "valid_loss:  0.6931469440460205\n",
      "valid_loss:  0.6931477189064026\n",
      "valid_loss:  0.6931471824645996\n",
      "valid_loss:  0.6931474804878235\n",
      "valid_loss:  0.6931471228599548\n",
      "valid_loss:  0.6931473612785339\n",
      "valid_loss:  0.6931474208831787\n",
      "valid_loss:  0.6931473612785339\n",
      "Class:  0  accuracy:  tensor(0.9399)\n",
      "Class:  0  correct:  469.0  of  tensor(499.)\n",
      "Class:  1  accuracy:  tensor(0.1800)\n",
      "Class:  1  correct:  18.0  of  tensor(100.)\n",
      "Final percentage:  tensor(0.5599)\n",
      "Last epoch:  21\n",
      "Credit Cost:  -440\n",
      "\n",
      "\n",
      "Best Score So Far:  -430\n",
      "| \u001b[0m 11      \u001b[0m | \u001b[0m-440.0   \u001b[0m | \u001b[0m 72.97   \u001b[0m | \u001b[0m 1.272   \u001b[0m | \u001b[0m 0.05932 \u001b[0m | \u001b[0m 0.0364  \u001b[0m | \u001b[0m 1.045e+0\u001b[0m | \u001b[0m 1.321   \u001b[0m | \u001b[0m 0.09803 \u001b[0m | \u001b[0m 23.39   \u001b[0m | \u001b[0m 0.5596  \u001b[0m | \u001b[0m 0.008888\u001b[0m | \u001b[0m 1.143   \u001b[0m | \u001b[0m 0.9576  \u001b[0m | \u001b[0m 2.699   \u001b[0m | \u001b[0m 2.218   \u001b[0m |\n",
      "Optimization:  AdamW (\n",
      "Parameter Group 0\n",
      "    betas: (0.9, 0.99)\n",
      "    eps: 1e-08\n",
      "    lr: 0.10354\n",
      "    weight_decay: 0.58\n",
      ")\n",
      "Batch Normalization Momentum:  0.19\n",
      "Nodes:  16\n",
      "LR:  0.10354\n",
      "RELU:  True\n",
      "BIAS:  False\n",
      "Loss Type:  1\n",
      "REGULARIZATION:  0.58\n",
      "BATCH_SIZE:  35\n",
      "Dropout:  0.17\n",
      "Final Linear Layers:  3\n",
      "valid_loss:  0.7005674839019775\n",
      "average loss: 0.700567\n",
      "valid_loss:  0.6949186325073242\n",
      "valid_loss:  0.6936132907867432\n",
      "valid_loss:  0.6933054327964783\n",
      "valid_loss:  0.693195104598999\n",
      "valid_loss:  0.6931623220443726\n",
      "valid_loss:  0.6931519508361816\n",
      "valid_loss:  0.6931486129760742\n",
      "valid_loss:  0.6931475400924683\n",
      "valid_loss:  0.6931474208831787\n",
      "valid_loss:  0.6931474208831787\n",
      "valid_loss:  0.6931474208831787\n",
      "valid_loss:  0.6931474208831787\n",
      "valid_loss:  0.6931474208831787\n",
      "valid_loss:  0.6931474208831787\n",
      "valid_loss:  0.6931474208831787\n",
      "valid_loss:  0.6931474208831787\n",
      "valid_loss:  0.6931474208831787\n",
      "valid_loss:  0.6931474208831787\n",
      "valid_loss:  0.6931474208831787\n",
      "valid_loss:  0.6931474208831787\n",
      "valid_loss:  0.6931474208831787\n",
      "valid_loss:  0.6931474208831787\n",
      "valid_loss:  0.6931474208831787\n",
      "valid_loss:  0.6931474208831787\n",
      "valid_loss:  0.6931474208831787\n",
      "valid_loss:  0.6931474208831787\n",
      "valid_loss:  0.6931474208831787\n",
      "Loaded the model with the lowest Validation Loss!\n",
      "Class:  0  accuracy:  tensor(0.3327)\n",
      "Class:  0  correct:  166.0  of  tensor(499.)\n",
      "Class:  1  accuracy:  tensor(0.5500)\n",
      "Class:  1  correct:  55.0  of  tensor(100.)\n",
      "Final percentage:  tensor(0.4413)\n",
      "Last epoch:  27\n",
      "Credit Cost:  -558\n",
      "\n",
      "\n",
      "Best Score So Far:  -430\n",
      "| \u001b[0m 12      \u001b[0m | \u001b[0m-558.0   \u001b[0m | \u001b[0m 35.29   \u001b[0m | \u001b[0m 2.48    \u001b[0m | \u001b[0m 0.1935  \u001b[0m | \u001b[0m 0.1744  \u001b[0m | \u001b[0m 1.97e+03\u001b[0m | \u001b[0m 3.532   \u001b[0m | \u001b[0m 0.1035  \u001b[0m | \u001b[0m 16.81   \u001b[0m | \u001b[0m 0.6197  \u001b[0m | \u001b[0m 0.5803  \u001b[0m | \u001b[0m 1.312   \u001b[0m | \u001b[0m 0.01839 \u001b[0m | \u001b[0m 1.209   \u001b[0m | \u001b[0m 3.913   \u001b[0m |\n",
      "Optimization:  Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: True\n",
      "    betas: (0.9, 0.99)\n",
      "    eps: 1e-08\n",
      "    lr: 0.22487\n",
      "    weight_decay: 0.186\n",
      ")\n",
      "Batch Normalization Momentum:  0.31\n",
      "Nodes:  24\n",
      "LR:  0.22487\n",
      "RELU:  True\n",
      "BIAS:  False\n",
      "Loss Type:  2\n",
      "REGULARIZATION:  0.186\n",
      "BATCH_SIZE:  79\n",
      "Dropout:  0.3\n",
      "Final Linear Layers:  2\n",
      "valid_loss:  0.6937829256057739\n",
      "average loss: 0.693783\n",
      "valid_loss:  0.6958616375923157\n",
      "valid_loss:  0.696482241153717\n",
      "valid_loss:  0.6931073665618896\n",
      "valid_loss:  0.6938867568969727\n",
      "valid_loss:  0.6931548118591309\n",
      "valid_loss:  0.6929805874824524\n",
      "valid_loss:  0.6929623484611511\n",
      "valid_loss:  0.6929976940155029\n",
      "valid_loss:  0.6926467418670654\n",
      "valid_loss:  0.6928518414497375\n",
      "valid_loss:  0.6931369304656982\n",
      "valid_loss:  0.6932322978973389\n",
      "valid_loss:  0.6930342316627502\n",
      "valid_loss:  0.6930407881736755\n",
      "valid_loss:  0.6931831240653992\n",
      "valid_loss:  0.6931450366973877\n",
      "valid_loss:  0.6931459307670593\n",
      "valid_loss:  0.6931434869766235\n",
      "valid_loss:  0.6931446194648743\n",
      "valid_loss:  0.6931458711624146\n",
      "valid_loss:  0.6931474804878235\n",
      "valid_loss:  0.6931475400924683\n",
      "valid_loss:  0.6931473016738892\n",
      "valid_loss:  0.6931472420692444\n",
      "valid_loss:  0.6931471824645996\n",
      "valid_loss:  0.6931474208831787\n",
      "valid_loss:  0.6931473016738892\n",
      "valid_loss:  0.6931474208831787\n",
      "valid_loss:  0.6931473612785339\n",
      "valid_loss:  0.6931474208831787\n",
      "Loaded the model with the lowest Validation Loss!\n",
      "Class:  0  accuracy:  tensor(0.6593)\n",
      "Class:  0  correct:  329.0  of  tensor(499.)\n",
      "Class:  1  accuracy:  tensor(0.5800)\n",
      "Class:  1  correct:  58.0  of  tensor(100.)\n",
      "Final percentage:  tensor(0.6197)\n",
      "Last epoch:  30\n",
      "Credit Cost:  -380\n",
      "\n",
      "\n",
      "Best Score So Far:  -380\n",
      "| \u001b[95m 13      \u001b[0m | \u001b[95m-380.0   \u001b[0m | \u001b[95m 79.18   \u001b[0m | \u001b[95m 2.132   \u001b[0m | \u001b[95m 0.3142  \u001b[0m | \u001b[95m 0.2966  \u001b[0m | \u001b[95m 1.58e+03\u001b[0m | \u001b[95m 2.137   \u001b[0m | \u001b[95m 0.2249  \u001b[0m | \u001b[95m 24.36   \u001b[0m | \u001b[95m 0.6689  \u001b[0m | \u001b[95m 0.1855  \u001b[0m | \u001b[95m 1.132   \u001b[0m | \u001b[95m 0.3664  \u001b[0m | \u001b[95m 2.883   \u001b[0m | \u001b[95m 2.259   \u001b[0m |\n",
      "Optimization:  Adagrad (\n",
      "Parameter Group 0\n",
      "    initial_accumulator_value: 0\n",
      "    lr: 0.21462\n",
      "    lr_decay: 0\n",
      "    weight_decay: 0.046\n",
      ")\n",
      "Batch Normalization Momentum:  0.26\n",
      "Nodes:  29\n",
      "LR:  0.21462\n",
      "RELU:  False\n",
      "BIAS:  True\n",
      "Loss Type:  3\n",
      "REGULARIZATION:  0.046\n",
      "BATCH_SIZE:  97\n",
      "Dropout:  0.24\n",
      "Final Linear Layers:  2\n",
      "valid_loss:  0.6921892166137695\n",
      "average loss: 0.692189\n",
      "valid_loss:  0.6931474804878235\n",
      "valid_loss:  0.6931474208831787\n",
      "valid_loss:  0.6931474208831787\n",
      "valid_loss:  0.6931474208831787\n",
      "valid_loss:  0.6931474208831787\n",
      "valid_loss:  0.6931474208831787\n",
      "valid_loss:  0.6931474208831787\n",
      "valid_loss:  0.6931474208831787\n",
      "valid_loss:  0.6931474208831787\n",
      "valid_loss:  0.6931474208831787\n",
      "valid_loss:  0.6931474208831787\n",
      "valid_loss:  0.6931474208831787\n",
      "valid_loss:  0.6931474208831787\n",
      "valid_loss:  0.6931474208831787\n",
      "valid_loss:  0.6931474208831787\n",
      "valid_loss:  0.6931474208831787\n",
      "valid_loss:  0.6931474208831787\n",
      "valid_loss:  0.6931474208831787\n",
      "valid_loss:  0.6931474208831787\n",
      "valid_loss:  0.6931474208831787\n",
      "valid_loss:  0.6931474208831787\n",
      "Class:  0  accuracy:  tensor(1.)\n",
      "Class:  0  correct:  499.0  of  tensor(499.)\n",
      "Class:  1  accuracy:  tensor(0.)\n",
      "Class:  1  correct:  0.0  of  tensor(100.)\n",
      "Final percentage:  tensor(0.5000)\n",
      "Last epoch:  21\n",
      "Credit Cost:  -800\n",
      "\n",
      "\n",
      "Best Score So Far:  -380\n",
      "| \u001b[0m 14      \u001b[0m | \u001b[0m-800.0   \u001b[0m | \u001b[0m 97.34   \u001b[0m | \u001b[0m 1.132   \u001b[0m | \u001b[0m 0.2577  \u001b[0m | \u001b[0m 0.2414  \u001b[0m | \u001b[0m 1.193e+0\u001b[0m | \u001b[0m 2.912   \u001b[0m | \u001b[0m 0.2146  \u001b[0m | \u001b[0m 29.74   \u001b[0m | \u001b[0m 0.2638  \u001b[0m | \u001b[0m 0.04627 \u001b[0m | \u001b[0m 2.463   \u001b[0m | \u001b[0m 0.7645  \u001b[0m | \u001b[0m 3.714   \u001b[0m | \u001b[0m 6.583   \u001b[0m |\n",
      "Optimization:  Adagrad (\n",
      "Parameter Group 0\n",
      "    initial_accumulator_value: 0\n",
      "    lr: 0.36709\n",
      "    lr_decay: 0\n",
      "    weight_decay: 0.34\n",
      ")\n",
      "Batch Normalization Momentum:  0.61\n",
      "Nodes:  21\n",
      "LR:  0.36709\n",
      "RELU:  False\n",
      "BIAS:  True\n",
      "Loss Type:  3\n",
      "REGULARIZATION:  0.34\n",
      "BATCH_SIZE:  5\n",
      "Dropout:  0.28\n",
      "Final Linear Layers:  2\n",
      "valid_loss:  0.6931474208831787\n",
      "average loss: 0.693147\n",
      "valid_loss:  0.6931474208831787\n",
      "valid_loss:  0.6931474208831787\n",
      "valid_loss:  0.6931474208831787\n",
      "valid_loss:  0.6931474208831787\n",
      "valid_loss:  0.6931474208831787\n",
      "valid_loss:  0.6931474208831787\n",
      "valid_loss:  0.6931474208831787\n",
      "valid_loss:  0.6931474208831787\n",
      "valid_loss:  0.6931474208831787\n",
      "valid_loss:  0.6931474208831787\n",
      "valid_loss:  0.6931474208831787\n",
      "valid_loss:  0.6931474208831787\n",
      "valid_loss:  0.6931474208831787\n",
      "valid_loss:  0.6931474208831787\n",
      "valid_loss:  0.6931474208831787\n",
      "valid_loss:  0.6931474208831787\n",
      "valid_loss:  0.6931474208831787\n",
      "valid_loss:  0.6931474208831787\n",
      "valid_loss:  0.6931474208831787\n",
      "valid_loss:  0.6931474208831787\n",
      "valid_loss:  0.6931474208831787\n",
      "Class:  0  accuracy:  tensor(1.)\n",
      "Class:  0  correct:  499.0  of  tensor(499.)\n",
      "Class:  1  accuracy:  tensor(0.)\n",
      "Class:  1  correct:  0.0  of  tensor(100.)\n",
      "Final percentage:  tensor(0.5000)\n",
      "Last epoch:  21\n",
      "Credit Cost:  -800\n",
      "\n",
      "\n",
      "Best Score So Far:  -380\n",
      "| \u001b[0m 15      \u001b[0m | \u001b[0m-800.0   \u001b[0m | \u001b[0m 5.73    \u001b[0m | \u001b[0m 1.466   \u001b[0m | \u001b[0m 0.6106  \u001b[0m | \u001b[0m 0.2847  \u001b[0m | \u001b[0m 1.95e+03\u001b[0m | \u001b[0m 2.664   \u001b[0m | \u001b[0m 0.3671  \u001b[0m | \u001b[0m 21.25   \u001b[0m | \u001b[0m 0.3902  \u001b[0m | \u001b[0m 0.3402  \u001b[0m | \u001b[0m 2.203   \u001b[0m | \u001b[0m 0.5441  \u001b[0m | \u001b[0m 3.769   \u001b[0m | \u001b[0m 6.503   \u001b[0m |\n",
      "Optimization:  Adadelta (\n",
      "Parameter Group 0\n",
      "    eps: 1e-06\n",
      "    lr: 0.01839\n",
      "    rho: 0.9\n",
      "    weight_decay: 0.011\n",
      ")\n",
      "Batch Normalization Momentum:  0.17\n",
      "Nodes:  30\n",
      "LR:  0.01839\n",
      "RELU:  True\n",
      "BIAS:  False\n",
      "Loss Type:  1\n",
      "REGULARIZATION:  0.011\n",
      "BATCH_SIZE:  52\n",
      "Dropout:  0.04\n",
      "Final Linear Layers:  2\n",
      "valid_loss:  0.6803578734397888\n",
      "average loss: 0.680358\n",
      "valid_loss:  0.6798068881034851\n",
      "valid_loss:  0.679448127746582\n",
      "valid_loss:  0.682162880897522\n",
      "valid_loss:  0.6757189631462097\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid_loss:  0.6753391027450562\n",
      "valid_loss:  0.6736605167388916\n",
      "valid_loss:  0.6749920845031738\n",
      "valid_loss:  0.6732900142669678\n",
      "valid_loss:  0.6684211492538452\n",
      "valid_loss:  0.6734665632247925\n",
      "valid_loss:  0.6759016513824463\n",
      "valid_loss:  0.6742407083511353\n",
      "valid_loss:  0.6722380518913269\n",
      "valid_loss:  0.6731740832328796\n",
      "valid_loss:  0.6728967428207397\n",
      "valid_loss:  0.6729834079742432\n",
      "valid_loss:  0.6760599613189697\n",
      "valid_loss:  0.6768255829811096\n",
      "valid_loss:  0.6736294031143188\n",
      "valid_loss:  0.6698828339576721\n",
      "valid_loss:  0.6723021268844604\n",
      "valid_loss:  0.6731031537055969\n",
      "valid_loss:  0.6730296611785889\n",
      "valid_loss:  0.6762775182723999\n",
      "valid_loss:  0.6738359928131104\n",
      "valid_loss:  0.6731058955192566\n",
      "valid_loss:  0.6739704608917236\n",
      "valid_loss:  0.6734068989753723\n",
      "valid_loss:  0.6716012358665466\n",
      "valid_loss:  0.6755683422088623\n",
      "Loaded the model with the lowest Validation Loss!\n",
      "Class:  0  accuracy:  tensor(0.6072)\n",
      "Class:  0  correct:  303.0  of  tensor(499.)\n",
      "Class:  1  accuracy:  tensor(0.4100)\n",
      "Class:  1  correct:  41.0  of  tensor(100.)\n",
      "Final percentage:  tensor(0.5086)\n",
      "Last epoch:  30\n",
      "Credit Cost:  -491\n",
      "\n",
      "\n",
      "Best Score So Far:  -380\n",
      "| \u001b[0m 16      \u001b[0m | \u001b[0m-491.0   \u001b[0m | \u001b[0m 52.96   \u001b[0m | \u001b[0m 2.917   \u001b[0m | \u001b[0m 0.1722  \u001b[0m | \u001b[0m 0.0379  \u001b[0m | \u001b[0m 1.135e+0\u001b[0m | \u001b[0m 2.512   \u001b[0m | \u001b[0m 0.01839 \u001b[0m | \u001b[0m 30.44   \u001b[0m | \u001b[0m 0.8265  \u001b[0m | \u001b[0m 0.01061 \u001b[0m | \u001b[0m 1.351   \u001b[0m | \u001b[0m 0.3287  \u001b[0m | \u001b[0m 1.392   \u001b[0m | \u001b[0m 5.849   \u001b[0m |\n",
      "Optimization:  SGD (\n",
      "Parameter Group 0\n",
      "    dampening: 0\n",
      "    lr: 0.18935\n",
      "    momentum: 0.59\n",
      "    nesterov: False\n",
      "    weight_decay: 0.2\n",
      ")\n",
      "Batch Normalization Momentum:  0.58\n",
      "Nodes:  18\n",
      "LR:  0.18935\n",
      "RELU:  True\n",
      "BIAS:  False\n",
      "Loss Type:  1\n",
      "REGULARIZATION:  0.2\n",
      "BATCH_SIZE:  46\n",
      "Dropout:  0.26\n",
      "Final Linear Layers:  3\n",
      "valid_loss:  0.6871554851531982\n",
      "average loss: 0.687155\n",
      "valid_loss:  0.6905472278594971\n",
      "valid_loss:  0.691817581653595\n",
      "valid_loss:  0.6929135322570801\n",
      "valid_loss:  0.6931275725364685\n",
      "valid_loss:  0.6931455135345459\n",
      "valid_loss:  0.6931471228599548\n",
      "valid_loss:  0.6931473612785339\n",
      "valid_loss:  0.6931474208831787\n",
      "valid_loss:  0.6931474208831787\n",
      "valid_loss:  0.6931474208831787\n",
      "valid_loss:  0.6931474208831787\n",
      "valid_loss:  0.6931474208831787\n",
      "valid_loss:  0.6931474208831787\n",
      "valid_loss:  0.6931474208831787\n",
      "valid_loss:  0.6931474208831787\n",
      "valid_loss:  0.6931474208831787\n",
      "valid_loss:  0.6931474208831787\n",
      "valid_loss:  0.6931474208831787\n",
      "valid_loss:  0.6931474208831787\n",
      "valid_loss:  0.6931474208831787\n",
      "valid_loss:  0.6931474208831787\n",
      "Class:  0  accuracy:  tensor(1.)\n",
      "Class:  0  correct:  499.0  of  tensor(499.)\n",
      "Class:  1  accuracy:  tensor(0.)\n",
      "Class:  1  correct:  0.0  of  tensor(100.)\n",
      "Final percentage:  tensor(0.5000)\n",
      "Last epoch:  21\n",
      "Credit Cost:  -800\n",
      "\n",
      "\n",
      "Best Score So Far:  -380\n",
      "| \u001b[0m 17      \u001b[0m | \u001b[0m-800.0   \u001b[0m | \u001b[0m 46.75   \u001b[0m | \u001b[0m 2.871   \u001b[0m | \u001b[0m 0.5762  \u001b[0m | \u001b[0m 0.2636  \u001b[0m | \u001b[0m 1.845e+0\u001b[0m | \u001b[0m 3.707   \u001b[0m | \u001b[0m 0.1894  \u001b[0m | \u001b[0m 18.39   \u001b[0m | \u001b[0m 0.798   \u001b[0m | \u001b[0m 0.2001  \u001b[0m | \u001b[0m 1.976   \u001b[0m | \u001b[0m 0.5931  \u001b[0m | \u001b[0m 1.046   \u001b[0m | \u001b[0m 4.555   \u001b[0m |\n",
      "Optimization:  Adagrad (\n",
      "Parameter Group 0\n",
      "    initial_accumulator_value: 0\n",
      "    lr: 0.31729\n",
      "    lr_decay: 0\n",
      "    weight_decay: 0.294\n",
      ")\n",
      "Batch Normalization Momentum:  0.31\n",
      "Nodes:  20\n",
      "LR:  0.31729\n",
      "RELU:  False\n",
      "BIAS:  False\n",
      "Loss Type:  1\n",
      "REGULARIZATION:  0.294\n",
      "BATCH_SIZE:  57\n",
      "Dropout:  0.27\n",
      "Final Linear Layers:  1\n",
      "valid_loss:  0.6931471824645996\n",
      "average loss: 0.693147\n",
      "valid_loss:  0.6931474208831787\n",
      "valid_loss:  0.6931474208831787\n",
      "valid_loss:  0.6931474208831787\n",
      "valid_loss:  0.6931474208831787\n",
      "valid_loss:  0.6931474208831787\n",
      "valid_loss:  0.6931474208831787\n",
      "valid_loss:  0.6931474208831787\n",
      "valid_loss:  0.6931474208831787\n",
      "valid_loss:  0.6931474208831787\n",
      "valid_loss:  0.6931474208831787\n",
      "valid_loss:  0.6931474208831787\n",
      "valid_loss:  0.6931474208831787\n",
      "valid_loss:  0.6931474208831787\n",
      "valid_loss:  0.6931474208831787\n",
      "valid_loss:  0.6931474208831787\n",
      "valid_loss:  0.6931474208831787\n",
      "valid_loss:  0.6931474208831787\n",
      "valid_loss:  0.6931474208831787\n",
      "valid_loss:  0.6931474208831787\n",
      "valid_loss:  0.6931474208831787\n",
      "valid_loss:  0.6931474208831787\n",
      "Class:  0  accuracy:  tensor(1.)\n",
      "Class:  0  correct:  499.0  of  tensor(499.)\n",
      "Class:  1  accuracy:  tensor(0.)\n",
      "Class:  1  correct:  0.0  of  tensor(100.)\n",
      "Final percentage:  tensor(0.5000)\n",
      "Last epoch:  21\n",
      "Credit Cost:  -800\n",
      "\n",
      "\n",
      "Best Score So Far:  -380\n",
      "| \u001b[0m 18      \u001b[0m | \u001b[0m-800.0   \u001b[0m | \u001b[0m 57.78   \u001b[0m | \u001b[0m 2.607   \u001b[0m | \u001b[0m 0.3121  \u001b[0m | \u001b[0m 0.2679  \u001b[0m | \u001b[0m 1.578e+0\u001b[0m | \u001b[0m 1.55    \u001b[0m | \u001b[0m 0.3173  \u001b[0m | \u001b[0m 20.36   \u001b[0m | \u001b[0m 0.0548  \u001b[0m | \u001b[0m 0.2942  \u001b[0m | \u001b[0m 2.351   \u001b[0m | \u001b[0m 0.9094  \u001b[0m | \u001b[0m 1.001   \u001b[0m | \u001b[0m 6.851   \u001b[0m |\n",
      "Optimization:  Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: True\n",
      "    betas: (0.9, 0.99)\n",
      "    eps: 1e-08\n",
      "    lr: 0.12137\n",
      "    weight_decay: 0.601\n",
      ")\n",
      "Batch Normalization Momentum:  0.6\n",
      "Nodes:  19\n",
      "LR:  0.12137\n",
      "RELU:  False\n",
      "BIAS:  False\n",
      "Loss Type:  3\n",
      "REGULARIZATION:  0.601\n",
      "BATCH_SIZE:  50\n",
      "Dropout:  0.25\n",
      "Final Linear Layers:  2\n",
      "valid_loss:  0.691127359867096\n",
      "average loss: 0.691127\n",
      "valid_loss:  0.6960650682449341\n",
      "valid_loss:  0.685839831829071\n",
      "valid_loss:  0.692758321762085\n",
      "valid_loss:  0.6942013502120972\n",
      "valid_loss:  0.6925463080406189\n",
      "valid_loss:  0.6931445598602295\n",
      "valid_loss:  0.6931586265563965\n",
      "valid_loss:  0.6931527853012085\n",
      "valid_loss:  0.6931506991386414\n",
      "valid_loss:  0.6931464076042175\n",
      "valid_loss:  0.6931450963020325\n",
      "valid_loss:  0.6931474804878235\n",
      "valid_loss:  0.6931474804878235\n",
      "valid_loss:  0.6931473612785339\n",
      "valid_loss:  0.6931473612785339\n",
      "valid_loss:  0.6931473612785339\n",
      "valid_loss:  0.6931474208831787\n",
      "valid_loss:  0.6931474208831787\n",
      "valid_loss:  0.6931474208831787\n",
      "valid_loss:  0.6931474208831787\n",
      "valid_loss:  0.6931474208831787\n",
      "valid_loss:  0.6931474208831787\n",
      "valid_loss:  0.6931474208831787\n",
      "Loaded the model with the lowest Validation Loss!\n",
      "Class:  0  accuracy:  tensor(0.6393)\n",
      "Class:  0  correct:  319.0  of  tensor(499.)\n",
      "Class:  1  accuracy:  tensor(0.5500)\n",
      "Class:  1  correct:  55.0  of  tensor(100.)\n",
      "Final percentage:  tensor(0.5946)\n",
      "Last epoch:  23\n",
      "Credit Cost:  -405\n",
      "\n",
      "\n",
      "Best Score So Far:  -380\n",
      "| \u001b[0m 19      \u001b[0m | \u001b[0m-405.0   \u001b[0m | \u001b[0m 50.7    \u001b[0m | \u001b[0m 2.938   \u001b[0m | \u001b[0m 0.5987  \u001b[0m | \u001b[0m 0.2487  \u001b[0m | \u001b[0m 1.575e+0\u001b[0m | \u001b[0m 2.878   \u001b[0m | \u001b[0m 0.1214  \u001b[0m | \u001b[0m 19.61   \u001b[0m | \u001b[0m 0.7495  \u001b[0m | \u001b[0m 0.6008  \u001b[0m | \u001b[0m 2.503   \u001b[0m | \u001b[0m 0.6911  \u001b[0m | \u001b[0m 3.585   \u001b[0m | \u001b[0m 2.933   \u001b[0m |\n",
      "Optimization:  Adadelta (\n",
      "Parameter Group 0\n",
      "    eps: 1e-06\n",
      "    lr: 0.25255\n",
      "    rho: 0.9\n",
      "    weight_decay: 0.474\n",
      ")\n",
      "Batch Normalization Momentum:  0.38\n",
      "Nodes:  14\n",
      "LR:  0.25255\n",
      "RELU:  True\n",
      "BIAS:  True\n",
      "Loss Type:  2\n",
      "REGULARIZATION:  0.474\n",
      "BATCH_SIZE:  87\n",
      "Dropout:  0.12\n",
      "Final Linear Layers:  1\n",
      "valid_loss:  0.7428365349769592\n",
      "average loss: 0.742837\n",
      "valid_loss:  0.7409247756004333\n",
      "valid_loss:  0.7492912411689758\n",
      "valid_loss:  0.7421858310699463\n",
      "valid_loss:  0.7547571659088135\n",
      "valid_loss:  0.7582268118858337\n",
      "valid_loss:  0.7657737135887146\n",
      "valid_loss:  0.7980940937995911\n",
      "valid_loss:  0.795121431350708\n",
      "valid_loss:  0.7543985247612\n",
      "valid_loss:  0.7549208998680115\n",
      "valid_loss:  0.7564520835876465\n",
      "valid_loss:  0.7603280544281006\n",
      "valid_loss:  0.7561208605766296\n",
      "valid_loss:  0.7560428977012634\n",
      "valid_loss:  0.7780251502990723\n",
      "valid_loss:  0.7601163983345032\n",
      "valid_loss:  0.7618699669837952\n",
      "valid_loss:  0.7545127272605896\n",
      "valid_loss:  0.7553247213363647\n",
      "valid_loss:  0.7565253973007202\n",
      "valid_loss:  0.7773382663726807\n",
      "valid_loss:  0.752849817276001\n",
      "Loaded the model with the lowest Validation Loss!\n",
      "Class:  0  accuracy:  tensor(0.2224)\n",
      "Class:  0  correct:  111.0  of  tensor(499.)\n",
      "Class:  1  accuracy:  tensor(0.6700)\n",
      "Class:  1  correct:  67.0  of  tensor(100.)\n",
      "Final percentage:  tensor(0.4462)\n",
      "Last epoch:  22\n",
      "Credit Cost:  -553\n",
      "\n",
      "\n",
      "Best Score So Far:  -380\n",
      "| \u001b[0m 20      \u001b[0m | \u001b[0m-553.0   \u001b[0m | \u001b[0m 87.18   \u001b[0m | \u001b[0m 1.897   \u001b[0m | \u001b[0m 0.3783  \u001b[0m | \u001b[0m 0.1232  \u001b[0m | \u001b[0m 1.401e+0\u001b[0m | \u001b[0m 1.949   \u001b[0m | \u001b[0m 0.2525  \u001b[0m | \u001b[0m 14.91   \u001b[0m | \u001b[0m 0.9729  \u001b[0m | \u001b[0m 0.4745  \u001b[0m | \u001b[0m 1.395   \u001b[0m | \u001b[0m 0.4224  \u001b[0m | \u001b[0m 2.027   \u001b[0m | \u001b[0m 5.778   \u001b[0m |\n",
      "Optimization:  AdamW (\n",
      "Parameter Group 0\n",
      "    betas: (0.9, 0.99)\n",
      "    eps: 1e-08\n",
      "    lr: 0.21581\n",
      "    weight_decay: 0.513\n",
      ")\n",
      "Batch Normalization Momentum:  0.66\n",
      "Nodes:  26\n",
      "LR:  0.21581\n",
      "RELU:  False\n",
      "BIAS:  False\n",
      "Loss Type:  2\n",
      "REGULARIZATION:  0.513\n",
      "BATCH_SIZE:  113\n",
      "Dropout:  0.08\n",
      "Final Linear Layers:  3\n",
      "valid_loss:  0.6873138546943665\n",
      "average loss: 0.687314\n",
      "valid_loss:  0.684903621673584\n",
      "valid_loss:  0.6863969564437866\n",
      "valid_loss:  0.6885971426963806\n",
      "valid_loss:  0.6903889179229736\n",
      "valid_loss:  0.6912400126457214\n",
      "valid_loss:  0.6915990710258484\n",
      "valid_loss:  0.6923243999481201\n",
      "valid_loss:  0.6927283406257629\n",
      "valid_loss:  0.6929696202278137\n",
      "valid_loss:  0.6930522322654724\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid_loss:  0.6931139826774597\n",
      "valid_loss:  0.6931331157684326\n",
      "valid_loss:  0.6931412220001221\n",
      "valid_loss:  0.6931445002555847\n",
      "valid_loss:  0.693146288394928\n",
      "valid_loss:  0.6931468844413757\n",
      "valid_loss:  0.6931473016738892\n",
      "valid_loss:  0.6931474208831787\n",
      "valid_loss:  0.6931473612785339\n",
      "valid_loss:  0.6931473612785339\n",
      "valid_loss:  0.6931474208831787\n",
      "valid_loss:  0.6931474208831787\n",
      "Loaded the model with the lowest Validation Loss!\n",
      "Class:  0  accuracy:  tensor(0.7475)\n",
      "Class:  0  correct:  373.0  of  tensor(499.)\n",
      "Class:  1  accuracy:  tensor(0.4200)\n",
      "Class:  1  correct:  42.0  of  tensor(100.)\n",
      "Final percentage:  tensor(0.5837)\n",
      "Last epoch:  22\n",
      "Credit Cost:  -416\n",
      "\n",
      "\n",
      "Best Score So Far:  -380\n",
      "| \u001b[0m 21      \u001b[0m | \u001b[0m-416.0   \u001b[0m | \u001b[0m 113.1   \u001b[0m | \u001b[0m 2.799   \u001b[0m | \u001b[0m 0.6561  \u001b[0m | \u001b[0m 0.08106 \u001b[0m | \u001b[0m 1.252e+0\u001b[0m | \u001b[0m 3.556   \u001b[0m | \u001b[0m 0.2158  \u001b[0m | \u001b[0m 26.06   \u001b[0m | \u001b[0m 0.5723  \u001b[0m | \u001b[0m 0.5132  \u001b[0m | \u001b[0m 2.033   \u001b[0m | \u001b[0m 0.7632  \u001b[0m | \u001b[0m 2.701   \u001b[0m | \u001b[0m 3.79    \u001b[0m |\n",
      "Optimization:  Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: True\n",
      "    betas: (0.9, 0.99)\n",
      "    eps: 1e-08\n",
      "    lr: 0.32662\n",
      "    weight_decay: 0.399\n",
      ")\n",
      "Batch Normalization Momentum:  0.37\n",
      "Nodes:  28\n",
      "LR:  0.32662\n",
      "RELU:  True\n",
      "BIAS:  True\n",
      "Loss Type:  2\n",
      "REGULARIZATION:  0.399\n",
      "BATCH_SIZE:  46\n",
      "Dropout:  0.02\n",
      "Final Linear Layers:  1\n",
      "valid_loss:  0.7210354208946228\n",
      "average loss: 0.721035\n",
      "valid_loss:  0.6931205987930298\n",
      "valid_loss:  0.6908037662506104\n",
      "valid_loss:  0.6925138831138611\n",
      "valid_loss:  0.6928515434265137\n",
      "valid_loss:  0.693327009677887\n",
      "valid_loss:  0.6928986310958862\n",
      "valid_loss:  0.6934734582901001\n",
      "valid_loss:  0.6931446194648743\n",
      "valid_loss:  0.6930274367332458\n",
      "valid_loss:  0.6931508183479309\n",
      "valid_loss:  0.6931459903717041\n",
      "valid_loss:  0.6931474208831787\n",
      "valid_loss:  0.6931473612785339\n",
      "valid_loss:  0.693146824836731\n",
      "valid_loss:  0.6931473612785339\n",
      "valid_loss:  0.6931473612785339\n",
      "valid_loss:  0.6931474208831787\n",
      "valid_loss:  0.6931474208831787\n",
      "valid_loss:  0.6931473612785339\n",
      "valid_loss:  0.6931474208831787\n",
      "valid_loss:  0.6931474208831787\n",
      "valid_loss:  0.6931474208831787\n",
      "valid_loss:  0.6931474208831787\n",
      "Loaded the model with the lowest Validation Loss!\n",
      "Class:  0  accuracy:  tensor(0.5912)\n",
      "Class:  0  correct:  295.0  of  tensor(499.)\n",
      "Class:  1  accuracy:  tensor(0.5400)\n",
      "Class:  1  correct:  54.0  of  tensor(100.)\n",
      "Final percentage:  tensor(0.5656)\n",
      "Last epoch:  23\n",
      "Credit Cost:  -434\n",
      "\n",
      "\n",
      "Best Score So Far:  -380\n",
      "| \u001b[0m 22      \u001b[0m | \u001b[0m-434.0   \u001b[0m | \u001b[0m 46.49   \u001b[0m | \u001b[0m 1.136   \u001b[0m | \u001b[0m 0.3741  \u001b[0m | \u001b[0m 0.02389 \u001b[0m | \u001b[0m 1.983e+0\u001b[0m | \u001b[0m 1.543   \u001b[0m | \u001b[0m 0.3266  \u001b[0m | \u001b[0m 28.25   \u001b[0m | \u001b[0m 0.688   \u001b[0m | \u001b[0m 0.3987  \u001b[0m | \u001b[0m 1.32    \u001b[0m | \u001b[0m 0.4622  \u001b[0m | \u001b[0m 2.032   \u001b[0m | \u001b[0m 2.348   \u001b[0m |\n",
      "Optimization:  SGD (\n",
      "Parameter Group 0\n",
      "    dampening: 0\n",
      "    lr: 0.08526\n",
      "    momentum: 0.84\n",
      "    nesterov: False\n",
      "    weight_decay: 0.146\n",
      ")\n",
      "Batch Normalization Momentum:  0.91\n",
      "Nodes:  16\n",
      "LR:  0.08526\n",
      "RELU:  True\n",
      "BIAS:  True\n",
      "Loss Type:  2\n",
      "REGULARIZATION:  0.146\n",
      "BATCH_SIZE:  77\n",
      "Dropout:  0.27\n",
      "Final Linear Layers:  1\n",
      "valid_loss:  2.035618543624878\n",
      "average loss: 2.035619\n",
      "valid_loss:  3.1853725910186768\n",
      "valid_loss:  0.939294159412384\n",
      "valid_loss:  0.6836119294166565\n",
      "valid_loss:  0.6919742226600647\n",
      "valid_loss:  0.6914935111999512\n",
      "valid_loss:  0.6929095387458801\n",
      "valid_loss:  0.693106472492218\n",
      "valid_loss:  0.6931456327438354\n",
      "valid_loss:  0.6931473612785339\n",
      "valid_loss:  0.6931471228599548\n",
      "valid_loss:  0.6931478977203369\n",
      "valid_loss:  0.6931481957435608\n",
      "valid_loss:  0.6931480765342712\n",
      "valid_loss:  0.6931478977203369\n",
      "valid_loss:  0.6931474208831787\n",
      "valid_loss:  0.6931474208831787\n",
      "valid_loss:  0.6931473612785339\n",
      "valid_loss:  0.6931473016738892\n",
      "valid_loss:  0.6931473612785339\n",
      "valid_loss:  0.6931474208831787\n",
      "valid_loss:  0.6931474208831787\n",
      "valid_loss:  0.6931474208831787\n",
      "valid_loss:  0.6931474208831787\n",
      "valid_loss:  0.6931474208831787\n",
      "Loaded the model with the lowest Validation Loss!\n",
      "Class:  0  accuracy:  tensor(0.0060)\n",
      "Class:  0  correct:  3.0  of  tensor(499.)\n",
      "Class:  1  accuracy:  tensor(0.9900)\n",
      "Class:  1  correct:  99.0  of  tensor(100.)\n",
      "Final percentage:  tensor(0.4980)\n",
      "Last epoch:  24\n",
      "Credit Cost:  -501\n",
      "\n",
      "\n",
      "Best Score So Far:  -380\n",
      "| \u001b[0m 23      \u001b[0m | \u001b[0m-501.0   \u001b[0m | \u001b[0m 77.47   \u001b[0m | \u001b[0m 1.621   \u001b[0m | \u001b[0m 0.9071  \u001b[0m | \u001b[0m 0.2729  \u001b[0m | \u001b[0m 1.257e+0\u001b[0m | \u001b[0m 1.332   \u001b[0m | \u001b[0m 0.08526 \u001b[0m | \u001b[0m 16.99   \u001b[0m | \u001b[0m 0.7281  \u001b[0m | \u001b[0m 0.1458  \u001b[0m | \u001b[0m 1.494   \u001b[0m | \u001b[0m 0.8432  \u001b[0m | \u001b[0m 2.243   \u001b[0m | \u001b[0m 4.694   \u001b[0m |\n",
      "Optimization:  Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.99)\n",
      "    eps: 1e-08\n",
      "    lr: 0.22216\n",
      "    weight_decay: 0.526\n",
      ")\n",
      "Batch Normalization Momentum:  0.51\n",
      "Nodes:  21\n",
      "LR:  0.22216\n",
      "RELU:  True\n",
      "BIAS:  True\n",
      "Loss Type:  3\n",
      "REGULARIZATION:  0.526\n",
      "BATCH_SIZE:  32\n",
      "Dropout:  0.14\n",
      "Final Linear Layers:  2\n",
      "valid_loss:  0.6908632516860962\n",
      "average loss: 0.690863\n",
      "valid_loss:  0.6938861608505249\n",
      "valid_loss:  0.6930705904960632\n",
      "valid_loss:  0.6934659481048584\n",
      "valid_loss:  0.6932321786880493\n",
      "valid_loss:  0.6931607723236084\n",
      "valid_loss:  0.6931480765342712\n",
      "valid_loss:  0.6931477189064026\n",
      "valid_loss:  0.6931478381156921\n",
      "valid_loss:  0.6931473016738892\n",
      "valid_loss:  0.6931474208831787\n",
      "valid_loss:  0.6931474208831787\n",
      "valid_loss:  0.6931474208831787\n",
      "valid_loss:  0.6931474208831787\n",
      "valid_loss:  0.6931474208831787\n",
      "valid_loss:  0.6931474208831787\n",
      "valid_loss:  0.6931474208831787\n",
      "valid_loss:  0.6931474208831787\n",
      "valid_loss:  0.6931474208831787\n",
      "valid_loss:  0.6931474208831787\n",
      "valid_loss:  0.6931474208831787\n",
      "valid_loss:  0.6931474208831787\n",
      "Class:  0  accuracy:  tensor(1.)\n",
      "Class:  0  correct:  499.0  of  tensor(499.)\n",
      "Class:  1  accuracy:  tensor(0.)\n",
      "Class:  1  correct:  0.0  of  tensor(100.)\n",
      "Final percentage:  tensor(0.5000)\n",
      "Last epoch:  21\n",
      "Credit Cost:  -800\n",
      "\n",
      "\n",
      "Best Score So Far:  -380\n",
      "| \u001b[0m 24      \u001b[0m | \u001b[0m-800.0   \u001b[0m | \u001b[0m 32.97   \u001b[0m | \u001b[0m 1.203   \u001b[0m | \u001b[0m 0.5107  \u001b[0m | \u001b[0m 0.1431  \u001b[0m | \u001b[0m 1.153e+0\u001b[0m | \u001b[0m 2.859   \u001b[0m | \u001b[0m 0.2222  \u001b[0m | \u001b[0m 21.62   \u001b[0m | \u001b[0m 0.1453  \u001b[0m | \u001b[0m 0.5261  \u001b[0m | \u001b[0m 1.442   \u001b[0m | \u001b[0m 0.5142  \u001b[0m | \u001b[0m 3.348   \u001b[0m | \u001b[0m 1.134   \u001b[0m |\n",
      "Optimization:  Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.99)\n",
      "    eps: 1e-08\n",
      "    lr: 0.3323\n",
      "    weight_decay: 0.456\n",
      ")\n",
      "Batch Normalization Momentum:  0.84\n",
      "Nodes:  27\n",
      "LR:  0.3323\n",
      "RELU:  False\n",
      "BIAS:  False\n",
      "Loss Type:  3\n",
      "REGULARIZATION:  0.456\n",
      "BATCH_SIZE:  44\n",
      "Dropout:  0.16\n",
      "Final Linear Layers:  3\n",
      "valid_loss:  0.6988007426261902\n",
      "average loss: 0.698801\n",
      "valid_loss:  0.6947888731956482\n",
      "valid_loss:  0.6831470131874084\n",
      "valid_loss:  0.6811155080795288\n",
      "valid_loss:  0.6932398676872253\n",
      "valid_loss:  0.6717645525932312\n",
      "valid_loss:  0.6814573407173157\n",
      "valid_loss:  0.6948859691619873\n",
      "valid_loss:  0.6928892731666565\n",
      "valid_loss:  0.6934443116188049\n",
      "valid_loss:  0.6931065917015076\n",
      "valid_loss:  0.6931689381599426\n",
      "valid_loss:  0.6931332945823669\n",
      "valid_loss:  0.6931458711624146\n",
      "valid_loss:  0.6931478977203369\n",
      "valid_loss:  0.6931475400924683\n",
      "valid_loss:  0.693147599697113\n",
      "valid_loss:  0.6931472420692444\n",
      "valid_loss:  0.6931473612785339\n",
      "valid_loss:  0.6931473612785339\n",
      "valid_loss:  0.6931474208831787\n",
      "valid_loss:  0.6931474208831787\n",
      "valid_loss:  0.6931474208831787\n",
      "valid_loss:  0.6931474208831787\n",
      "valid_loss:  0.6931474208831787\n",
      "valid_loss:  0.6931474208831787\n",
      "valid_loss:  0.6931474208831787\n",
      "Loaded the model with the lowest Validation Loss!\n",
      "Class:  0  accuracy:  tensor(0.6293)\n",
      "Class:  0  correct:  314.0  of  tensor(499.)\n",
      "Class:  1  accuracy:  tensor(0.6000)\n",
      "Class:  1  correct:  60.0  of  tensor(100.)\n",
      "Final percentage:  tensor(0.6146)\n",
      "Last epoch:  26\n",
      "Credit Cost:  -385\n",
      "\n",
      "\n",
      "Best Score So Far:  -380\n",
      "| \u001b[0m 25      \u001b[0m | \u001b[0m-385.0   \u001b[0m | \u001b[0m 44.22   \u001b[0m | \u001b[0m 2.737   \u001b[0m | \u001b[0m 0.8363  \u001b[0m | \u001b[0m 0.1615  \u001b[0m | \u001b[0m 1.867e+0\u001b[0m | \u001b[0m 3.84    \u001b[0m | \u001b[0m 0.3323  \u001b[0m | \u001b[0m 27.62   \u001b[0m | \u001b[0m 0.09955 \u001b[0m | \u001b[0m 0.4559  \u001b[0m | \u001b[0m 2.4     \u001b[0m | \u001b[0m 0.6041  \u001b[0m | \u001b[0m 3.391   \u001b[0m | \u001b[0m 1.207   \u001b[0m |\n",
      "Optimization:  SGD (\n",
      "Parameter Group 0\n",
      "    dampening: 0\n",
      "    lr: 0.32067\n",
      "    momentum: 0.14\n",
      "    nesterov: False\n",
      "    weight_decay: 0.693\n",
      ")\n",
      "Batch Normalization Momentum:  0.26\n",
      "Nodes:  15\n",
      "LR:  0.32067\n",
      "RELU:  True\n",
      "BIAS:  False\n",
      "Loss Type:  3\n",
      "REGULARIZATION:  0.693\n",
      "BATCH_SIZE:  99\n",
      "Dropout:  0.08\n",
      "Final Linear Layers:  2\n",
      "valid_loss:  0.6919363141059875\n",
      "average loss: 0.691936\n",
      "valid_loss:  0.6930797100067139\n",
      "valid_loss:  0.6931521892547607\n",
      "valid_loss:  0.6931483149528503\n",
      "valid_loss:  0.6931473612785339\n",
      "valid_loss:  0.6931474208831787\n",
      "valid_loss:  0.6931474208831787\n",
      "valid_loss:  0.6931474208831787\n",
      "valid_loss:  0.6931474208831787\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid_loss:  0.6931474208831787\n",
      "valid_loss:  0.6931474208831787\n",
      "valid_loss:  0.6931474208831787\n",
      "valid_loss:  0.6931474208831787\n",
      "valid_loss:  0.6931474208831787\n",
      "valid_loss:  0.6931474208831787\n",
      "valid_loss:  0.6931474208831787\n",
      "valid_loss:  0.6931474208831787\n",
      "valid_loss:  0.6931474208831787\n",
      "valid_loss:  0.6931474208831787\n",
      "valid_loss:  0.6931474208831787\n",
      "valid_loss:  0.6931474208831787\n",
      "valid_loss:  0.6931474208831787\n",
      "Class:  0  accuracy:  tensor(1.)\n",
      "Class:  0  correct:  499.0  of  tensor(499.)\n",
      "Class:  1  accuracy:  tensor(0.)\n",
      "Class:  1  correct:  0.0  of  tensor(100.)\n",
      "Final percentage:  tensor(0.5000)\n",
      "Last epoch:  21\n",
      "Credit Cost:  -800\n",
      "\n",
      "\n",
      "Best Score So Far:  -380\n",
      "| \u001b[0m 26      \u001b[0m | \u001b[0m-800.0   \u001b[0m | \u001b[0m 99.51   \u001b[0m | \u001b[0m 2.456   \u001b[0m | \u001b[0m 0.2571  \u001b[0m | \u001b[0m 0.07712 \u001b[0m | \u001b[0m 1.632e+0\u001b[0m | \u001b[0m 2.032   \u001b[0m | \u001b[0m 0.3207  \u001b[0m | \u001b[0m 15.38   \u001b[0m | \u001b[0m 0.7822  \u001b[0m | \u001b[0m 0.6933  \u001b[0m | \u001b[0m 1.597   \u001b[0m | \u001b[0m 0.1416  \u001b[0m | \u001b[0m 3.695   \u001b[0m | \u001b[0m 4.244   \u001b[0m |\n",
      "Optimization:  Adadelta (\n",
      "Parameter Group 0\n",
      "    eps: 1e-06\n",
      "    lr: 0.14873\n",
      "    rho: 0.9\n",
      "    weight_decay: 0.522\n",
      ")\n",
      "Batch Normalization Momentum:  0.98\n",
      "Nodes:  2\n",
      "LR:  0.14873\n",
      "RELU:  True\n",
      "BIAS:  False\n",
      "Loss Type:  3\n",
      "REGULARIZATION:  0.522\n",
      "BATCH_SIZE:  124\n",
      "Dropout:  0.16\n",
      "Final Linear Layers:  1\n",
      "valid_loss:  0.696956217288971\n",
      "average loss: 0.696956\n",
      "valid_loss:  0.6904341578483582\n",
      "valid_loss:  0.6889006495475769\n",
      "valid_loss:  0.6870549917221069\n",
      "valid_loss:  0.6958182454109192\n",
      "valid_loss:  0.691724956035614\n",
      "valid_loss:  0.7002153396606445\n",
      "valid_loss:  0.690989077091217\n",
      "valid_loss:  0.6982483863830566\n",
      "valid_loss:  0.6986250877380371\n",
      "valid_loss:  0.6874923706054688\n",
      "valid_loss:  0.6901013851165771\n",
      "valid_loss:  0.6914353966712952\n",
      "valid_loss:  0.6943999528884888\n",
      "valid_loss:  0.683793842792511\n",
      "valid_loss:  0.6940567493438721\n",
      "valid_loss:  0.6980695128440857\n",
      "valid_loss:  0.6863255500793457\n",
      "valid_loss:  0.6870465278625488\n",
      "valid_loss:  0.6892130374908447\n",
      "valid_loss:  0.6914255619049072\n",
      "valid_loss:  0.6948100924491882\n",
      "valid_loss:  0.6908390522003174\n",
      "valid_loss:  0.6843747496604919\n",
      "valid_loss:  0.6915752291679382\n",
      "valid_loss:  0.6895212531089783\n",
      "valid_loss:  0.6878945231437683\n",
      "valid_loss:  0.6896806955337524\n",
      "valid_loss:  0.6859130859375\n",
      "valid_loss:  0.6901251673698425\n",
      "valid_loss:  0.6880955100059509\n",
      "valid_loss:  0.6875943541526794\n",
      "valid_loss:  0.6837022304534912\n",
      "valid_loss:  0.6913958191871643\n",
      "valid_loss:  0.6840175986289978\n",
      "valid_loss:  0.6854844689369202\n",
      "valid_loss:  0.6863973736763\n",
      "valid_loss:  0.693535327911377\n",
      "valid_loss:  0.6915352940559387\n",
      "valid_loss:  0.6903617978096008\n",
      "valid_loss:  0.6846491098403931\n",
      "valid_loss:  0.6903720498085022\n",
      "valid_loss:  0.6848401427268982\n",
      "valid_loss:  0.6880112886428833\n",
      "valid_loss:  0.6870465874671936\n",
      "valid_loss:  0.6903295516967773\n",
      "valid_loss:  0.694799542427063\n",
      "valid_loss:  0.6852782964706421\n",
      "valid_loss:  0.6853011250495911\n",
      "valid_loss:  0.685913622379303\n",
      "valid_loss:  0.6879118084907532\n",
      "valid_loss:  0.6869526505470276\n",
      "valid_loss:  0.6888179183006287\n",
      "valid_loss:  0.689999520778656\n",
      "Loaded the model with the lowest Validation Loss!\n",
      "Class:  0  accuracy:  tensor(0.6453)\n",
      "Class:  0  correct:  322.0  of  tensor(499.)\n",
      "Class:  1  accuracy:  tensor(0.3200)\n",
      "Class:  1  correct:  32.0  of  tensor(100.)\n",
      "Final percentage:  tensor(0.4826)\n",
      "Last epoch:  53\n",
      "Credit Cost:  -517\n",
      "\n",
      "\n",
      "Best Score So Far:  -380\n",
      "| \u001b[0m 27      \u001b[0m | \u001b[0m-517.0   \u001b[0m | \u001b[0m 124.9   \u001b[0m | \u001b[0m 2.267   \u001b[0m | \u001b[0m 0.984   \u001b[0m | \u001b[0m 0.1638  \u001b[0m | \u001b[0m 1.526e+0\u001b[0m | \u001b[0m 1.405   \u001b[0m | \u001b[0m 0.1487  \u001b[0m | \u001b[0m 2.787   \u001b[0m | \u001b[0m 0.1611  \u001b[0m | \u001b[0m 0.522   \u001b[0m | \u001b[0m 1.06    \u001b[0m | \u001b[0m 0.3629  \u001b[0m | \u001b[0m 3.578   \u001b[0m | \u001b[0m 5.149   \u001b[0m |\n",
      "Optimization:  Adadelta (\n",
      "Parameter Group 0\n",
      "    eps: 1e-06\n",
      "    lr: 0.10662\n",
      "    rho: 0.9\n",
      "    weight_decay: 0.32\n",
      ")\n",
      "Batch Normalization Momentum:  0.44\n",
      "Nodes:  9\n",
      "LR:  0.10662\n",
      "RELU:  True\n",
      "BIAS:  True\n",
      "Loss Type:  1\n",
      "REGULARIZATION:  0.32\n",
      "BATCH_SIZE:  89\n",
      "Dropout:  0.17\n",
      "Final Linear Layers:  1\n",
      "valid_loss:  0.6990581750869751\n",
      "average loss: 0.699058\n",
      "valid_loss:  0.689391553401947\n",
      "valid_loss:  0.6806634068489075\n",
      "valid_loss:  0.6767891645431519\n",
      "valid_loss:  0.6777732372283936\n",
      "valid_loss:  0.680001974105835\n",
      "valid_loss:  0.6814124584197998\n",
      "valid_loss:  0.6798383593559265\n",
      "valid_loss:  0.6767873764038086\n",
      "valid_loss:  0.6765795350074768\n",
      "valid_loss:  0.6776341199874878\n",
      "valid_loss:  0.6872638463973999\n",
      "valid_loss:  0.680465042591095\n",
      "valid_loss:  0.6800548434257507\n",
      "valid_loss:  0.7028085589408875\n",
      "valid_loss:  0.6798346042633057\n",
      "valid_loss:  0.680670976638794\n",
      "valid_loss:  0.6788974404335022\n",
      "valid_loss:  0.6815137267112732\n",
      "valid_loss:  0.6796132922172546\n",
      "valid_loss:  0.6821939945220947\n",
      "valid_loss:  0.6821277141571045\n",
      "valid_loss:  0.682723343372345\n",
      "valid_loss:  0.6776695847511292\n",
      "valid_loss:  0.6807294487953186\n",
      "valid_loss:  0.6791491508483887\n",
      "valid_loss:  0.6795004606246948\n",
      "valid_loss:  0.6821413040161133\n",
      "valid_loss:  0.680037260055542\n",
      "valid_loss:  0.6842019557952881\n",
      "valid_loss:  0.6812188029289246\n",
      "Loaded the model with the lowest Validation Loss!\n",
      "Class:  0  accuracy:  tensor(0.7956)\n",
      "Class:  0  correct:  397.0  of  tensor(499.)\n",
      "Class:  1  accuracy:  tensor(0.4100)\n",
      "Class:  1  correct:  41.0  of  tensor(100.)\n",
      "Final percentage:  tensor(0.6028)\n",
      "Last epoch:  30\n",
      "Credit Cost:  -397\n",
      "\n",
      "\n",
      "Best Score So Far:  -380\n",
      "| \u001b[0m 28      \u001b[0m | \u001b[0m-397.0   \u001b[0m | \u001b[0m 89.68   \u001b[0m | \u001b[0m 1.375   \u001b[0m | \u001b[0m 0.4375  \u001b[0m | \u001b[0m 0.1745  \u001b[0m | \u001b[0m 1.99e+03\u001b[0m | \u001b[0m 1.61    \u001b[0m | \u001b[0m 0.1066  \u001b[0m | \u001b[0m 9.865   \u001b[0m | \u001b[0m 0.7497  \u001b[0m | \u001b[0m 0.3199  \u001b[0m | \u001b[0m 1.113   \u001b[0m | \u001b[0m 0.5034  \u001b[0m | \u001b[0m 1.634   \u001b[0m | \u001b[0m 5.784   \u001b[0m |\n",
      "Optimization:  Adagrad (\n",
      "Parameter Group 0\n",
      "    initial_accumulator_value: 0\n",
      "    lr: 0.20935\n",
      "    lr_decay: 0\n",
      "    weight_decay: 0.563\n",
      ")\n",
      "Batch Normalization Momentum:  0.59\n",
      "Nodes:  18\n",
      "LR:  0.20935\n",
      "RELU:  True\n",
      "BIAS:  True\n",
      "Loss Type:  2\n",
      "REGULARIZATION:  0.563\n",
      "BATCH_SIZE:  40\n",
      "Dropout:  0.25\n",
      "Final Linear Layers:  3\n",
      "valid_loss:  0.6931474208831787\n",
      "average loss: 0.693147\n",
      "valid_loss:  0.6931474208831787\n",
      "valid_loss:  0.6931474208831787\n",
      "valid_loss:  0.6931474208831787\n",
      "valid_loss:  0.6931474208831787\n",
      "valid_loss:  0.6931474208831787\n",
      "valid_loss:  0.6931474208831787\n",
      "valid_loss:  0.6931474208831787\n",
      "valid_loss:  0.6931474208831787\n",
      "valid_loss:  0.6931474208831787\n",
      "valid_loss:  0.6931474208831787\n",
      "valid_loss:  0.6931474208831787\n",
      "valid_loss:  0.6931474208831787\n",
      "valid_loss:  0.6931474208831787\n",
      "valid_loss:  0.6931474208831787\n",
      "valid_loss:  0.6931474208831787\n",
      "valid_loss:  0.6931474208831787\n",
      "valid_loss:  0.6931474208831787\n",
      "valid_loss:  0.6931474208831787\n",
      "valid_loss:  0.6931474208831787\n",
      "valid_loss:  0.6931474208831787\n",
      "valid_loss:  0.6931474208831787\n",
      "Class:  0  accuracy:  tensor(1.)\n",
      "Class:  0  correct:  499.0  of  tensor(499.)\n",
      "Class:  1  accuracy:  tensor(0.)\n",
      "Class:  1  correct:  0.0  of  tensor(100.)\n",
      "Final percentage:  tensor(0.5000)\n",
      "Last epoch:  21\n",
      "Credit Cost:  -800\n",
      "\n",
      "\n",
      "Best Score So Far:  -380\n",
      "| \u001b[0m 29      \u001b[0m | \u001b[0m-800.0   \u001b[0m | \u001b[0m 40.87   \u001b[0m | \u001b[0m 1.055   \u001b[0m | \u001b[0m 0.5875  \u001b[0m | \u001b[0m 0.2532  \u001b[0m | \u001b[0m 1.381e+0\u001b[0m | \u001b[0m 3.242   \u001b[0m | \u001b[0m 0.2093  \u001b[0m | \u001b[0m 18.23   \u001b[0m | \u001b[0m 0.9585  \u001b[0m | \u001b[0m 0.5628  \u001b[0m | \u001b[0m 1.064   \u001b[0m | \u001b[0m 0.7023  \u001b[0m | \u001b[0m 2.39    \u001b[0m | \u001b[0m 6.676   \u001b[0m |\n",
      "Optimization:  SGD (\n",
      "Parameter Group 0\n",
      "    dampening: 0\n",
      "    lr: 0.32316\n",
      "    momentum: 0.42\n",
      "    nesterov: False\n",
      "    weight_decay: 0.24\n",
      ")\n",
      "Batch Normalization Momentum:  0.08\n",
      "Nodes:  22\n",
      "LR:  0.32316\n",
      "RELU:  False\n",
      "BIAS:  True\n",
      "Loss Type:  3\n",
      "REGULARIZATION:  0.24\n",
      "BATCH_SIZE:  31\n",
      "Dropout:  0.13\n",
      "Final Linear Layers:  2\n",
      "valid_loss:  0.6937509179115295\n",
      "average loss: 0.693751\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "if OPTIMIZATION_PLUGIN == 'Bayesian' :\n",
    "    from bayes_opt import BayesianOptimization\n",
    "    \n",
    "    #def black_box_function(x, y):\n",
    "    def objective(SCI_RELU, SCI_BIAS, SCI_loss_type, SCI_optimizer, SCI_BATCH_SIZE, SCI_MM, SCI_REGULARIZATION, SCI_LR, SCI_DROPOUT, SCI_L_SECOND, SCI_EPOCHS, SCI_BN_MOMENTUM, SCI_SGD_MOMENTUM, SCI_LINEARITY):\n",
    "        global device, MaxCredit  \n",
    "        \n",
    "        SCI_BATCH_SIZE = int(SCI_BATCH_SIZE)                    # integer between 4 and 256\n",
    "        SCI_MM = round(SCI_MM,3)                                # real with three decimals between (0.001, 0.999)\n",
    "        SCI_REGULARIZATION = round(SCI_REGULARIZATION,3)        # real with three decimals between (0.001, 0.7)\n",
    "        SCI_LR = round(SCI_LR,5)                                # real with five decimals between(1e-4, 7e-1)            \n",
    "        SCI_DROPOUT = round(SCI_DROPOUT,2)                      # real with two decimals between (0, 0.4)\n",
    "        SCI_L_SECOND = int(SCI_L_SECOND)                        # integer between 2 and 64\n",
    "        SCI_EPOCHS = int(SCI_EPOCHS)                            # integer between (100, 500)\n",
    "        SCI_BN_MOMENTUM = round(SCI_BN_MOMENTUM,2)              # real with two decimals between (0, 0.99)\n",
    "        SCI_SGD_MOMENTUM = round(SCI_SGD_MOMENTUM,2)            # real with two decimals between (0, 0.99) \n",
    "        SCI_optimizer = int(SCI_optimizer)                      # integer between 1 and 4\n",
    "        SCI_loss_type = int(SCI_loss_type)                      # integer between 1 and 3 ('CrossEntropyLoss', 'MultiMarginLoss','NLLLoss')\n",
    "        SCI_LINEARITY = int(SCI_LINEARITY)\n",
    "        if int(SCI_RELU) == 1 :                                 # integer between 1 and 2 ('True', 'False')\n",
    "            SCI_RELU = True      \n",
    "        else:\n",
    "            SCI_RELU = False      \n",
    "        if int(SCI_BIAS) == 1 :                                 # integer between 1 and 2 ('True', 'False')\n",
    "            SCI_BIAS = True      \n",
    "        else:\n",
    "            SCI_BIAS = False  \n",
    "               \n",
    "        from cnn_model import CNN6\n",
    "        cnn = CNN6(L_FIRST, SCI_L_SECOND, KERNEL_X, SCI_BIAS, SCI_BN_MOMENTUM, SCI_RELU, SCI_DROPOUT, dataset.CLASSES, SCI_LINEARITY)     \n",
    "    \n",
    "        if GPU_SELECT == 2:\n",
    "            if torch.cuda.device_count() > 1:\n",
    "                cnn = nn.DataParallel(cnn,device_ids=[0, 1], dim = 0) \n",
    "            cnn = cnn.cuda()                \n",
    "        if GPU_SELECT == 1:\n",
    "            cnn.to(device)  \n",
    "        if GPU_SELECT == 0:\n",
    "            cnn.to(device)        \n",
    "\n",
    "        #next(cnn.parameters()).is_cuda\n",
    "        #print(cnn)  # net architecture   \n",
    "        #list(cnn.parameters()) \n",
    "        cnn.apply(CNN6.weights_reset)        \n",
    "        cnn.share_memory()\n",
    "     \n",
    "        loss_func = nn.CrossEntropyLoss()\n",
    "\n",
    "        def create_loss(LOSS):   \n",
    "            if LOSS == 1:\n",
    "                loss_func = nn.CrossEntropyLoss()\n",
    "            if LOSS == 2:\n",
    "                loss_func = nn.NLLLoss()\n",
    "            else:\n",
    "                loss_func = nn.MultiMarginLoss()\n",
    "            return loss_func\n",
    "\n",
    "        MM = float(str(SCI_MM))\n",
    "        REGULARIZATION = float(str(SCI_REGULARIZATION))\n",
    "        #optimizer = str(SCI_optimizer)\n",
    "        LR = float(str(SCI_LR))\n",
    "        train_losses = []         # to track the training loss as the model trains\n",
    "        output = 0\n",
    "        loss = 0\n",
    "        accuracy = 0\n",
    "        early_stopping.counter = 0\n",
    "        early_stopping.best_score = None\n",
    "        early_stopping.early_stop = False\n",
    "        early_stopping.verbose = False  \n",
    "        TEST_RESULTS = torch.zeros(1,2)\n",
    "    \n",
    "        loss_type = create_loss(SCI_loss_type)\n",
    "    \n",
    "        from adamw import AdamW\n",
    "        \n",
    "        \n",
    "        if SCI_optimizer == 1:\n",
    "            optimizer = optim.Adam(cnn.parameters(), lr=LR, betas=(0.9, 0.99), weight_decay=REGULARIZATION)\n",
    "        if SCI_optimizer == 2:\n",
    "            optimizer = optim.Adam(cnn.parameters(), lr=LR, betas=(0.9, 0.99), weight_decay=REGULARIZATION, amsgrad=True)\n",
    "        if SCI_optimizer == 3:\n",
    "            optimizer = AdamW(cnn.parameters(), lr=LR, betas=(0.9, 0.99), weight_decay = REGULARIZATION)           \n",
    "        if SCI_optimizer == 4:\n",
    "            optimizer = optim.SGD(cnn.parameters(), lr=LR, momentum=SCI_SGD_MOMENTUM, weight_decay=REGULARIZATION)\n",
    "        if SCI_optimizer == 5:\n",
    "            optimizer = optim.Adadelta(cnn.parameters(), lr=LR, weight_decay=REGULARIZATION)\n",
    "        if SCI_optimizer == 6:\n",
    "            optimizer = optim.Adagrad(cnn.parameters(), lr=LR, weight_decay=REGULARIZATION)\n",
    "    \n",
    "        from Utillities import Utillities\n",
    "        Utillities.listing(optimizer, SCI_SGD_MOMENTUM, SCI_BN_MOMENTUM, SCI_L_SECOND, SCI_LR, SCI_RELU, SCI_BIAS, SCI_loss_type, REGULARIZATION, SCI_BATCH_SIZE, SCI_DROPOUT, SCI_LINEARITY)\n",
    "\n",
    "    \n",
    "        # Data Loader for easy mini-batch return in training\n",
    "        SCI_BATCH_SIZE = int(SCI_BATCH_SIZE)\n",
    "        train_loader = Data.DataLoader(dataset = dataset.train_dataset, batch_size = SCI_BATCH_SIZE, shuffle = True, num_workers = 0, drop_last=True, pin_memory=True)\n",
    "        validation_loader = Data.DataLoader(dataset = dataset.validation_dataset, batch_size = 144, shuffle = True, num_workers = 0, drop_last=True, pin_memory=True)    \n",
    "        test_loader = Data.DataLoader(dataset = dataset.test_dataset, batch_size = 599, shuffle = True, num_workers = 0, drop_last=True, pin_memory=True)\n",
    "    \n",
    "        for epoch in range(SCI_EPOCHS):\n",
    "            loss = None        \n",
    "            cnn.train().cuda()\n",
    "            for step, (train_data, train_target) in enumerate(train_loader):   \n",
    "                train_data, train_target = train_data.to(device), train_target.to(device)\n",
    "                output, temp = cnn(train_data)                # forward pass: compute predicted outputs by passing inputs to the model     \n",
    "                loss = loss_func(output, train_target)\n",
    "                train_losses.append(loss.item())              # record training loss \n",
    "                loss.backward()                               # backward pass: compute gradient of the loss with respect to model parameters\n",
    "                optimizer.zero_grad()\n",
    "                optimizer.step()                              # perform a single optimization step (parameter update)\n",
    "      \n",
    "            cnn.eval().cuda()                 # switch to evaluation (no change) mode           \n",
    "            valid_loss = 0\n",
    "            accuracy = 0\n",
    "            running_loss = 0.0\n",
    "            with torch.no_grad():\n",
    "                for step, (validation_data, validation_target) in enumerate(validation_loader):\n",
    "                    validation_data, validation_target = validation_data.to(device), validation_target.to(device)\n",
    "                    output, temp = cnn(validation_data)            # forward pass: compute predicted outputs by passing inputs to the model\n",
    "                    valid_loss += loss_func(output, validation_target).item()\n",
    "                    #ps = torch.exp(output)\n",
    "                    #equality = (validation_target[0].data == ps.max(dim=1)[1])\n",
    "                    #accuracy += equality.type(torch.FloatTensor).mean()    \n",
    "                    print('valid_loss: ', valid_loss)\n",
    "                    \n",
    "                    # print statistics\n",
    "                running_loss += valid_loss\n",
    "                if epoch % 100 == 0: \n",
    "                    print('average loss: %.6f' %(running_loss))\n",
    "                    running_loss = 0.0\n",
    "                   \n",
    "            train_losses = []\n",
    "            early_stopping(valid_loss, cnn)\n",
    "        \n",
    "            if early_stopping.early_stop:\n",
    "                if os.path.exists('checkpoint.pt'):\n",
    "                    #cnn = TheModelClass(*args, **kwargs)\n",
    "                    print(\"Loaded the model with the lowest Validation Loss!\")\n",
    "                    cnn.load_state_dict(torch.load('checkpoint.pt'))  # Choose whatever GPU device number you want\n",
    "                    cnn.to(device)\n",
    "                break\n",
    "      \n",
    "        cnn.eval()\n",
    "        class_correct = list(0. for i in range(1000))\n",
    "        class_total = list(0. for i in range(1000))\n",
    "        with torch.no_grad():\n",
    "            for (test_data, test_target) in test_loader:\n",
    "                test_data, test_target = test_data.to(device), test_target.to(device)\n",
    "                outputs, temp = cnn(test_data)\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                c = (predicted == test_target).squeeze()\n",
    "                for i in range(test_target.size(0)):\n",
    "                    label = test_target[i]\n",
    "                    class_correct[label] += c[i].item()\n",
    "                    class_total[label] += 1\n",
    "\n",
    "        for i in range(dataset.CLASSES):\n",
    "            TEST_RESULTS[0,i] = class_correct[i] / dataset.TESTED_ELEMENTS[i]\n",
    "            print('Class: ',i,' accuracy: ', TEST_RESULTS[0,i])   \n",
    "            print('Class: ',i,' correct: ', class_correct[i],' of ',dataset.TESTED_ELEMENTS[i])\n",
    "        percent = (TEST_RESULTS[0,0]+TEST_RESULTS[0,1])/2\n",
    "        print('Final percentage: ',percent)\n",
    "    \n",
    "        CreditCost = int((1 - TEST_RESULTS[0,0]) * dataset.TESTED_ELEMENTS[0] + (1 - TEST_RESULTS[0,1]) * dataset.TESTED_ELEMENTS[1] * 5)\n",
    "        \n",
    "        if TEST_RESULTS[0,0] == 0 or TEST_RESULTS[0,1] == 0 :\n",
    "            CreditCost = CreditCost + 300\n",
    "    \n",
    "        print('Last epoch: ', epoch)\n",
    "        print('Credit Cost: ',-CreditCost)\n",
    "        #list(cnn.parameters())\n",
    "    \n",
    "        if os.path.exists('checkpoint.pt'):  \n",
    "            os.remove('checkpoint.pt') \n",
    "\n",
    "        print()\n",
    "        \n",
    "        \n",
    "        print()\n",
    "        \n",
    "        if -CreditCost > MaxCredit : \n",
    "            MaxCredit = -CreditCost\n",
    "        print('Best Score So Far: ',MaxCredit)    \n",
    "        \n",
    "        return -CreditCost\n",
    "    \n",
    "    \n",
    "    optimizer = BayesianOptimization(\n",
    "        f=objective,\n",
    "        #pbounds=pbounds,\n",
    "        pbounds={'SCI_RELU': (1,2.99), \n",
    "                 'SCI_BIAS': (1,2.99), \n",
    "                 'SCI_loss_type': (1, 3.99), \n",
    "                 'SCI_optimizer': (1, 6.99),\n",
    "                 'SCI_LR': (0.01, 0.4), \n",
    "                 'SCI_MM': (0.001, 0.999), \n",
    "                 'SCI_REGULARIZATION': (0.0001, 0.7), \n",
    "                 'SCI_EPOCHS': (1000, 2000), \n",
    "                 'SCI_BATCH_SIZE': (4, 128), \n",
    "                 'SCI_DROPOUT': (0, 0.3), \n",
    "                 'SCI_L_SECOND': (2, 32), \n",
    "                 'SCI_BN_MOMENTUM': (0, 0.99), \n",
    "                 'SCI_SGD_MOMENTUM': (0, 0.99), \n",
    "                 'SCI_LINEARITY': (1,3.99)},\n",
    "        verbose=2, # verbose = 1 prints only when a maximum is observed, verbose = 0 is silent\n",
    "        random_state=1,\n",
    "    )\n",
    "        \n",
    "\n",
    "    #optimizer.maximize(\n",
    "        #n_iter=TRIALS, acq=\"ucb\", kappa=0.1\n",
    "    #)\n",
    "    \n",
    "    \n",
    "    optimizer.maximize(\n",
    "        init_points = RANDOM_STARTS,\n",
    "        n_iter = TRIALS,\n",
    "    )\n",
    "    \n",
    "    \n",
    "    print(optimizer.max)\n",
    "    \n",
    "    for i, res in enumerate(optimizer.res):\n",
    "        print(\"Iteration {}: \\n\\t{}\".format(i, res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if OPTIMIZATION_PLUGIN == 'GradDescent' :\n",
    "    import pandas as pd\n",
    "    import matplotlib.pyplot as plt\n",
    "    import torch\n",
    "    import torch.optim as optim\n",
    "    from torch.autograd import Variable\n",
    "  \n",
    "\n",
    "   \n",
    "    #CI_LR = torch.randn(1).detach().requires_grad_(True)\n",
    "    SCI_LR = 0.35\n",
    "    SCI_REGULARIZATION = 0.03\n",
    "    SCI_EPOCHS = 200\n",
    "    #SCI_optimizer = 'Adam'\n",
    "    SCI_loss_type = 'CrossEntropyLoss'\n",
    "    SCI_RELU = 'True'\n",
    "    SCI_BIAS = 'True'\n",
    "    #SCI_L_SECOND = 48\n",
    "    SCI_BN_MOMENTUM = 0.1\n",
    "\n",
    "    SCI_SGD_MOMENTUM = torch.rand(1, requires_grad=True)\n",
    "    print('SCI_SGD_MOMENTUM: ', SCI_SGD_MOMENTUM)\n",
    "    SCI_BATCH_SIZE   = torch.randint(2, 128, (1,1), dtype=torch.float, requires_grad=True) \n",
    "    print('SCI_BATCH_SIZE: ',SCI_BATCH_SIZE)\n",
    "    SCI_L_SECOND   = torch.randint(2, 64, (1,1), dtype=torch.float, requires_grad=True) \n",
    "    print('SCI_L_SECOND: ',SCI_L_SECOND)\n",
    "    SCI_optimizer   = torch.randint(1, 6, (1,1), dtype=torch.float, requires_grad=True) \n",
    "    print('SCI_optimizer: ',SCI_optimizer)    \n",
    "    SCI_DROPOUT      = torch.rand(1, requires_grad=True)    \n",
    "    print('SCI_DROPOUT: ',SCI_DROPOUT)   \n",
    "    \n",
    "\n",
    "    def objective(SCI_SGD_MOMENTUM, SCI_DROPOUT, SCI_BATCH_SIZE, SCI_L_SECOND, SCI_optimizer):\n",
    "        global SCI_REGULARIZATION, SCI_EPOCHS, SCI_loss_type, SCI_RELU\n",
    "        global SCI_BIAS, SCI_BN_MOMENTUM, device, SCI_LR, MaxCredit\n",
    "        \n",
    "        SCI_SGD_MOMENTUM = SCI_SGD_MOMENTUM/10\n",
    "        DROPOUT = (SCI_DROPOUT/2).item()\n",
    "        if SCI_DROPOUT < 0 :\n",
    "            DROPOUT = 0\n",
    "\n",
    "        BATCH_SIZE = int(SCI_BATCH_SIZE)\n",
    "        \n",
    "        if SCI_L_SECOND < 4 :\n",
    "            SCI_L_SECOND = 4\n",
    "            \n",
    "        if SCI_optimizer < 1 :\n",
    "            SCI_optimizer = 1\n",
    "        \n",
    "        L_SECOND = int(SCI_L_SECOND)\n",
    "        \n",
    "        loss_func = nn.CrossEntropyLoss()\n",
    "\n",
    "        def create_loss(LOSS):   \n",
    "            if LOSS == 'CrossEntropyLoss':\n",
    "                loss_func = nn.CrossEntropyLoss()\n",
    "            if LOSS == 'NLLLoss':\n",
    "                loss_func = nn.NLLLoss()\n",
    "            else:\n",
    "                loss_func = nn.MultiMarginLoss()\n",
    "            return loss_func\n",
    "\n",
    "\n",
    "        REGULARIZATION = float(str(SCI_REGULARIZATION))\n",
    "        optimizer1 = str(SCI_optimizer)\n",
    "\n",
    "        from cnn_model import CNN6      \n",
    "        cnn = CNN6(L_FIRST, L_SECOND, KERNEL_X, SCI_BIAS, SCI_BN_MOMENTUM, SCI_RELU, DROPOUT, dataset.CLASSES)     \n",
    "    \n",
    "        if GPU_SELECT == 2:\n",
    "            if torch.cuda.device_count() > 1:\n",
    "                cnn = nn.DataParallel(cnn,device_ids=[0, 1], dim=0) \n",
    "            cnn = cnn.cuda()\n",
    "        if GPU_SELECT == 1:\n",
    "            cnn.to(device)  \n",
    "        if GPU_SELECT == 0:\n",
    "            cnn.to(device)        \n",
    "\n",
    "        cnn.apply(CNN6.weights_reset)\n",
    "        cnn.share_memory()\n",
    "\n",
    "\n",
    "        train_losses = []         # to track the training loss as the model trains\n",
    "        output = 0\n",
    "        loss = 0\n",
    "        accuracy = 0\n",
    "        early_stopping.counter = 0\n",
    "        early_stopping.best_score = None\n",
    "        early_stopping.early_stop = False\n",
    "        early_stopping.verbose = False  \n",
    "        TEST_RESULTS = torch.zeros(1,2)\n",
    "\n",
    "    \n",
    "        loss_type = create_loss(SCI_loss_type)\n",
    "        \n",
    "        from adamw import AdamW\n",
    "        \n",
    "        \n",
    "        if optimizer1 == '1':\n",
    "            optimizer = optim.Adam(cnn.parameters(), lr=SCI_LR, betas=(0.9, 0.99), weight_decay=REGULARIZATION)\n",
    "        if optimizer1 == '2':\n",
    "            optimizer = optim.Adam(cnn.parameters(), lr=SCI_LR, betas=(0.9, 0.99), weight_decay=REGULARIZATION, amsgrad=True)\n",
    "        if optimizer1 == '3':\n",
    "            optimizer = AdamW(cnn.parameters(), lr=SCI_LR, betas=(0.9, 0.99), weight_decay = REGULARIZATION)            \n",
    "        if optimizer1 == '4':\n",
    "            optimizer = optim.SGD(cnn.parameters(), lr=SCI_LR, momentum=SCI_SGD_MOMENTUM, weight_decay=REGULARIZATION)\n",
    "        if optimizer1 == '5':\n",
    "            optimizer = optim.Adadelta(cnn.parameters(), lr=SCI_LR, weight_decay=REGULARIZATION)\n",
    "        if optimizer1 == '6':\n",
    "            optimizer = optim.Adagrad(cnn.parameters(), lr=SCI_LR, weight_decay=REGULARIZATION)\n",
    "        if optimizer1  > '6':           \n",
    "            optimizer = optim.Adam(cnn.parameters(), lr=SCI_LR, betas=(0.9, 0.99), weight_decay=REGULARIZATION)\n",
    "\n",
    "    \n",
    "        from Utillities import Utillities\n",
    "        Utillities.listing(optimizer, SCI_SGD_MOMENTUM, SCI_BN_MOMENTUM, L_SECOND, SCI_LR, SCI_RELU, SCI_BIAS, SCI_loss_type, REGULARIZATION, BATCH_SIZE, DROPOUT)\n",
    "\n",
    "        train_loader = Data.DataLoader(dataset = dataset.train_dataset, batch_size = BATCH_SIZE, shuffle = False, num_workers = 0, drop_last=True, pin_memory=True)\n",
    "        validation_loader = Data.DataLoader(dataset = dataset.validation_dataset, batch_size = BATCH_SIZE, shuffle = False, num_workers = 0, drop_last=True, pin_memory=True)    \n",
    "        test_loader = Data.DataLoader(dataset = dataset.test_dataset, batch_size = BATCH_SIZE, shuffle = False, num_workers = 0, pin_memory=True)\n",
    "    \n",
    "        for epoch in range(SCI_EPOCHS):\n",
    "            loss = None        \n",
    "            cnn.train().cuda()\n",
    "            for step, (train_data, train_target) in enumerate(train_loader):   \n",
    "                train_data, train_target = train_data.to(device), train_target.to(device)\n",
    "                output, temp = cnn(train_data)                # forward pass: compute predicted outputs by passing inputs to the model     \n",
    "                loss = loss_func(output, train_target)\n",
    "                train_losses.append(loss.item())              # record training loss \n",
    "                loss.backward()                               # backward pass: compute gradient of the loss with respect to model parameters\n",
    "                optimizer.zero_grad()\n",
    "                optimizer.step()                              # perform a single optimization step (parameter update)\n",
    "      \n",
    "            cnn.eval().cuda()                 # switch to evaluation (no change) mode           \n",
    "            valid_loss = 0\n",
    "            accuracy = 0\n",
    "            with torch.no_grad():\n",
    "                for step, (validation_data, validation_target) in enumerate(validation_loader):\n",
    "                    validation_data, validation_target = validation_data.to(device), validation_target.to(device)\n",
    "                    output, temp = cnn(validation_data)            # forward pass: compute predicted outputs by passing inputs to the model\n",
    "                    valid_loss += loss_func(output, validation_target).item()\n",
    "                    ps = torch.exp(output)\n",
    "                    equality = (validation_target[0].data == ps.max(dim=1)[1])\n",
    "                    accuracy += equality.type(torch.FloatTensor).mean()      \n",
    "               \n",
    "            train_losses = []\n",
    "            early_stopping(valid_loss, cnn)\n",
    "       \n",
    "            if early_stopping.early_stop:\n",
    "                if os.path.exists('checkpoint.pt'):\n",
    "                    print(\"Loaded the model with the lowest Validation Loss!\")\n",
    "                    cnn.load_state_dict(torch.load('checkpoint.pt', map_location=\"cuda:1\"))  # Choose whatever GPU device number you want\n",
    "                    cnn.to(device)\n",
    "                break\n",
    "      \n",
    "        cnn.eval()\n",
    "        class_correct = list(0. for i in range(1000))\n",
    "        class_total = list(0. for i in range(1000))\n",
    "        with torch.no_grad():\n",
    "            for (test_data, test_target) in test_loader:\n",
    "                test_data, test_target = test_data.to(device), test_target.to(device)\n",
    "                outputs, temp = cnn(test_data)\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                c = (predicted == test_target).squeeze()\n",
    "                for i in range(test_target.size(0)):\n",
    "                    label = test_target[i]\n",
    "                    class_correct[label] += c[i].item()\n",
    "                    class_total[label] += 1\n",
    "\n",
    "        for i in range(dataset.CLASSES):\n",
    "            TEST_RESULTS[0,i] = class_correct[i] / dataset.TESTED_ELEMENTS[i]\n",
    "            print('Class: ',i,' accuracy: ', TEST_RESULTS[0,i])\n",
    "            print('Class: ',i,' correct: ', class_correct[i])\n",
    "        percent = (TEST_RESULTS[0,0]+TEST_RESULTS[0,1])/2\n",
    "        print('Final percentage: ',percent)\n",
    "    \n",
    "        CreditCost = (1 - TEST_RESULTS[0,0]) * dataset.TESTED_ELEMENTS[0] + (1 - TEST_RESULTS[0,1]) * dataset.TESTED_ELEMENTS[1] * 5\n",
    "    \n",
    "        if TEST_RESULTS[0,0] == 0 or TEST_RESULTS[0,1] == 0 :\n",
    "            CreditCost = CreditCost + 300\n",
    "    \n",
    "        print('Last epoch: ', epoch)\n",
    "   \n",
    "        if os.path.exists('checkpoint.pt'):  \n",
    "            os.remove('checkpoint.pt') \n",
    "\n",
    "        print()\n",
    "        torch.cuda.empty_cache()\n",
    "        print()\n",
    "        \n",
    "        CreditCost = CreditCost + (SCI_SGD_MOMENTUM + SCI_DROPOUT + SCI_BATCH_SIZE + SCI_L_SECOND + SCI_optimizer)/1000\n",
    "        print('Credit Cost: ',CreditCost)\n",
    "        \n",
    "        \n",
    "        if -CreditCost > MaxCredit : \n",
    "            MaxCredit = -CreditCost\n",
    "        print('Best Score So Far: ',MaxCredit)   \n",
    "             \n",
    "        return CreditCost\n",
    "\n",
    "    \n",
    "    def loss(y_predicted, expected):\n",
    "        return (y_predicted - expected).sum()\n",
    "            \n",
    "    \n",
    "    expected = 300\n",
    "    \n",
    "    #optim_alg = optim.Adagrad([SCI_SGD_MOMENTUM, SCI_DROPOUT, SCI_BATCH_SIZE, SCI_L_SECOND], lr=0.01)\n",
    "    optim_alg = optim.Adam([       \n",
    "        {'params': SCI_SGD_MOMENTUM, 'lr': 1e-3},\n",
    "        {'params': SCI_DROPOUT, 'lr': 1e-2},\n",
    "        {'params': SCI_BATCH_SIZE, 'lr': 0.5},\n",
    "        {'params': SCI_L_SECOND, 'lr': 0.5},\n",
    "        {'params': SCI_optimizer, 'lr': 0.25}\n",
    "        ]) \n",
    "    \n",
    "    # Main optimization loop\n",
    "    for t in range(50):\n",
    "        optim_alg.zero_grad()\n",
    "        y_predicted = objective(SCI_SGD_MOMENTUM, SCI_DROPOUT, SCI_BATCH_SIZE, SCI_L_SECOND, SCI_optimizer)\n",
    "        current_loss = loss(y_predicted, expected)\n",
    "        current_loss.backward()\n",
    "        optim_alg.step()\n",
    "        print(f\"t = {t}, loss = {current_loss}, SCI_DROPOUT = {SCI_DROPOUT.detach().numpy()}, SCI_SGD_MOMENTUM = {SCI_SGD_MOMENTUM.item()}, SCI_BATCH_SIZE = {SCI_BATCH_SIZE.detach().numpy()}, SCI_L_SECOND = {SCI_L_SECOND.detach().numpy()}, SCI_optimizer = {SCI_optimizer.detach().numpy()}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "end.record()\n",
    "\n",
    "#print('Minimum Credit Cost: ',Min_Credit_Cost)\n",
    "\n",
    "print()\n",
    "print('Total execution time (minutes): ',start.elapsed_time(end)/60000)\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "if GET_STATS:\n",
    "    pr.disable()\n",
    "    s = io.StringIO()\n",
    "    sortby = SortKey.CUMULATIVE\n",
    "    ps = pstats.Stats(pr, stream=s).sort_stats(sortby)\n",
    "    ps.print_stats()\n",
    "    print(s.getvalue())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
