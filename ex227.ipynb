{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch Version:  1.2.0\n",
      "Torchvision Version:  0.4.0a0+6b959ee\n",
      "Using 2 NVIDIA 1080TI GPUs!\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as Data\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from torch.utils import data\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import cProfile, pstats, io\n",
    "from pstats import SortKey\n",
    "from random import randint\n",
    "from Utillities import Utillities\n",
    "from cnn_model import CNN6     \n",
    "\n",
    "\n",
    "print(\"PyTorch Version: \",torch.__version__)\n",
    "print(\"Torchvision Version: \",torchvision.__version__)\n",
    "\n",
    "if os.path.exists(\"checkpoint.pt\"):\n",
    "    os.remove(\"checkpoint.pt\")\n",
    "\n",
    "torch.manual_seed(21)   # reproducible\n",
    "\n",
    "OPTIMIZATION_PLUGIN = 'Bayesian' # 'Bayesian' or 'Scikit' or 'GradDescent'\n",
    "#Bayesian requires: $ conda install -c conda-forge bayesian-optimization\n",
    "\n",
    "GET_STATS = False\n",
    "GPU_SELECT = 2 # can be 0, 1, 2 (both)\n",
    "PARALLEL_PROCESSES = 2\n",
    "TRIALS = 500\n",
    "RANDOM_STARTS = 500\n",
    "LR  = 1e-5                    # learning rate\n",
    "SCI_LR =  1e-5\n",
    "LR2 = 1e-5\n",
    "SCI_MM = 0.5                  # momentum - used only with SGD optimizer\n",
    "MM = 0.5\n",
    "L_FIRST = 24                  # initial number of channels\n",
    "KERNEL_X = 24\n",
    "patience = 21                 # if validation loss not going down, wait \"patience\" number of epochs\n",
    "accuracy = 0\n",
    "MaxCredit = -800\n",
    "\n",
    "CreditVector = np.zeros(RANDOM_STARTS + TRIALS)\n",
    "CreditVector = CreditVector - 800\n",
    "CreditVec = np.zeros(RANDOM_STARTS + TRIALS)\n",
    "count = 0\n",
    "\n",
    "pr = cProfile.Profile()\n",
    "\n",
    "if GET_STATS:\n",
    "    pr.enable()\n",
    "    \n",
    "\n",
    "if GPU_SELECT == 2:\n",
    "    if torch.cuda.device_count() > 1:\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        print(\"Using\", torch.cuda.device_count(), \"NVIDIA 1080TI GPUs!\")\n",
    "\n",
    "if GPU_SELECT == 1:\n",
    "    device = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")    \n",
    "    print(\"Using one (the second) NVIDIA 1080TI GPU!\")\n",
    "\n",
    "if GPU_SELECT == 0:\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")       \n",
    "    print(\"Using one (the first) NVIDIA 1080TI GPU!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from early_stopping import EarlyStopping\n",
    "from dataset import dataset\n",
    "\n",
    "\n",
    "early_stopping = EarlyStopping(patience=patience, verbose=True)  # initialize the early_stopping object\n",
    "\n",
    "# Counter for the execution time\n",
    "start = torch.cuda.Event(enable_timing=True)\n",
    "end = torch.cuda.Event(enable_timing=True)\n",
    "\n",
    "start.record()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if OPTIMIZATION_PLUGIN == 'Scikit' :\n",
    "    from skopt import gp_minimize\n",
    "    from sklearn.datasets import load_boston\n",
    "    from sklearn.ensemble import GradientBoostingRegressor\n",
    "    from sklearn.model_selection import cross_val_score\n",
    "    from skopt.space import Real, Integer\n",
    "    from skopt.utils import use_named_args\n",
    "    from skopt.plots import plot_convergence\n",
    "    from functools import partial\n",
    "    from skopt.plots import plot_evaluations\n",
    "    from skopt import gp_minimize, forest_minimize, dummy_minimize, gbrt_minimize\n",
    "    from skopt.plots import plot_objective\n",
    "    from sklearn.preprocessing import LabelEncoder\n",
    "    #from sklearn.preprocessing import CategoricalEncoder\n",
    "    from skopt.space import Real, Categorical, Integer\n",
    "    from sklearn.externals.joblib import Parallel, delayed\n",
    "\n",
    "    #SCI_LR = Categorical(categories=[1e-1, 3e-1, 5e-1, 7e-1, 1e-2, 3e-2, 5e-2, 7e-2, 1e-3, 3e-3, 5e-3, 7e-3, 1e-4, 3e-4, 0.1, 0.2, 0.3, 0.01, 0.02, 0.03, 0.04, 0.05, 0.06, 0.07, 0.08, 0.09, 0.001, 0.0001, 1e-5],name= 'SCI_LR')\n",
    "    SCI_LR = Categorical(categories=[1e-1, 3e-1, 5e-1, 7e-1, 0.1, 0.11, 0.12, 0.13, 0.14, 0.15, 0.16, 0.17, 0.18, 0.19, 0.2, 0.21, 0.22, 0.23, 0.24, 0.25, 0.26, 0.27, 0.28, 0.29, 0.3, 0.31, 0.32, 0.33, 0.34, 0.35, 0.36, 0.37, 0.38, 0.08, 0.09],name= 'SCI_LR')\n",
    "    SCI_MM = Categorical(categories=[0.001, 0.01, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 0.99, 0.999], name='SCI_MM')\n",
    "    SCI_REGULARIZATION = Categorical(categories=[0.0001, 0.0003, 0.0007, 0.001, 0.003, 0.007, 0.01, 0.03, 0.07, 0.1, 0.3, 0.7], name='SCI_REGULARIZATION')\n",
    "    SCI_EPOCHS = Categorical(categories=[2000, 1000], name='SCI_EPOCHS')\n",
    "    SCI_optimizer = Categorical(categories=['Adam', 'Adadelta', 'SGD', 'Adagrad', 'AMSGrad', 'AdamW'],name='SCI_optimizer') #\n",
    "    SCI_loss_type = Categorical(categories=['CrossEntropyLoss', 'MultiMarginLoss','NLLLoss'],name='SCI_loss_type') # \n",
    "    SCI_BATCH_SIZE = Categorical(categories=[4, 8, 12, 16, 24, 32, 48, 64, 96, 128, 160, 192, 224, 256], name='SCI_BATCH_SIZE')\n",
    "    SCI_DROPOUT = Categorical(categories=[0, 0.01, 0.03, 0.07, 0.1, 0.13, 0.17, 0.2, 0.23, 0.27, 0.3, 0.33, 0.37, 0.4] , name = 'SCI_DROPOUT')\n",
    "    SCI_RELU = Categorical(categories=['True', 'False'] , name = 'SCI_RELU')\n",
    "    SCI_BIAS = Categorical(categories=['True', 'False'] , name = 'SCI_BIAS')\n",
    "    SCI_L_SECOND = Categorical(categories=[2, 4, 6, 8, 12, 16, 20, 24, 32, 48, 64], name='SCI_L_SECOND')\n",
    "    SCI_BN_MOMENTUM = Categorical(categories=[0, 0.01, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 0.99] , name = 'SCI_BN_MOMENTUM') \n",
    "    SCI_SGD_MOMENTUM = Categorical(categories=[0, 0.01, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 0.99] , name = 'SCI_SGD_MOMENTUM') \n",
    "    SCI_LINEARITY = Categorical(categories=[1, 2],name= 'SCI_LINEARITY')\n",
    "    \n",
    "    dimensions = [SCI_BATCH_SIZE, SCI_MM, SCI_REGULARIZATION, SCI_optimizer, SCI_LR, SCI_loss_type, SCI_DROPOUT, SCI_RELU, SCI_BIAS, SCI_L_SECOND, SCI_EPOCHS, SCI_BN_MOMENTUM, SCI_SGD_MOMENTUM, SCI_LINEARITY]\n",
    "\n",
    "    @use_named_args(dimensions = dimensions)\n",
    "\n",
    "    def objective(SCI_BATCH_SIZE, SCI_MM, SCI_REGULARIZATION, SCI_optimizer, SCI_LR, SCI_loss_type, SCI_DROPOUT, SCI_RELU, SCI_BIAS, SCI_L_SECOND, SCI_EPOCHS, SCI_BN_MOMENTUM, SCI_SGD_MOMENTUM, SCI_LINEARITY):\n",
    "        global device  \n",
    "\n",
    "        loss_func = nn.CrossEntropyLoss()\n",
    "\n",
    "        def create_loss(LOSS):   \n",
    "            if LOSS == 'CrossEntropyLoss':\n",
    "                loss_func = nn.CrossEntropyLoss()\n",
    "            if LOSS == 'NLLLoss':\n",
    "                loss_func = nn.NLLLoss()\n",
    "            else:\n",
    "                loss_func = nn.MultiMarginLoss()\n",
    "            return loss_func\n",
    "\n",
    "        MM = float(str(SCI_MM))\n",
    "        REGULARIZATION = float(str(SCI_REGULARIZATION))\n",
    "        optimizer = str(SCI_optimizer)\n",
    "        LR = float(str(SCI_LR))\n",
    "        train_losses = []         # to track the training loss as the model trains\n",
    "        output = 0\n",
    "        loss = 0\n",
    "        accuracy = 0\n",
    "        early_stopping.counter = 0\n",
    "        early_stopping.best_score = None\n",
    "        early_stopping.early_stop = False\n",
    "        early_stopping.verbose = False  \n",
    "        TEST_RESULTS = torch.zeros(1,2)\n",
    "\n",
    "    \n",
    "        loss_type = create_loss(SCI_loss_type)\n",
    "        \n",
    "        \n",
    "        \n",
    "        from cnn_model import CNN6      \n",
    "        cnn = CNN6(L_FIRST, SCI_L_SECOND, KERNEL_X, SCI_BIAS, SCI_BN_MOMENTUM, SCI_RELU, SCI_DROPOUT, dataset.CLASSES, SCI_LINEARITY)     \n",
    "    \n",
    "        if GPU_SELECT == 2:\n",
    "            if torch.cuda.device_count() > 1:\n",
    "                cnn = nn.DataParallel(cnn,device_ids=[0, 1], dim=0) \n",
    "            cnn = cnn.cuda()\n",
    "        if GPU_SELECT == 1:\n",
    "            cnn.to(device)  \n",
    "        if GPU_SELECT == 0:\n",
    "            cnn.to(device)        \n",
    "\n",
    "        cnn.apply(CNN6.weights_reset)\n",
    "        cnn.share_memory()\n",
    "     \n",
    "\n",
    "        \n",
    "        from adamw import AdamW\n",
    "        \n",
    "        \n",
    "        if SCI_optimizer == 'Adam':\n",
    "            optimizer = optim.Adam(cnn.parameters(), lr=LR, betas=(0.9, 0.99), weight_decay=REGULARIZATION)\n",
    "        if SCI_optimizer == 'AMSGrad':\n",
    "            optimizer = optim.Adam(cnn.parameters(), lr=LR, betas=(0.9, 0.99), weight_decay=REGULARIZATION, amsgrad=True)\n",
    "        if SCI_optimizer == 'AdamW':\n",
    "            optimizer = AdamW(cnn.parameters(), lr=LR, betas=(0.9, 0.99), weight_decay = REGULARIZATION)            \n",
    "        if SCI_optimizer == 'SGD':\n",
    "            optimizer = optim.SGD(cnn.parameters(), lr=LR, momentum=SCI_SGD_MOMENTUM, weight_decay=REGULARIZATION)\n",
    "        if SCI_optimizer == 'Adadelta':\n",
    "            optimizer = optim.Adadelta(cnn.parameters(), lr=LR, weight_decay=REGULARIZATION)\n",
    "        if SCI_optimizer == 'Adagrad':\n",
    "            optimizer = optim.Adagrad(cnn.parameters(), lr=LR, weight_decay=REGULARIZATION)\n",
    "    \n",
    "        from Utillities import Utillities\n",
    "        Utillities.listing(optimizer, SCI_SGD_MOMENTUM, SCI_BN_MOMENTUM, SCI_L_SECOND, SCI_LR, SCI_RELU, SCI_BIAS, SCI_loss_type, REGULARIZATION, SCI_BATCH_SIZE, SCI_DROPOUT, SCI_LINEARITY)\n",
    "    \n",
    "        #SCI_BATCH_SIZE = 1\n",
    "        # Data Loader for easy mini-batch return in training\n",
    "        SCI_BATCH_SIZE = int(SCI_BATCH_SIZE)\n",
    "        train_loader = Data.DataLoader(dataset = dataset.train_dataset, batch_size = SCI_BATCH_SIZE, shuffle = False, num_workers = 0, drop_last=True, pin_memory=True)\n",
    "        validation_loader = Data.DataLoader(dataset = dataset.validation_dataset, batch_size = SCI_BATCH_SIZE, shuffle = False, num_workers = 0, drop_last=True, pin_memory=True)    \n",
    "        test_loader = Data.DataLoader(dataset = dataset.test_dataset, batch_size = SCI_BATCH_SIZE, shuffle = False, num_workers = 0, pin_memory=True)\n",
    "    \n",
    "        for epoch in range(SCI_EPOCHS):\n",
    "            loss = None        \n",
    "            cnn.train().cuda()\n",
    "            for step, (train_data, train_target) in enumerate(train_loader):   \n",
    "                train_data, train_target = train_data.to(device), train_target.to(device)\n",
    "                output, temp = cnn(train_data)                # forward pass: compute predicted outputs by passing inputs to the model     \n",
    "                loss = loss_func(output, train_target)\n",
    "                train_losses.append(loss.item())              # record training loss \n",
    "                loss.backward()                               # backward pass: compute gradient of the loss with respect to model parameters\n",
    "                optimizer.zero_grad()\n",
    "                optimizer.step()                              # perform a single optimization step (parameter update)\n",
    "      \n",
    "            cnn.eval().cuda()                 # switch to evaluation (no change) mode           \n",
    "            valid_loss = 0\n",
    "            accuracy = 0\n",
    "            with torch.no_grad():\n",
    "                for step, (validation_data, validation_target) in enumerate(validation_loader):\n",
    "                    validation_data, validation_target = validation_data.to(device), validation_target.to(device)\n",
    "                    output, temp = cnn(validation_data)            # forward pass: compute predicted outputs by passing inputs to the model\n",
    "                    valid_loss += loss_func(output, validation_target).item()\n",
    "                    #ps = torch.exp(output)\n",
    "                    #equality = (validation_target[0].data == ps.max(dim=1)[1])\n",
    "                    #accuracy += equality.type(torch.FloatTensor).mean()      \n",
    "               \n",
    "            train_losses = []\n",
    "            early_stopping(valid_loss, cnn)\n",
    "       \n",
    "            if early_stopping.early_stop:\n",
    "                if os.path.exists('checkpoint.pt'):\n",
    "                    print(\"Loaded the model with the lowest Validation Loss!\")\n",
    "                    #nn.load_state_dict(torch.load('checkpoint.pt', map_location=\"cuda:1\"))  # Choose whatever GPU device number you want\n",
    "                    cnn.load_state_dict(torch.load('checkpoint.pt', map_location=\"cuda:1\"))  # Choose whatever GPU device number you want\n",
    "                    cnn.to(device)\n",
    "                break\n",
    "      \n",
    "        cnn.eval()\n",
    "        class_correct = list(0. for i in range(1000))\n",
    "        class_total = list(0. for i in range(1000))\n",
    "        with torch.no_grad():\n",
    "            for (test_data, test_target) in test_loader:\n",
    "                test_data, test_target = test_data.to(device), test_target.to(device)\n",
    "                outputs, temp = cnn(test_data)\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                c = (predicted == test_target).squeeze()\n",
    "                for i in range(test_target.size(0)):\n",
    "                    label = test_target[i]\n",
    "                    class_correct[label] += c[i].item()\n",
    "                    class_total[label] += 1\n",
    "\n",
    "        for i in range(dataset.CLASSES):\n",
    "            TEST_RESULTS[0,i] = class_correct[i] / dataset.TESTED_ELEMENTS[i]\n",
    "            print('Class: ',i,' accuracy: ', TEST_RESULTS[0,i])\n",
    "            print('Class: ',i,' correct: ', class_correct[i])\n",
    "        percent = (TEST_RESULTS[0,0]+TEST_RESULTS[0,1])/2\n",
    "        print('Final percentage: ',percent)\n",
    "    \n",
    "        CreditCost = int((1 - TEST_RESULTS[0,0]) * dataset.TESTED_ELEMENTS[0] + (1 - TEST_RESULTS[0,1]) * dataset.TESTED_ELEMENTS[1] * 5)\n",
    "    \n",
    "        if TEST_RESULTS[0,0] == 0 or TEST_RESULTS[0,1] == 0 :\n",
    "            CreditCost = CreditCost + 300\n",
    "    \n",
    "        print('Last epoch: ', epoch)\n",
    "        print('Credit Cost: ',CreditCost)\n",
    "    \n",
    "        if os.path.exists('checkpoint.pt'):  \n",
    "            os.remove('checkpoint.pt') \n",
    "\n",
    "        print()\n",
    "        torch.cuda.empty_cache()\n",
    "        print()\n",
    "        \n",
    "        return CreditCost\n",
    "    \n",
    "    #not working #res_gp = gp_minimize(objective, dimensions=dimensions, n_calls=TRIALS, random_state=1, verbose=True, acq_func='gp_hedge', acq_optimizer='auto', n_jobs=1)\n",
    "    res_gp = forest_minimize(objective, dimensions=dimensions, base_estimator='RF', n_calls=TRIALS, n_random_starts=RANDOM_STARTS, acq_func='EI', x0=None, y0=None, random_state=None, verbose=True, callback=None, n_points=10000, xi=0.01, kappa=1.5, n_jobs=4)\n",
    "    #res_gp = gbrt_minimize(objective, dimensions=dimensions, base_estimator='ET', n_calls=TRIALS+RANDOM_STARTS, n_random_starts=RANDOM_STARTS, acq_func='LCB', x0=None, y0=None, random_state=None, verbose=True, callback=None, n_points=100, xi=0.01, kappa=1.96, n_jobs=1)\n",
    "    #res_gp = dummy_minimize(objective, dimensions=dimensions, n_calls=TRIALS, x0=None, y0=None, random_state=None, verbose=True, callback=None)      \n",
    "\n",
    "    \"Best score=%.4f\" % res_gp.fun\n",
    "    print(\"\"\"Best parameters: - optimization=%d\"\"\" % (res_gp.x[0]))\n",
    "  \n",
    "    print(res_gp)\n",
    "    plot_convergence(res_gp)\n",
    "    #plot_evaluations(res_gp)\n",
    "    #plot_objective(res_gp)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   | SCI_BA... | SCI_BIAS  | SCI_BN... | SCI_DR... | SCI_EP... | SCI_LI... |  SCI_LR   | SCI_L_... |  SCI_MM   | SCI_RE... | SCI_RELU  | SCI_SG... | SCI_lo... | SCI_op... |\n",
      "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "SCI_optimizer:  8.894275753154599\n",
      "<class 'numpy.float64'>\n",
      "Optimization:  Adamax (\n",
      "Parameter Group 0\n",
      "    betas: (0.9, 0.999)\n",
      "    eps: 1e-08\n",
      "    lr: 0.08264\n",
      "    weight_decay: 0.3772178321289495\n",
      ")\n",
      "Batch Normalization Momentum:  0.0\n",
      "Nodes:  12\n",
      "LR:  0.08264\n",
      "RELU:  True\n",
      "BIAS:  False\n",
      "Loss Type:  1\n",
      "REGULARIZATION:  0.3772178321289495\n",
      "BATCH_SIZE:  55\n",
      "Dropout:  0.09\n",
      "Final Linear Layers:  1\n",
      "average loss: 0.689365\n",
      "Class:  0  accuracy:  tensor(0.6994)\n",
      "Class:  0  correct:  349.0  of  tensor(499.)\n",
      "Class:  1  accuracy:  tensor(0.2800)\n",
      "Class:  1  correct:  28.0  of  tensor(100.)\n",
      "Final percentage:  tensor(0.4897)\n",
      "Last epoch:  21\n",
      "Credit Cost:  -510\n",
      "\n",
      "\n",
      "Best Score So Far:  -510\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m 1       \u001b[0m | \u001b[0m-510.0   \u001b[0m | \u001b[0m 55.71   \u001b[0m | \u001b[0m 2.433   \u001b[0m | \u001b[0m 0.000113\u001b[0m | \u001b[0m 0.0907  \u001b[0m | \u001b[0m 1.147e+0\u001b[0m | \u001b[0m 1.276   \u001b[0m | \u001b[0m 0.08264 \u001b[0m | \u001b[0m 12.37   \u001b[0m | \u001b[0m 0.397   \u001b[0m | \u001b[0m 0.3772  \u001b[0m | \u001b[0m 1.834   \u001b[0m | \u001b[0m 0.6784  \u001b[0m | \u001b[0m 1.611   \u001b[0m | \u001b[0m 8.894   \u001b[0m |\n",
      "SCI_optimizer:  1.3511025012636124\n",
      "<class 'numpy.float64'>\n",
      "Optimization:  Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.99)\n",
      "    eps: 1e-08\n",
      "    lr: 0.32229\n",
      "    weight_decay: 0.4846565987069529\n",
      ")\n",
      "Batch Normalization Momentum:  0.41\n",
      "Nodes:  31\n",
      "LR:  0.32229\n",
      "RELU:  False\n",
      "BIAS:  False\n",
      "Loss Type:  1\n",
      "REGULARIZATION:  0.4846565987069529\n",
      "BATCH_SIZE:  7\n",
      "Dropout:  0.17\n",
      "Final Linear Layers:  1\n",
      "average loss: 0.692342\n",
      "Class:  0  accuracy:  tensor(0.3567)\n",
      "Class:  0  correct:  178.0  of  tensor(499.)\n",
      "Class:  1  accuracy:  tensor(0.5300)\n",
      "Class:  1  correct:  53.0  of  tensor(100.)\n",
      "Final percentage:  tensor(0.4434)\n",
      "Last epoch:  21\n",
      "Credit Cost:  -556\n",
      "\n",
      "\n",
      "Best Score So Far:  -510\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD4CAYAAAAXUaZHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjAsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+17YcXAAAgAElEQVR4nO3dd3hUZfr/8fedhARCLwGRXgKIdCKdZJWOCogNGxYUVJCSbfpzd7+u666urqGIoqCo6CoogqLS1U3oEDpEQHqHUKQIUp/fHxl2oyKZQCYnM/m8rmuuOfPMMzP3Q8KHw5kz95hzDhERCS1hXhcgIiI5T+EuIhKCFO4iIiFI4S4iEoIU7iIiISjC6wIAypQp46pWrep1GSIiQWXp0qUHnHMxF7svT4R71apVSU1N9boMEZGgYmbbfu0+HZYREQlBCncRkRCkcBcRCUEKdxGREKRwFxEJQX6Fu5kNMbO1ZrbGzD40s4JmVs3MFpnZd2Y2wcwifXOjfLc3+u6vGsgFiIjIL2UZ7mZWARgIxDnn6gHhQC/gn8BQ51wscBjo43tIH+Cwc64mMNQ3T0REcpG/h2UigEJmFgFEA3uAG4CJvvvfBXr4trv7buO7v52ZWc6U+1MHj5/i2c/TOPrjmUA8vYhI0Moy3J1zu4B/AdvJCPUjwFLge+fcWd+0nUAF33YFYIfvsWd980v//HnNrK+ZpZpZanp6+mUVP2/TQd6Zv4UOScnMTtt3Wc8hIhKK/DksU5KMvfFqwNVAYaDLRaZe+NaPi+2l/+IbQZxzo51zcc65uJiYi356NkvdGl7N5MdbUzI6kofHpTLww+UcPH7qsp5LRCSU+HNYpj2wxTmX7pw7A0wCWgElfIdpACoCu33bO4FKAL77iwOHcrTqTBpWKsGUAW0Y0r4W09bsoX1SMp+t2IW+YUpE8jN/wn070MLMon3HztsBacA3wG2+OfcDn/m2p/hu47v/axfgpI2MCGNQ+1i+HNiWKqULM2j8Cvq8m8ru708G8mVFRPIs8yd3zeyvwJ3AWWA58DAZx9bHA6V8Y/c6506ZWUHgPaAxGXvsvZxzmy/1/HFxcS6nGoedO+94e94W/jVzPRFhYTzVtQ53XVeZsLCAvKcrIuIZM1vqnIu76H154fBFTob7BdsPnuDJSauYv+kgzauV4oVbG1CtTOEcfQ0RES9dKtxD9hOqlUtH8++Hm/NCz/qk7T5K52EpjE7ZxNlz570uTUQk4EI23AHMjF7NKjMrMYG2sTH8Y+o6eo6az7d7jnpdmohIQIV0uF9wVfGCjOndlJF3N2bX4ZPc/Mpckmau59TZc16XJiISEPki3CFjL/6mBlczOzGBmxtezYivN3LTiLks237Y69JERHJcvgn3C0oWjmTonY14+4HrOH7qLLeOms+zn6dx4vTZrB8sIhIk8l24X3B9nbLMHBLPPc0rM3beFjoNS2HexgNelyUikiPybbgDFC1YgOd61GdC3xZEhIVxz5uL+OPEVRw5qUZkIhLc8nW4X9C8emmmDWrLowk1mLhsJx2Skpm5dq/XZYmIXDaFu0/BAuE82aUOnz7emtJFouj73lL6f7CM9GNqRCYiwUfh/jP1KxZnyoDW/K5jLWat3UeHoclMWrZTjchEJKgo3C+iQHgYA26IZeqgNlQvU5jEj1by4DtL2KVGZCISJBTul1CzbFE+frQV/3dzXRZtPkTHpGTeW7CV8+e1Fy8ieZvCPQvhYcaDrasxc0g8TaqU5M+fraXX6IVsTj/udWkiIr9K4e6nSqWiGfdQM166rQHr9h6l8/A5jPqPGpGJSN6kcM8GM+P2uErMTkzg+tox/HP6Onq8No+1u494XZqIyE8o3C9D2WIFeeO+OEbd04S9R07RbeQ8Xpqxjh/PqBGZiOQNCvcr0KV+eWYnxtOjUQVe/WYTN46Yw9JtAfu6WBERvyncr1CJ6EhevqMh7z7UjB/PnOe21xfwzJS1/HBKjchExDsK9xySUCuGGUPi6d2iCu8u2ErHoSmkbEj3uiwRyacU7jmoSFQEf+1ej4/6tSSqQBi9xy7mdx+v5MgJNSITkdylcA+A66qWYurAtjz+mxpMXr6L9kOTmb5mj9dliUg+onAPkIIFwvlD5zp81r81MUWiePT9ZTz2/lL2H/vR69JEJB9QuAdYvQrF+WxAa37fqTZfrdtPh6QUPk7doUZkIhJQCvdcUCA8jP7X12TqwLbEli3C7yeuovfYxew4dMLr0kQkRCncc1HNskX4qF9Lnu1+Lcu2HabTsBTembdFjchEJMdlGe5mVtvMVmS6HDWzwWb2jJntyjTeNdNjnjKzjWa23sw6BXYJwSUszOjdsiozhsQTV7UUz3yexh1vLGDjfjUiE5GcY9k59mtm4cAuoDnwIHDcOfevn82pC3wINAOuBmYDtZxzv/rZ/Li4OJeampr96oOcc45Jy3bx7BdpnDx9jkHtY+kbX50C4foPlYhkzcyWOufiLnZfdlOkHbDJObftEnO6A+Odc6ecc1uAjWQEvfyMmXFr04rMTkygfd2yvDRjPd1HzmPNLjUiE5Erk91w70XGXvkFA8xslZmNNbOSvrEKwI5Mc3b6xn7CzPqaWaqZpaan5+9PcsYUjeK1e5ry+r1NSD9+iu6vzuOf09WITEQun9/hbmaRQDfgY9/QKKAG0AjYA7x8YepFHv6LYz/OudHOuTjnXFxMTEy2ig5VneuVZ/aQBHo2rsCo/2yi6/A5LNmqRmQikn3Z2XPvAixzzu0DcM7tc86dc86dB8bwv0MvO4FKmR5XEdidE8XmB8WjC/DS7Q15r08zTp87z+2vL+Avn63huBqRiUg2ZCfc7yLTIRkzK5/pvluANb7tKUAvM4sys2pALLD4SgvNb9rGxjBjcDwPtq7Kewu30TEpmW/W7/e6LBEJEn6Fu5lFAx2ASZmGXzSz1Wa2CrgeGALgnFsLfASkAdOB/pc6U0Z+XeGoCP7v5muZ+GgroqMiePDtJSROWMHhH057XZqI5HHZOhUyUPLrqZDZcersOUZ+vZFR/9lEiegC/LVbPbrWvwqzi73FISL5QU6eCikeiYoI57cdazNlQBvKFy9E/w+W0e+9pew/qkZkIvJLCvcgU/fqYkx+vBVPdalD8oZ02iUl89ESNSITkZ9SuAehiPAw+iXUYNqgtlxTvhh/+GQV972lRmQi8j8K9yBWPaYI4x9pwXM96rFix/d0HJrC2LlbOKdGZCL5nsI9yIWFGfe2qMLMIfE0r16KZ79I47bX5/PdvmNelyYiHlK4h4irSxTi7QeuY9idjdh64AduHDGXEV99x+mz570uTUQ8oHAPIWZGj8YVmJWYQMdry5E0awPdRs5l1c7vvS5NRHKZwj0ElSkSxci7mzD6vqYcPnGaHq/O4/mp36oRmUg+onAPYR2vvYqZQxK487pKvJGymc7DUli4+aDXZYlILlC4h7jihQrwfM8GfPBwc8476DV6IU9PXs2xH894XZqIBJDCPZ9oVbMM0we35eE21fhw8XY6Dk3h63X7vC5LRAJE4Z6PREdG8Keb6vLJY60oEhXBQ++kMnj8cg6pEZlIyFG450ONK5fki4FtGNQuli9W7aF9UjJTVu5WCwOREKJwz6eiIsIZ0qEWXwxsQ6WShRj44XIeGbeUvUfUiEwkFCjc87k6VxVj0uOtebrrNczdmE6HpGQ+XLxde/EiQU7hLoSHGY/EV2f6oHiurVCMpyat5u4xi9h28AevSxORy6Rwl/+qWqYwHzzcgn/cUp81u47QaVgKb87ZrEZkIkFI4S4/ERZm3N28MjMT42ldowzPffktPUfNZ/1eNSITCSYKd7mo8sUL8eb9cQzv1Ygdh05w0ytzGDZ7gxqRiQQJhbv8KjOje6MKzBoST9f65Rk2+ztufmUuK3aoEZlIXqdwlyyVLhLF8F6Neev+OI6cPEPP1+bx9y/TOHlajchE8iqFu/it3TXlmJkYT69mlRkzZwudhqUwf9MBr8sSkYtQuEu2FCtYgH/cUp8PH2mBGdw9ZhFPTVrFUTUiE8lTFO5yWVrWKM30QfH0ja/OhCU76JCUzOw0NSITySsU7nLZCkWG8/+6XsPkx1tTMjqSh8el8sSHyzl4/JTXpYnke1mGu5nVNrMVmS5HzWywmZUys1lm9p3vuqRvvpnZCDPbaGarzKxJ4JchXmpYqQRTBrQhsUMtpq/JaET22YpdamEg4qEsw905t94518g51whoCpwAJgNPAl8552KBr3y3AboAsb5LX2BUIAqXvCUyIoyB7WL5cmBbqpQuzKDxK+jzbiq7vz/pdWki+VJ2D8u0AzY557YB3YF3fePvAj18292BcS7DQqCEmZXPkWolz6tVriifPNaKP99UlwWbDtJxaArvL9zGebUwEMlV2Q33XsCHvu1yzrk9AL7rsr7xCsCOTI/Z6Rv7CTPra2apZpaanp6ezTIkLwsPM/q0qcaMwfE0rFScP326hrvGLGTLATUiE8ktfoe7mUUC3YCPs5p6kbFf7LY550Y75+Kcc3ExMTH+liFBpHLpaN7v05x/3lqftD1H6TwshTeSN3H2nFoYiARadvbcuwDLnHMXznfbd+Fwi+96v298J1Ap0+MqAruvtFAJTmbGnddVZnZiAvG1Ynh+2jp6jprPt3uOel2aSEjLTrjfxf8OyQBMAe73bd8PfJZpvLfvrJkWwJELh28k/ypXrCCj72vKq3c3Yff3J7n5lbkkzVzPqbNqYSASCObP6WpmFk3GcfTqzrkjvrHSwEdAZWA7cLtz7pCZGTAS6EzGmTUPOudSL/X8cXFxLjX1klMkhBz+4TR/+yKNSct3EVu2CP+8rQFNKpf0uiyRoGNmS51zcRe9Ly+ci6xwz5++Wb+fpyetZs/RH3mwVTV+16kW0ZERXpclEjQuFe76hKp45vraZZkxJJ57m1dh7LwtdByawtzv1IhMJCco3MVTRQsW4G896jGhbwsKhIdx71uL+MPElRw5qUZkIldC4S55QvPqpZk2qC2PJtTgk2W76JCUzIy1e70uSyRoKdwlzyhYIJwnu9Th08dbU7pIFP3eW0r/fy8j/ZgakYlkl8Jd8pz6FYszZUBrft+pNrPS9tFhaDKTlu1UIzKRbFC4S55UIDyM/tfXZOqgNlQvU5jEj1bywNtL2KVGZCJ+UbhLnlazbFE+frQVz9xclyVbD9ExKZlxC7aqEZlIFhTukueFhxkPtM5oRNakSkn+8tla7hy9gE3px70uTSTPUrhL0KhUKppxDzXjpdsasH7vMboMn8Nr/9moRmQiF6Fwl6BiZtweV4nZv03ghtpleXH6enq8No+1u494XZpInqJwl6BUtmhBXr+vKaPuacLeI6foNnIeL81Yx49n1IhMBBTuEuS61C/P7MR4ejSqwKvfbKLriDmkbj3kdVkinlO4S9ArER3Jy3c05N2HmnHqzHluf2MBz0xZyw+nznpdmohnFO4SMhJqxTBjSDy9W1Th3QVb6Tg0hZQN+gpHyZ8U7hJSikRF8Nfu9fi4X0uiCoTRe+xifvfxSr4/cdrr0kRylcJdQlJc1VJMHdiW/tfXYPLyXbRPSmHaan0hmOQfCncJWQULhPP7TnWYMqA15YpF8di/l/HY+0vZf+xHr0sTCTiFu4S8a68uzqf9W/OHzrX5at1+2r+czMepO9SITEKawl3yhQLhYTz+m5pMG9SW2lcV5fcTV9F77GJ2HDrhdWkiAaFwl3ylRkwRJvRtyd+6X8uybYfpNCyFd+ZtUSMyCTkKd8l3wsKM+1pWZcaQeK6rWopnPk/j9jcWsHH/Ma9LE8kxCnfJtyqWjOadB68j6Y6GbEo/Ttfhc3n1m42cUSMyCQEKd8nXzIyeTSoya0gCHeqW46UZ6+k2ch5rdqkRmQQ3hbsIEFM0ilfvacLr9zblwPFTdH91Hi9MUyMyCV4Kd5FMOte7itlDEri1SQVeT95E1+FzWLxFjcgk+PgV7mZWwswmmtk6M/vWzFqa2TNmtsvMVvguXTPNf8rMNprZejPrFLjyRXJe8egCvHhbQ97v05zT585zxxsL+POnaziuRmQSRPzdcx8OTHfO1QEaAt/6xoc65xr5LlMBzKwu0Au4FugMvGZm4Tlct0jAtYktw8wh8TzUuhrvL9pGx6Rkvlm/3+uyRPySZbibWTEgHngLwDl32jn3/SUe0h0Y75w75ZzbAmwEmuVEsSK5LToygr/cXJeJj7YiOiqCB99eQuKEFRz+QY3IJG/zZ8+9OpAOvG1my83sTTMr7LtvgJmtMrOxZlbSN1YB2JHp8Tt9Yz9hZn3NLNXMUtPT1ZZV8ramVUry5cA2DLyhJlNW7qbD0GS+XLVHLQwkz/In3COAJsAo51xj4AfgSWAUUANoBOwBXvbNt4s8xy/+BjjnRjvn4pxzcTExMZdTu0iuiooIJ7FjbaYMaEP54oXo/8Ey+r23lH1H1YhM8h5/wn0nsNM5t8h3eyLQxDm3zzl3zjl3HhjD/w697AQqZXp8RWB3ThUs4rW6Vxdj8uOteKpLHZI3pNM+KZkJS7ZrL17ylCzD3Tm3F9hhZrV9Q+2ANDMrn2naLcAa3/YUoJeZRZlZNSAWWJyDNYt4LiI8jH4JNZg+OJ5ryhfjj5+s5t63FrH9oBqRSd7g79kyTwD/NrNVZByG+Qfwopmt9o1dDwwBcM6tBT4C0oDpQH/nnD4JIiGpWpnCjH+kBc/1qMfKHUfoNCyFt+Zu4ZwakYnHLC/8VzIuLs6lpqZ6XYbIFdn9/Umenryab9an07hyCV68tQGx5Yp6XZaEMDNb6pyLu9h9+oSqSA65ukQhxj5wHcPubMTWAz9w44i5jPjqO06fVSMyyX0Kd5EcZGb0aFyBWYkJdKp3FUmzNtBt5FxW7rjUR0NEcp7CXSQAyhSJ4pW7GjOmdxyHT5zmltfm8fzUbzl5Wm8/Se5QuIsEUIe65Zg5JIE7r6vEGymb6TI8hYWbD3pdluQDCneRACteqADP92zABw8357yDXqMX8vTk1Rz78YzXpUkIU7iL5JJWNcswY3A8D7epxoeLt9NxaApfr9vndVkSohTuIrmoUGQ4f7qpLp881oqiBSN46J1UBo1fzsHjp7wuTUKMwl3EA40rl+SLJ9oyqF0sU1fvocPQFKas3K0WBpJjFO4iHomMCGNIh1p8/kQbKpUsxMAPl/PIuFT2HlEjMrlyCncRj9W5qhiTHm/Nn268hrkbD9AhKZkPF6sRmVwZhbtIHhAeZjzctjozBsdTr0Jxnpq0mrvHLGLbwR+8Lk2ClMJdJA+pUrowHzzSnOd71mfNroxGZG/O2axGZJJtCneRPMbMuKtZZWYlJtCmZhme+/Jbeo6az/q9x7wuTYKIwl0kj7qqeEHG9I5jxF2N2XHoBDe9MoehszaoEZn4ReEukoeZGd0aXs3sxARurF+e4V99x02vzGGFGpFJFhTuIkGgVOFIhvVqzNgH4jj241l6vjaP575IUyMy+VUKd5EgckOdcswcEs9dzSrz5twtdBqWwvxNB7wuS/IghbtIkClasAB/v6U+4/u2IMzg7jGLeGrSKo6qEZlkonAXCVItqpdm2qB4+sVXZ8KSHXRISmZWmhqRSQaFu0gQKxQZzlNdr+HT/q0pGR3JI+NSGfDBMg6oEVm+p3AXCQENKpZgyoA2JHaoxYy1e+mQlMyny3ephUE+pnAXCRGREWEMbBfL1IFtqVqmMIMnrKDPu6ns/v6k16WJBxTuIiEmtlxRJj7air/cVJcFmw7ScWgK7y/cxnm1MMhXFO4iISg8zHioTTVmDI6nYaXi/OnTNfQas5AtB9SILL9QuIuEsMqlo3m/T3NevLUB3+45SudhKbyevImz59TCINT5Fe5mVsLMJprZOjP71sxamlkpM5tlZt/5rkv65pqZjTCzjWa2ysyaBHYJInIpZsYd11VidmIC8bVieGHaOm55bT5pu496XZoEkL977sOB6c65OkBD4FvgSeAr51ws8JXvNkAXINZ36QuMytGKReSylCtWkNH3NeXVu5uw58hJuo2cy8sz13PqrFoYhKIsw93MigHxwFsAzrnTzrnvge7Au75p7wI9fNvdgXEuw0KghJmVz/HKRSTbzIwbG5Rn1pAEujW6mle+3siNI+aydNthr0uTHObPnnt1IB1428yWm9mbZlYYKOec2wPguy7rm18B2JHp8Tt9YyKSR5QsHEnSHY14+8HrOHHqLLe9Pp+/fr6WE6fPel2a5BB/wj0CaAKMcs41Bn7gf4dgLsYuMvaLc7DMrK+ZpZpZanp6ul/FikjOur52WWYmJnBfiyq8PW8rHYemMPc7NSILBf6E+05gp3Nuke/2RDLCft+Fwy2+6/2Z5lfK9PiKwO6fP6lzbrRzLs45FxcTE3O59YvIFSoSFcGz3evxUb+WFAgP4963FvGHiSs5ckKNyIJZluHunNsL7DCz2r6hdkAaMAW43zd2P/CZb3sK0Nt31kwL4MiFwzciknc1q1aKaYPa8thvavDJsl20H5rM9DV7vS5LLpP503vCzBoBbwKRwGbgQTL+YfgIqAxsB253zh0yMwNGAp2BE8CDzrnUSz1/XFycS0295BQRyUVrdh3hDxNXkbbnKDfWL88z3a4lpmiU12XJz5jZUudc3EXvywuNhRTuInnPmXPnGZ2ymeGzv6NQZDh/uakuPZtUIGP/TfKCS4W7PqEqIhdVIDyM/tfXZOqgttQsW4TffrySB95ewi41IgsKCncRuaSaZYvwcb+WPHNzXZZsPUTHpGTGLdiqRmR5nMJdRLIUFmY80DqjEVmTKiX5y2druXP0AjalH/e6NPkVCncR8VulUtGMe6gZL93WgPV7j9Fl+Bxe+89GzqgRWZ6jcBeRbDEzbo+rxOzfJtCuTllenL6eHq/OY82uI16XJpko3EXkspQtWpBR9zZl1D1N2Hf0FN1fncdLM9bx4xk1IssLFO4ickW61C/P7MR4bmlcgVe/2UTXEXNI3XrI67LyPYW7iFyxEtGR/Ov2hox7qBmnzpzn9jcW8MyUtfxwSo3IvKJwF5EcE18rhplD4rm/ZVXeXZDRiCx5gxoDekHhLiI5qnBUBM90u5aP+7WkYIEw7h+7mN9+tJLvT5z2urR8ReEuIgERV7UUXw5sy4Dra/Lpil20T0ph2mr1EMwtCncRCZiCBcL5XafaTBnQmnLFonjs38t49L2l7D/6o9elhTyFu4gE3LVXF+ez/q35Y+c6fL1+P+2Tkvk4dQd5oXFhqFK4i0iuiAgP47Hf1GDaoLbUvqoov5+4it5jF7Pj0AmvSwtJCncRyVU1YoowoW9L/tb9WpZtO0ynYSm8PW8L59SILEcp3EUk14WFGfe1rMrMxASuq1qKv36exh1vLGDj/mNelxYyFO4i4pkKJQrxzoPXkXRHQzalH6fr8LmM/Po7NSLLAQp3EfGUmdGzSUVmDUmgw7Xl+NfMDXQbqUZkV0rhLiJ5QkzRKF69uwlv3NeUA8czGpG9ME2NyC6Xwl1E8pRO117F7CEJ3NakIq8nb6Lr8Dks3qJGZNmlcBeRPKd4dAH+eVsD3u/TnNPnznPHGwv486drOPbjGa9LCxoKdxHJs9rElmHmkHgeal2N9xdto9PQFL5Zv9/rsoKCwl1E8rToyAj+cnNdPnmsFYWjInjw7SUkTljB4R/UiOxSFO4iEhSaVC7JFwPbMPCGmkxZuZv2Scl8sWq3Whj8CoW7iASNqIhwEjvW5vMn2nB1iUIM+GA5/d5byj41IvsFv8LdzLaa2WozW2Fmqb6xZ8xsl29shZl1zTT/KTPbaGbrzaxToIoXkfzpmvLFmPx4K57qUofkDem0T0pmwpLt2ovPJDt77tc75xo55+IyjQ31jTVyzk0FMLO6QC/gWqAz8JqZhedcySIiGY3I+iXUYPrgeK4pX4w/frKae95cxPaDakQGgTks0x0Y75w75ZzbAmwEmgXgdUREqFamMOMfacHfb6nHqp1H6DQshbfmqhGZv+HugJlmttTM+mYaH2Bmq8xsrJmV9I1VAHZkmrPTNyYiEhBhYcY9zaswKzGeljVK87cv0rh11Hw27Mu/jcj8DffWzrkmQBegv5nFA6OAGkAjYA/wsm+uXeTxv/gn1Mz6mlmqmaWmp+sLdEXkypUvXoi37o9jeK9GbDv4AzeOmMOIr77j9Nn814jMr3B3zu32Xe8HJgPNnHP7nHPnnHPngTH879DLTqBSpodXBHZf5DlHO+finHNxMTExV7IGEZH/MjO6N6rA7MQEOtcrT9KsDXQbOZeVO773urRclWW4m1lhMyt6YRvoCKwxs/KZpt0CrPFtTwF6mVmUmVUDYoHFOVu2iMillS4SxSt3NWZM7zgOnzjNLa/N4x9Tv+Xk6fzRiCzCjznlgMlmdmH+B8656Wb2npk1IuOQy1agH4Bzbq2ZfQSkAWeB/s65/PGnKSJ5Toe65WhevRTPT/2W0Smbmbl2L8/3bEDLGqW9Li2gLC+cFxoXF+dSU1O9LkNEQtz8jQd4ctJqth86wd3NK/NklzoUK1jA67Ium5kt/dnp6f+lT6iKSL7RqmYZZgyO55G21Ri/eDsdk1L4et0+r8sKCIW7iOQrhSLDefrGukx6vDXFCxXgoXdSGTR+OQePn/K6tBylcBeRfKlRpRJ8/kQbBrePZerqPXQYmsKUlaHTiEzhLiL5VmREGIPb1+KLJ9pSqVQ0Az9cziPjUtlz5KTXpV0xhbuI5Hu1ryrKpMda8acbr2HuxgN0TErhg0XbOR/ELQwU7iIiQHiY8XDb6swYHE+9CsX5f5NXc/ebC9l64AevS7ssCncRkUyqlC7MB48054We9Vm76yidh6cwJmVz0DUiU7iLiPyMmdGrWWVmJSbQpmYZ/j71W3q+No/1e4OnEZnCXUTkV1xVvCBjesfxyl2N2Xn4JDe9MoehszZw6mze/9C9wl1E5BLMjJsbXs2sxARurF+e4V99x82vzGX59sNel3ZJCncRET+UKhzJsF6NGftAHMd+PEvPUfP52xdpnDh91uvSLkrhLiKSDTfUKcfMIfHc07wyb83dQudhc5i/8YDXZf2Cwl1EJJuKFizAcz3qM75vC8IM7n5zEURvM2kAAAaGSURBVE9+soojJ894Xdp/KdxFRC5Ti+qlmT44nn4J1fkodQcdhyYzKy1vNCJTuIuIXIGCBcJ5qss1fNq/NSWjI3lkXCoDPljGAY8bkSncRURyQIOKJZgyoA2/7VCLmWv30T4pmcnLd3rWiEzhLiKSQyIjwniiXSxfDmxDtTKFGTJhJQ+9s4Td3+d+IzKFu4hIDostV5SJj7biLzfVZeHmQ3QcmsJ7C7flaiMyhbuISACEhxkPtanGzCHxNKpUgj9/uoZeYxayJZcakSncRUQCqFKpaN7r04wXb23At3uO0nlYCq8nb+LsufMBfV2Fu4hIgJkZd1xXidmJCSTUiuGFaeu45bX5pO0+GrDXjAjYM+eC5A3pPPdFmtdliIj4zQERYcbqXUfoNnIuo3s35YY65XL8dYI63ItERRBbrojXZYiIZEstX26ZGWWLFgzIawR1uDetUpKmVZp6XYaISJ6jY+4iIiFI4S4iEoL8Cncz22pmq81shZml+sZKmdksM/vOd13SN25mNsLMNprZKjNrEsgFiIjIL2Vnz/1651wj51yc7/aTwFfOuVjgK99tgC5ArO/SFxiVU8WKiIh/ruSwTHfgXd/2u0CPTOPjXIaFQAkzK38FryMiItnkb7g7YKaZLTWzvr6xcs65PQC+67K+8QrAjkyP3ekb+wkz62tmqWaWmp6efnnVi4jIRfl7KmRr59xuMysLzDKzdZeYaxcZ+0W3HOfcaGA0QFxcnDc9MUVEQpRfe+7Oud2+6/3AZKAZsO/C4Rbf9X7f9J1ApUwPrwjszqmCRUQka5ZVI3kzKwyEOeeO+bZnAc8C7YCDzrkXzOxJoJRz7g9mdiMwAOgKNAdGOOeaZfEa6cC2y1xDGSDvfTttYGnN+YPWnD9cyZqrOOdiLnaHP4dlygGTzezC/A+cc9PNbAnwkZn1AbYDt/vmTyUj2DcCJ4AHs3qBXyvOH2aWmukMnnxBa84ftOb8IVBrzjLcnXObgYYXGT9Ixt77z8cd0D9HqhMRkcuiT6iKiISgUAj30V4X4AGtOX/QmvOHgKw5yzdURUQk+ITCnruIiPyMwl1EJAQFTbibWWczW+/rNvnkRe6PMrMJvvsXmVnV3K8yZ/mx5kQzS/N13/zKzKp4UWdOymrNmebdZmbOzIL+tDl/1mxmd/h+1mvN7IPcrjGn+fG7XdnMvjGz5b7f765e1JlTzGysme03szW/cn/Od9N1zuX5CxAObAKqA5HASqDuz+Y8Drzu2+4FTPC67lxY8/VAtG/7sfywZt+8okAKsBCI87ruXPg5xwLLgZK+22W9rjsX1jwaeMy3XRfY6nXdV7jmeKAJsOZX7u8KTCOjfUsLYNGVvmaw7Lk3AzY65zY7504D48noPplZ5i6VE4F25vvkVZDKcs3OuW+ccyd8NxeS0eohmPnzcwb4G/Ai8GNuFhcg/qz5EeBV59xh+G8bkGDmz5odUMy3XZwgb2HinEsBDl1iSo530w2WcPen0+R/5zjnzgJHgNK5Ul1g+NVdM5M+ZPzLH8yyXLOZNQYqOee+yM3CAsifn3MtoJaZzTOzhWbWOdeqCwx/1vwMcK+Z7STjU+9P5E5pnsnu3/csBcsXZPvTadKvbpRBxO/1mNm9QByQENCKAu+SazazMGAo8EBuFZQL/Pk5R5BxaOY3ZPzvbI6Z1XPOfR/g2gLFnzXfBbzjnHvZzFoC7/nWfD7w5Xkix/MrWPbc/ek0+d85ZhZBxn/lLvXfoLzOr+6aZtYeeBro5pw7lUu1BUpWay4K1AP+Y2ZbyTg2OSXI31T193f7M+fcGefcFmA9GWEfrPxZcx/gIwDn3AKgIBkNtkJVjnfTDZZwXwLEmlk1M4sk4w3TKT+bMwW437d9G/C1871TEaSyXLPvEMUbZAR7sB+HhSzW7Jw74pwr45yr6pyrSsb7DN2cc6nelJsj/Pnd/pSMN88xszJkHKbZnKtV5ix/1rwdX+8qM7uGjHAP5W/1mQL09p010wI44nxfhnTZvH4XORvvNncFNpDxLvvTvrFnyfjLDRk//I/J6Ea5GKjudc25sObZwD5ghe8yxeuaA73mn839D0F+toyfP2cDkoA0YDXQy+uac2HNdYF5ZJxJswLo6HXNV7jeD4E9wBky9tL7AI8Cj2b6Gb/q+/NYnRO/12o/ICISgoLlsIyIiGSDwl1EJAQp3EVEQpDCXUQkBCncRURCkMJdRCQEKdxFRELQ/wdVuzCLyUNobQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\n",
    "if OPTIMIZATION_PLUGIN == 'Bayesian' :\n",
    "    from bayes_opt import BayesianOptimization\n",
    "    \n",
    "    #def black_box_function(x, y):\n",
    "    def objective(SCI_RELU, SCI_BIAS, SCI_loss_type,\n",
    "                  SCI_optimizer, SCI_LR, SCI_MM, \n",
    "                  SCI_REGULARIZATION, SCI_EPOCHS, SCI_BATCH_SIZE, \n",
    "                  SCI_DROPOUT, SCI_L_SECOND, SCI_BN_MOMENTUM, SCI_SGD_MOMENTUM, SCI_LINEARITY):\n",
    "        #global device, MaxCredit  , SCI_REGULARIZATION, SCI_DROPOUT, SCI_L_SECOND, SCI_EPOCHS, SCI_BN\n",
    "        global count, CreditVector, CreditVec, device, MaxCredit\n",
    "\n",
    "        \n",
    "        SCI_BATCH_SIZE = int(SCI_BATCH_SIZE)                    # integer between 4 and 256\n",
    "        SCI_MM = round(SCI_MM,3)                                # real with three decimals between (0.001, 0.999)\n",
    "        #SCI_REGULARIZATION = round(SCI_REGULARIZATION,3)        # real with three decimals between (0.001, 0.7)\n",
    "        SCI_LR = round(SCI_LR,5)                                # real with five decimals between(1e-4, 7e-1)            \n",
    "        SCI_DROPOUT = round(SCI_DROPOUT,2)                      # real with two decimals between (0, 0.4)\n",
    "        SCI_L_SECOND = int(SCI_L_SECOND)                        # integer between 2 and 64\n",
    "        SCI_EPOCHS = int(SCI_EPOCHS)                            # integer between (100, 500)\n",
    "        SCI_BN_MOMENTUM = round(SCI_BN_MOMENTUM,2)              # real with two decimals between (0, 0.99)\n",
    "        SCI_SGD_MOMENTUM = round(SCI_SGD_MOMENTUM,2)            # real with two decimals between (0, 0.99) \n",
    "        #SCI_optimizer = int(SCI_optimizer)                      # integer between 1 and 4\n",
    "        SCI_loss_type = int(SCI_loss_type)                      # integer between 1 and 3 ('CrossEntropyLoss', 'MultiMarginLoss','NLLLoss')\n",
    "        SCI_LINEARITY = int(SCI_LINEARITY)\n",
    "        if int(SCI_RELU) == 1 :                                 # integer between 1 and 2 ('True', 'False')\n",
    "            SCI_RELU = True      \n",
    "        else:\n",
    "            SCI_RELU = False      \n",
    "        if int(SCI_BIAS) == 1 :                                 # integer between 1 and 2 ('True', 'False')\n",
    "            SCI_BIAS = True      \n",
    "        else:\n",
    "            SCI_BIAS = False  \n",
    " \n",
    "        SCI_REGULARIZATION = float(str(SCI_REGULARIZATION))\n",
    "        \n",
    "        cnn = CNN6(L_FIRST, SCI_L_SECOND, KERNEL_X,\n",
    "                   SCI_BIAS, SCI_BN_MOMENTUM, SCI_RELU,\n",
    "                   SCI_DROPOUT, dataset.CLASSES, SCI_LINEARITY)     \n",
    "\n",
    "        optimizer = Utillities.optimization_algorithms(SCI_optimizer,cnn, SCI_LR, SCI_SGD_MOMENTUM,\n",
    "                                                       SCI_REGULARIZATION)\n",
    "        \n",
    "        if GPU_SELECT == 2:\n",
    "            if torch.cuda.device_count() > 1:\n",
    "                cnn = nn.DataParallel(cnn,device_ids=[0, 1], dim = 0) \n",
    "            cnn = cnn.cuda()                \n",
    "        if GPU_SELECT == 1:\n",
    "            cnn.to(device)  \n",
    "        if GPU_SELECT == 0:\n",
    "            cnn.to(device)        \n",
    "\n",
    "        cnn.apply(CNN6.weights_reset)        \n",
    "        cnn.share_memory()\n",
    "     \n",
    "        loss_func = nn.CrossEntropyLoss()\n",
    "\n",
    "        def create_loss(LOSS):   \n",
    "            if LOSS == 1:\n",
    "                loss_func = nn.CrossEntropyLoss()\n",
    "            if LOSS == 2:\n",
    "                loss_func = nn.NLLLoss()\n",
    "            else:\n",
    "                loss_func = nn.MultiMarginLoss()\n",
    "            return loss_func\n",
    "\n",
    "        MM = float(str(SCI_MM))\n",
    "\n",
    "        LR = float(str(SCI_LR))\n",
    "        train_losses = []         # to track the training loss as the model trains\n",
    "        output = 0\n",
    "        loss = 0\n",
    "        accuracy = 0\n",
    "        early_stopping.counter = 0\n",
    "        early_stopping.best_score = None\n",
    "        early_stopping.early_stop = False\n",
    "        early_stopping.verbose = False  \n",
    "        TEST_RESULTS = torch.zeros(1,2)\n",
    "    \n",
    "        loss_type = create_loss(SCI_loss_type)\n",
    "    \n",
    "        Utillities.listing(optimizer, SCI_SGD_MOMENTUM, SCI_BN_MOMENTUM, \n",
    "                           SCI_L_SECOND, SCI_LR, SCI_RELU, \n",
    "                           SCI_BIAS, SCI_loss_type, SCI_REGULARIZATION, \n",
    "                           SCI_BATCH_SIZE, SCI_DROPOUT, SCI_LINEARITY)\n",
    "\n",
    "    \n",
    "        # Data Loader for easy mini-batch return in training\n",
    "        SCI_BATCH_SIZE = int(SCI_BATCH_SIZE)\n",
    "        train_loader = Data.DataLoader(dataset = dataset.train_dataset, batch_size = SCI_BATCH_SIZE, shuffle = True, num_workers = 0, drop_last=True, pin_memory=True)\n",
    "        validation_loader = Data.DataLoader(dataset = dataset.validation_dataset, batch_size = 144, shuffle = True, num_workers = 0, drop_last=True, pin_memory=True)    \n",
    "        test_loader = Data.DataLoader(dataset = dataset.test_dataset, batch_size = 599, shuffle = True, num_workers = 0, drop_last=True, pin_memory=True)\n",
    "    \n",
    "        for epoch in range(SCI_EPOCHS):\n",
    "            loss = None        \n",
    "            cnn.train().cuda()\n",
    "            for step, (train_data, train_target) in enumerate(train_loader):   \n",
    "                train_data, train_target = train_data.to(device), train_target.to(device)\n",
    "                output, temp = cnn(train_data)                # forward pass: compute predicted outputs by passing inputs to the model     \n",
    "                loss = loss_func(output, train_target)\n",
    "                train_losses.append(loss.item())              # record training loss \n",
    "                loss.backward()                               # backward pass: compute gradient of the loss with respect to model parameters\n",
    "                optimizer.zero_grad()\n",
    "                optimizer.step()                              # perform a single optimization step (parameter update)\n",
    "      \n",
    "            cnn.eval().cuda()                 # switch to evaluation (no change) mode           \n",
    "            valid_loss = 0\n",
    "            accuracy = 0\n",
    "            running_loss = 0.0\n",
    "            with torch.no_grad():\n",
    "                for step, (validation_data, validation_target) in enumerate(validation_loader):\n",
    "                    validation_data, validation_target = validation_data.to(device), validation_target.to(device)\n",
    "                    output, temp = cnn(validation_data)            # forward pass: compute predicted outputs by passing inputs to the model\n",
    "                    valid_loss += loss_func(output, validation_target).item()\n",
    "                    #ps = torch.exp(output)\n",
    "                    #equality = (validation_target[0].data == ps.max(dim=1)[1])\n",
    "                    #accuracy += equality.type(torch.FloatTensor).mean()    \n",
    "                    #print('valid_loss: ', valid_loss)                    \n",
    "                    # print statistics\n",
    "                running_loss += valid_loss\n",
    "                if epoch % 100 == 0: \n",
    "                    print('average loss: %.6f' %(running_loss))\n",
    "                    running_loss = 0.0\n",
    "                   \n",
    "            train_losses = []\n",
    "            early_stopping(valid_loss, cnn)\n",
    "        \n",
    "            if early_stopping.early_stop:\n",
    "                if os.path.exists('checkpoint.pt'):\n",
    "                    #cnn = TheModelClass(*args, **kwargs)\n",
    "                    print(\"Loaded the model with the lowest Validation Loss!\")\n",
    "                    cnn.load_state_dict(torch.load('checkpoint.pt'))  # Choose whatever GPU device number you want\n",
    "                    cnn.to(device)\n",
    "                break\n",
    "      \n",
    "        cnn.eval()\n",
    "        class_correct = list(0. for i in range(1000))\n",
    "        class_total = list(0. for i in range(1000))\n",
    "        with torch.no_grad():\n",
    "            for (test_data, test_target) in test_loader:\n",
    "                test_data, test_target = test_data.to(device), test_target.to(device)\n",
    "                outputs, temp = cnn(test_data)\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                c = (predicted == test_target).squeeze()\n",
    "                for i in range(test_target.size(0)):\n",
    "                    label = test_target[i]\n",
    "                    class_correct[label] += c[i].item()\n",
    "                    class_total[label] += 1\n",
    "\n",
    "        for i in range(dataset.CLASSES):\n",
    "            TEST_RESULTS[0,i] = class_correct[i] / dataset.TESTED_ELEMENTS[i]\n",
    "            print('Class: ',i,' accuracy: ', TEST_RESULTS[0,i])   \n",
    "            print('Class: ',i,' correct: ', class_correct[i],' of ',dataset.TESTED_ELEMENTS[i])\n",
    "        percent = (TEST_RESULTS[0,0]+TEST_RESULTS[0,1])/2\n",
    "        print('Final percentage: ',percent)\n",
    "    \n",
    "        CreditCost = int((1 - TEST_RESULTS[0,0]) * dataset.TESTED_ELEMENTS[0] + (1 - TEST_RESULTS[0,1]) * dataset.TESTED_ELEMENTS[1] * 5)\n",
    "        \n",
    "        if TEST_RESULTS[0,0] == 0 or TEST_RESULTS[0,1] == 0 :\n",
    "            CreditCost = CreditCost + 300\n",
    "    \n",
    "        print('Last epoch: ', epoch)\n",
    "        print('Credit Cost: ',-CreditCost)\n",
    "        #list(cnn.parameters())\n",
    "    \n",
    "        if os.path.exists('checkpoint.pt'):  \n",
    "            os.remove('checkpoint.pt') \n",
    "\n",
    "        print()\n",
    "        \n",
    "        \n",
    "        print()\n",
    "        \n",
    "        if -CreditCost > MaxCredit : \n",
    "            MaxCredit = -CreditCost\n",
    "        print('Best Score So Far: ',MaxCredit)    \n",
    "        \n",
    "        CreditVector[count] = MaxCredit    \n",
    "        CreditVec[count] = count\n",
    "        # plot the data\n",
    "        fig = plt.figure()\n",
    "        ax = fig.add_subplot(1, 1, 1)\n",
    "        ax.plot(CreditVec, -CreditVector, color='tab:blue')\n",
    "        #print(CreditVec, -CreditVector)\n",
    "        count = count + 1\n",
    "        # display the plot\n",
    "        plt.show()\n",
    "        \n",
    "        return -CreditCost\n",
    "    \n",
    "    \n",
    "    optimizer = BayesianOptimization(\n",
    "        f=objective,\n",
    "        #pbounds=pbounds,\n",
    "        pbounds={'SCI_RELU': (1,2.99), \n",
    "                 'SCI_BIAS': (1,2.99), \n",
    "                 'SCI_loss_type': (1, 3.99), \n",
    "                 'SCI_optimizer': (1, 9.99),\n",
    "                 'SCI_LR': (0.01, 0.4), \n",
    "                 'SCI_MM': (0.001, 0.999), \n",
    "                 'SCI_REGULARIZATION': (0.0001, 0.7), \n",
    "                 'SCI_EPOCHS': (1000, 2000), \n",
    "                 'SCI_BATCH_SIZE': (4, 128), \n",
    "                 'SCI_DROPOUT': (0, 0.3), \n",
    "                 'SCI_L_SECOND': (2, 32), \n",
    "                 'SCI_BN_MOMENTUM': (0, 0.99), \n",
    "                 'SCI_SGD_MOMENTUM': (0, 0.99), \n",
    "                 'SCI_LINEARITY': (1,3.99)},\n",
    "        verbose=2, # verbose = 1 prints only when a maximum is observed, verbose = 0 is silent\n",
    "        random_state=1,\n",
    "    )\n",
    "        \n",
    "\n",
    "    #optimizer.maximize(\n",
    "        #n_iter=TRIALS, acq=\"ucb\", kappa=0.1\n",
    "    #)\n",
    "    \n",
    "    \n",
    "    optimizer.maximize(\n",
    "        init_points = RANDOM_STARTS,\n",
    "        n_iter = TRIALS,\n",
    "        #acq=\"ucb\", kappa=0.1\n",
    "        \n",
    "        acq=\"ei\", xi=1e-4\n",
    "    )\n",
    "    \n",
    "    \n",
    "    print(optimizer.max)\n",
    "    \n",
    "    for i, res in enumerate(optimizer.res):\n",
    "        print(\"Iteration {}: \\n\\t{}\".format(i, res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if OPTIMIZATION_PLUGIN == 'GradDescent' :\n",
    "    import pandas as pd\n",
    "    import matplotlib.pyplot as plt\n",
    "    import torch\n",
    "    import torch.optim as optim\n",
    "    from torch.autograd import Variable\n",
    "    from Utillities import Utillities\n",
    "    from cnn_model import CNN6      \n",
    "\n",
    "    SCI_LR = 0.17\n",
    "    SCI_REGULARIZATION = 0.03\n",
    "    SCI_EPOCHS = 200\n",
    "    SCI_loss_type = 'CrossEntropyLoss'\n",
    "    SCI_RELU = 'True'\n",
    "    SCI_BIAS = 'True'\n",
    "    SCI_BN_MOMENTUM = 0.1\n",
    "\n",
    "    SCI_SGD_MOMENTUM = torch.rand(1, requires_grad=True)\n",
    "    print('SCI_SGD_MOMENTUM: ', SCI_SGD_MOMENTUM)\n",
    "    SCI_BATCH_SIZE   = torch.randint(128, 256, (1,1), dtype=torch.float, requires_grad=True) \n",
    "    print('SCI_BATCH_SIZE: ',SCI_BATCH_SIZE)\n",
    "    SCI_L_SECOND   = torch.randint(80, 96, (1,1), dtype=torch.float, requires_grad=True) \n",
    "    print('SCI_L_SECOND: ',SCI_L_SECOND)\n",
    "    SCI_optimizer   = torch.randint(6, 11, (1,1), dtype=torch.float, requires_grad=True) \n",
    "    print('SCI_optimizer: ',SCI_optimizer)    \n",
    "    SCI_DROPOUT      = torch.rand(1, requires_grad=True)    \n",
    "    print('SCI_DROPOUT: ',SCI_DROPOUT)   \n",
    "    \n",
    "\n",
    "    def objective(SCI_SGD_MOMENTUM, SCI_DROPOUT, SCI_BATCH_SIZE, SCI_L_SECOND, SCI_optimizer, LINEARITY):\n",
    "        global SCI_REGULARIZATION, SCI_EPOCHS, SCI_loss_type, SCI_RELU\n",
    "        global SCI_BIAS, SCI_BN_MOMENTUM, device, SCI_LR, MaxCredit, count, CreditVector, CreditVec\n",
    "        \n",
    "        SCI_SGD_MOMENTUM = SCI_SGD_MOMENTUM/10\n",
    "        DROPOUT = (SCI_DROPOUT/2).item()\n",
    "        if SCI_DROPOUT < 0 :\n",
    "            DROPOUT = 0\n",
    "            \n",
    "        if SCI_BATCH_SIZE < 2 :\n",
    "            SCI_BATCH_SIZE = 64            \n",
    "\n",
    "        BATCH_SIZE = int(SCI_BATCH_SIZE)\n",
    "        \n",
    "        if SCI_L_SECOND < 4 :\n",
    "            SCI_L_SECOND = 64\n",
    "            \n",
    "        #if SCI_optimizer < 1 :\n",
    "         #   SCI_optimizer += 5\n",
    "        \n",
    "        L_SECOND = int(SCI_L_SECOND)\n",
    "        \n",
    "        loss_func = nn.CrossEntropyLoss()\n",
    "\n",
    "        def create_loss(LOSS):   \n",
    "            if LOSS == 'CrossEntropyLoss':\n",
    "                loss_func = nn.CrossEntropyLoss()\n",
    "            if LOSS == 'NLLLoss':\n",
    "                loss_func = nn.NLLLoss()\n",
    "            else:\n",
    "                loss_func = nn.MultiMarginLoss()\n",
    "            return loss_func\n",
    "\n",
    "\n",
    "        REGULARIZATION = float(str(SCI_REGULARIZATION))\n",
    "\n",
    "        cnn = CNN6(L_FIRST, L_SECOND, KERNEL_X, SCI_BIAS, SCI_BN_MOMENTUM, SCI_RELU, DROPOUT, dataset.CLASSES, LINEARITY)     \n",
    "\n",
    "        optimizer1 = Utillities.optimization_algorithms(SCI_optimizer.detach().numpy(),cnn, SCI_LR, SCI_SGD_MOMENTUM, SCI_REGULARIZATION)\n",
    "        \n",
    "        if GPU_SELECT == 2:\n",
    "            if torch.cuda.device_count() > 1:\n",
    "                cnn = nn.DataParallel(cnn,device_ids=[0, 1], dim=0) \n",
    "            cnn = cnn.cuda()\n",
    "        if GPU_SELECT == 1:\n",
    "            cnn.to(device)  \n",
    "        if GPU_SELECT == 0:\n",
    "            cnn.to(device)        \n",
    "\n",
    "        cnn.apply(CNN6.weights_reset)\n",
    "        cnn.share_memory()\n",
    "\n",
    "\n",
    "        train_losses = []         # to track the training loss as the model trains\n",
    "        output = 0\n",
    "        loss = 0\n",
    "        accuracy = 0\n",
    "        early_stopping.counter = 0\n",
    "        early_stopping.best_score = None\n",
    "        early_stopping.early_stop = False\n",
    "        early_stopping.verbose = False  \n",
    "        TEST_RESULTS = torch.zeros(1,2)\n",
    "\n",
    "    \n",
    "        loss_type = create_loss(SCI_loss_type)\n",
    "        \n",
    "\n",
    "        Utillities.listing(optimizer1, SCI_SGD_MOMENTUM, SCI_BN_MOMENTUM, L_SECOND, SCI_LR, SCI_RELU, SCI_BIAS, SCI_loss_type, REGULARIZATION, BATCH_SIZE, DROPOUT, LINEARITY)\n",
    "\n",
    "        train_loader = Data.DataLoader(dataset = dataset.train_dataset, batch_size = BATCH_SIZE, shuffle = False, num_workers = 0, drop_last=True, pin_memory=True)\n",
    "        validation_loader = Data.DataLoader(dataset = dataset.validation_dataset, batch_size = 144, shuffle = False, num_workers = 0, drop_last=True, pin_memory=True)    \n",
    "        test_loader = Data.DataLoader(dataset = dataset.test_dataset, batch_size = 599, shuffle = False, num_workers = 0, pin_memory=True, drop_last=True)\n",
    "    \n",
    "        for epoch in range(SCI_EPOCHS):\n",
    "            loss = None        \n",
    "            cnn.train().cuda()\n",
    "            for step, (train_data, train_target) in enumerate(train_loader):   \n",
    "                train_data, train_target = train_data.to(device), train_target.to(device)\n",
    "                output, temp = cnn(train_data)                   \n",
    "                loss = loss_func(output, train_target)\n",
    "                train_losses.append(loss.item())            \n",
    "                loss.backward()                             \n",
    "                optimizer1.zero_grad()\n",
    "                optimizer1.step()                           \n",
    "      \n",
    "            cnn.eval().cuda()                   \n",
    "            valid_loss = 0\n",
    "            accuracy = 0\n",
    "            with torch.no_grad():\n",
    "                for step, (validation_data, validation_target) in enumerate(validation_loader):\n",
    "                    validation_data, validation_target = validation_data.to(device), validation_target.to(device)\n",
    "                    output, temp = cnn(validation_data)            # forward pass: compute predicted outputs by passing inputs to the model\n",
    "                    valid_loss += loss_func(output, validation_target).item()  \n",
    "               \n",
    "            train_losses = []\n",
    "            early_stopping(valid_loss, cnn)\n",
    "       \n",
    "            if early_stopping.early_stop:\n",
    "                if os.path.exists('checkpoint.pt'):\n",
    "                    print(\"Loaded the model with the lowest Validation Loss!\")\n",
    "                    cnn.load_state_dict(torch.load('checkpoint.pt', map_location=\"cuda:1\"))  # Choose whatever GPU device number you want\n",
    "                    cnn.to(device)\n",
    "                break\n",
    "      \n",
    "        cnn.eval()\n",
    "        class_correct = list(0. for i in range(1000))\n",
    "        class_total = list(0. for i in range(1000))\n",
    "        with torch.no_grad():\n",
    "            for (test_data, test_target) in test_loader:\n",
    "                test_data, test_target = test_data.to(device), test_target.to(device)\n",
    "                outputs, temp = cnn(test_data)\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                c = (predicted == test_target).squeeze()\n",
    "                for i in range(test_target.size(0)):\n",
    "                    label = test_target[i]\n",
    "                    class_correct[label] += c[i].item()\n",
    "                    class_total[label] += 1\n",
    "\n",
    "        for i in range(dataset.CLASSES):\n",
    "            TEST_RESULTS[0,i] = class_correct[i] / dataset.TESTED_ELEMENTS[i]\n",
    "            print('Class: ',i,' accuracy: ', TEST_RESULTS[0,i])\n",
    "            print('Class: ',i,' correct: ', class_correct[i])\n",
    "        percent = (TEST_RESULTS[0,0]+TEST_RESULTS[0,1])/2\n",
    "        print('Final percentage: ',percent)\n",
    "    \n",
    "        CreditCost = (1 - TEST_RESULTS[0,0]) * dataset.TESTED_ELEMENTS[0] + (1 - TEST_RESULTS[0,1]) * dataset.TESTED_ELEMENTS[1] * 5\n",
    "    \n",
    "        if TEST_RESULTS[0,0] == 0 or TEST_RESULTS[0,1] == 0 :\n",
    "            CreditCost = CreditCost + 300\n",
    "    \n",
    "        print('Last epoch: ', epoch)\n",
    "   \n",
    "        if os.path.exists('checkpoint.pt'):  \n",
    "            os.remove('checkpoint.pt') \n",
    "\n",
    "        print()\n",
    "        torch.cuda.empty_cache()\n",
    "        print()\n",
    "        \n",
    "        CreditCost = CreditCost + (SCI_SGD_MOMENTUM + SCI_DROPOUT + SCI_BATCH_SIZE + SCI_L_SECOND + SCI_optimizer)/1000\n",
    "        print('Credit Cost: ',CreditCost)\n",
    "        \n",
    "        \n",
    "        if -CreditCost > MaxCredit : \n",
    "            MaxCredit = -CreditCost\n",
    "        print('Best Score So Far: ',MaxCredit)   \n",
    "        \n",
    "        CreditVector[count] = MaxCredit    \n",
    "        CreditVec[count] = count\n",
    "        # plot the data\n",
    "        fig = plt.figure()\n",
    "        ax = fig.add_subplot(1, 1, 1)\n",
    "        ax.plot(CreditVec, -CreditVector, color='tab:orange')\n",
    "        #print(CreditVec, -CreditVector)\n",
    "        count = count + 1\n",
    "        # display the plot\n",
    "        plt.show()\n",
    "             \n",
    "        return CreditCost\n",
    "\n",
    "    \n",
    "    def loss(y_predicted, expected):\n",
    "        return (y_predicted - expected).sum()\n",
    "            \n",
    "    \n",
    "    expected = 250\n",
    "    \n",
    "    #optim_alg = optim.Adagrad([SCI_SGD_MOMENTUM, SCI_DROPOUT, SCI_BATCH_SIZE, SCI_L_SECOND], lr=0.01)\n",
    "    optim_alg = optim.Adadelta([       \n",
    "        {'params': SCI_SGD_MOMENTUM, 'lr': 0.9},\n",
    "        {'params': SCI_DROPOUT, 'lr': 1e-2},\n",
    "        {'params': SCI_BATCH_SIZE, 'lr': 1},\n",
    "        {'params': SCI_L_SECOND, 'lr': 1},\n",
    "        {'params': SCI_optimizer, 'lr': 0.9}\n",
    "        ]) \n",
    "    \n",
    "    LINEARITY = 2\n",
    "    # Main optimization loop\n",
    "    for t in range(RANDOM_STARTS + TRIALS):\n",
    "        optim_alg.zero_grad()\n",
    "        y_predicted = objective(SCI_SGD_MOMENTUM, SCI_DROPOUT, SCI_BATCH_SIZE, SCI_L_SECOND, SCI_optimizer, LINEARITY)\n",
    "        current_loss = loss(y_predicted, expected)\n",
    "        current_loss.backward()\n",
    "        optim_alg.step()\n",
    "        print(f\"t = {t}, loss = {current_loss}, SCI_DROPOUT = {SCI_DROPOUT.detach().numpy()}, SCI_SGD_MOMENTUM = {SCI_SGD_MOMENTUM.item()}, SCI_BATCH_SIZE = {SCI_BATCH_SIZE.detach().numpy()}, SCI_L_SECOND = {SCI_L_SECOND.detach().numpy()}, SCI_optimizer = {SCI_optimizer.detach().numpy()}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "end.record()\n",
    "\n",
    "#print('Minimum Credit Cost: ',Min_Credit_Cost)\n",
    "\n",
    "print()\n",
    "print('Total execution time (minutes): ',start.elapsed_time(end)/60000)\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "if GET_STATS:\n",
    "    pr.disable()\n",
    "    s = io.StringIO()\n",
    "    sortby = SortKey.CUMULATIVE\n",
    "    ps = pstats.Stats(pr, stream=s).sort_stats(sortby)\n",
    "    ps.print_stats()\n",
    "    print(s.getvalue())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
