{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch Version:  1.2.0\n",
      "Torchvision Version:  0.4.0a0+6b959ee\n",
      "Using 2 NVIDIA 1080TI GPUs!\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as Data\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from torch.utils import data\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import cProfile, pstats, io\n",
    "from pstats import SortKey\n",
    "from random import randint\n",
    "from Utillities import Utillities\n",
    "from cnn_model import CNN6     \n",
    "\n",
    "\n",
    "print(\"PyTorch Version: \",torch.__version__)\n",
    "print(\"Torchvision Version: \",torchvision.__version__)\n",
    "\n",
    "if os.path.exists(\"checkpoint.pt\"):\n",
    "    os.remove(\"checkpoint.pt\")\n",
    "\n",
    "torch.manual_seed(10)   # reproducible\n",
    "\n",
    "OPTIMIZATION_PLUGIN = 'GradDescent' # 'Bayesian' or 'Scikit' or 'GradDescent'\n",
    "#Bayesian requires: $ conda install -c conda-forge bayesian-optimization\n",
    "\n",
    "GET_STATS = False\n",
    "GPU_SELECT = 2 # can be 0, 1, 2 (both)\n",
    "PARALLEL_PROCESSES = 2\n",
    "TRIALS = 10000\n",
    "RANDOM_STARTS = 10000\n",
    "LR  = 1e-5                    # learning rate\n",
    "SCI_LR =  1e-5\n",
    "LR2 = 1e-5\n",
    "SCI_MM = 0.5                  # momentum - used only with SGD optimizer\n",
    "MM = 0.5\n",
    "L_FIRST = 24                  # initial number of channels\n",
    "KERNEL_X = 24\n",
    "patience = 21                 # if validation loss not going down, wait \"patience\" number of epochs\n",
    "accuracy = 0\n",
    "MaxCredit = -800\n",
    "\n",
    "CreditVector = np.zeros(RANDOM_STARTS + TRIALS)\n",
    "CreditVector = CreditVector - 800\n",
    "CreditVec = np.zeros(RANDOM_STARTS + TRIALS)\n",
    "count = 0\n",
    "\n",
    "pr = cProfile.Profile()\n",
    "\n",
    "if GET_STATS:\n",
    "    pr.enable()\n",
    "    \n",
    "\n",
    "if GPU_SELECT == 2:\n",
    "    if torch.cuda.device_count() > 1:\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        print(\"Using\", torch.cuda.device_count(), \"NVIDIA 1080TI GPUs!\")\n",
    "\n",
    "if GPU_SELECT == 1:\n",
    "    device = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")    \n",
    "    print(\"Using one (the second) NVIDIA 1080TI GPU!\")\n",
    "\n",
    "if GPU_SELECT == 0:\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")       \n",
    "    print(\"Using one (the first) NVIDIA 1080TI GPU!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from early_stopping import EarlyStopping\n",
    "from dataset import dataset\n",
    "\n",
    "\n",
    "early_stopping = EarlyStopping(patience=patience, verbose=True)  # initialize the early_stopping object\n",
    "\n",
    "# Counter for the execution time\n",
    "start = torch.cuda.Event(enable_timing=True)\n",
    "end = torch.cuda.Event(enable_timing=True)\n",
    "\n",
    "start.record()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if OPTIMIZATION_PLUGIN == 'Scikit' :\n",
    "    from skopt import gp_minimize\n",
    "    from sklearn.datasets import load_boston\n",
    "    from sklearn.ensemble import GradientBoostingRegressor\n",
    "    from sklearn.model_selection import cross_val_score\n",
    "    from skopt.space import Real, Integer\n",
    "    from skopt.utils import use_named_args\n",
    "    from skopt.plots import plot_convergence\n",
    "    from functools import partial\n",
    "    from skopt.plots import plot_evaluations\n",
    "    from skopt import gp_minimize, forest_minimize, dummy_minimize, gbrt_minimize\n",
    "    from skopt.plots import plot_objective\n",
    "    from sklearn.preprocessing import LabelEncoder\n",
    "    from skopt.space import Real, Categorical, Integer\n",
    "    from sklearn.externals.joblib import Parallel, delayed\n",
    "\n",
    "    SCI_LR = Categorical(categories=[1e-1, 3e-1, 5e-1, 7e-1, 0.1, 0.11, 0.12, 0.13, 0.14, 0.15, 0.16, 0.17, 0.18, 0.19, 0.2, 0.21, 0.22, 0.23, 0.24, 0.25, 0.26, 0.27, 0.28, 0.29, 0.3, 0.31, 0.32, 0.33, 0.34, 0.35, 0.36, 0.37, 0.38, 0.08, 0.09],name= 'SCI_LR')\n",
    "    SCI_MM = Categorical(categories=[0.001, 0.01, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 0.99, 0.999], name='SCI_MM')\n",
    "    SCI_REGULARIZATION = Categorical(categories=[0.0001, 0.0003, 0.0007, 0.001, 0.003, 0.007, 0.01, 0.03, 0.07, 0.1, 0.3, 0.7], name='SCI_REGULARIZATION')\n",
    "    SCI_EPOCHS = Categorical(categories=[2000, 1000], name='SCI_EPOCHS')\n",
    "    SCI_optimizer = Categorical(categories=['Adam', 'AMSGrad', 'SGD', 'RMSprop', 'Rprop', 'AdamW', 'ASGD', 'Adadelta', 'Adamax'],name='SCI_optimizer') #\n",
    "    SCI_loss_type = Categorical(categories=['CrossEntropyLoss', 'MultiMarginLoss','NLLLoss', 'L1Loss'],name='SCI_loss_type') # \n",
    "    SCI_BATCH_SIZE = Categorical(categories=[4, 8, 12, 16, 24, 32, 48, 64, 80, 96, 104, 128, 144, 160, 192, 224, 256], name='SCI_BATCH_SIZE')\n",
    "    SCI_DROPOUT = Categorical(categories=[0, 0.01, 0.03, 0.07, 0.1, 0.13, 0.17, 0.2, 0.23, 0.27, 0.3, 0.33, 0.37, 0.4] , name = 'SCI_DROPOUT')\n",
    "    SCI_RELU = Categorical(categories=['True', 'False'] , name = 'SCI_RELU')\n",
    "    SCI_BIAS = Categorical(categories=['True', 'False'] , name = 'SCI_BIAS')\n",
    "    SCI_L_SECOND = Categorical(categories=[2, 4, 6, 8, 12, 16, 20, 24, 32, 48, 64], name='SCI_L_SECOND')\n",
    "    SCI_BN_MOMENTUM = Categorical(categories=[0, 0.01, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 0.99] , name = 'SCI_BN_MOMENTUM') \n",
    "    SCI_SGD_MOMENTUM = Categorical(categories=[0, 0.01, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 0.99] , name = 'SCI_SGD_MOMENTUM') \n",
    "    SCI_LINEARITY = Categorical(categories=[1, 2],name= 'SCI_LINEARITY')\n",
    "   \n",
    "\n",
    "    dimensions = [SCI_BATCH_SIZE, SCI_MM, SCI_REGULARIZATION, SCI_optimizer, SCI_LR, SCI_loss_type, SCI_DROPOUT, SCI_RELU, SCI_BIAS, SCI_L_SECOND, SCI_EPOCHS, SCI_BN_MOMENTUM, SCI_SGD_MOMENTUM, SCI_LINEARITY]\n",
    "\n",
    "    @use_named_args(dimensions = dimensions)\n",
    "\n",
    "    def objective(SCI_BATCH_SIZE, SCI_MM, SCI_REGULARIZATION, SCI_optimizer, SCI_LR, SCI_loss_type, SCI_DROPOUT, SCI_RELU, SCI_BIAS, SCI_L_SECOND, SCI_EPOCHS, SCI_BN_MOMENTUM, SCI_SGD_MOMENTUM, SCI_LINEARITY):\n",
    "        global device  \n",
    "\n",
    "        loss_func = nn.CrossEntropyLoss()\n",
    "\n",
    "        def create_loss(LOSS):   \n",
    "            if LOSS == 'CrossEntropyLoss':\n",
    "                loss_func = nn.CrossEntropyLoss()\n",
    "            if LOSS == 'NLLLoss':\n",
    "                loss_func = nn.NLLLoss()\n",
    "            else:\n",
    "                loss_func = nn.MultiMarginLoss()\n",
    "            return loss_func\n",
    "\n",
    "        MM = float(str(SCI_MM))\n",
    "        REGULARIZATION = float(str(SCI_REGULARIZATION))\n",
    "        optimizer = str(SCI_optimizer)\n",
    "        LR = float(str(SCI_LR))\n",
    "        train_losses = []         # to track the training loss as the model trains\n",
    "        output = 0\n",
    "        loss = 0\n",
    "        accuracy = 0\n",
    "        early_stopping.counter = 0\n",
    "        early_stopping.best_score = None\n",
    "        early_stopping.early_stop = False\n",
    "        early_stopping.verbose = False  \n",
    "        TEST_RESULTS = torch.zeros(1,2)\n",
    " \n",
    "        loss_type = create_loss(SCI_loss_type)\n",
    "                \n",
    "        cnn = CNN6(L_FIRST, SCI_L_SECOND, KERNEL_X, SCI_BIAS, SCI_BN_MOMENTUM, SCI_RELU, SCI_DROPOUT, dataset.CLASSES, SCI_LINEARITY)     \n",
    "\n",
    "        optimizer = Utillities.optimization_algorithms(SCI_optimizer,cnn, SCI_LR, SCI_SGD_MOMENTUM,\n",
    "                                                       SCI_REGULARIZATION)\n",
    "        \n",
    "        if GPU_SELECT == 2:\n",
    "            if torch.cuda.device_count() > 1:\n",
    "                cnn = nn.DataParallel(cnn,device_ids=[0, 1], dim=0) \n",
    "            cnn = cnn.cuda()\n",
    "        if GPU_SELECT == 1:\n",
    "            cnn.to(device)  \n",
    "        if GPU_SELECT == 0:\n",
    "            cnn.to(device)        \n",
    "\n",
    "        cnn.apply(CNN6.weights_reset)\n",
    "        cnn.share_memory()\n",
    "     \n",
    "\n",
    "        Utillities.listing(optimizer, SCI_SGD_MOMENTUM, SCI_BN_MOMENTUM, SCI_L_SECOND, SCI_LR, SCI_RELU, SCI_BIAS, SCI_loss_type, REGULARIZATION, SCI_BATCH_SIZE, SCI_DROPOUT, SCI_LINEARITY)\n",
    "    \n",
    "        #SCI_BATCH_SIZE = 1\n",
    "        # Data Loader for easy mini-batch return in training\n",
    "        SCI_BATCH_SIZE = int(SCI_BATCH_SIZE)\n",
    "        train_loader = Data.DataLoader(dataset = dataset.train_dataset, batch_size = SCI_BATCH_SIZE, shuffle = False, num_workers = 0, drop_last=True, pin_memory=True)\n",
    "        validation_loader = Data.DataLoader(dataset = dataset.validation_dataset, batch_size = SCI_BATCH_SIZE, shuffle = False, num_workers = 0, drop_last=True, pin_memory=True)    \n",
    "        test_loader = Data.DataLoader(dataset = dataset.test_dataset, batch_size = SCI_BATCH_SIZE, shuffle = False, num_workers = 0, pin_memory=True)\n",
    "    \n",
    "        for epoch in range(SCI_EPOCHS):\n",
    "            loss = None        \n",
    "            cnn.train().cuda()\n",
    "            for step, (train_data, train_target) in enumerate(train_loader):   \n",
    "                train_data, train_target = train_data.to(device), train_target.to(device)\n",
    "                output, temp = cnn(train_data)                # forward pass: compute predicted outputs by passing inputs to the model     \n",
    "                loss = loss_func(output, train_target)\n",
    "                train_losses.append(loss.item())              # record training loss \n",
    "                loss.backward()                               # backward pass: compute gradient of the loss with respect to model parameters\n",
    "                optimizer.zero_grad()\n",
    "                optimizer.step()                              # perform a single optimization step (parameter update)\n",
    "      \n",
    "            cnn.eval().cuda()                 # switch to evaluation (no change) mode           \n",
    "            valid_loss = 0\n",
    "            accuracy = 0\n",
    "            with torch.no_grad():\n",
    "                for step, (validation_data, validation_target) in enumerate(validation_loader):\n",
    "                    validation_data, validation_target = validation_data.to(device), validation_target.to(device)\n",
    "                    output, temp = cnn(validation_data)            # forward pass: compute predicted outputs by passing inputs to the model\n",
    "                    valid_loss += loss_func(output, validation_target).item()\n",
    "                    #ps = torch.exp(output)\n",
    "                    #equality = (validation_target[0].data == ps.max(dim=1)[1])\n",
    "                    #accuracy += equality.type(torch.FloatTensor).mean()      \n",
    "               \n",
    "            train_losses = []\n",
    "            early_stopping(valid_loss, cnn)\n",
    "       \n",
    "            if early_stopping.early_stop:\n",
    "                if os.path.exists('checkpoint.pt'):\n",
    "                    print(\"Loaded the model with the lowest Validation Loss!\")\n",
    "                    #nn.load_state_dict(torch.load('checkpoint.pt', map_location=\"cuda:1\"))  # Choose whatever GPU device number you want\n",
    "                    cnn.load_state_dict(torch.load('checkpoint.pt', map_location=\"cuda:1\"))  # Choose whatever GPU device number you want\n",
    "                    cnn.to(device)\n",
    "                break\n",
    "      \n",
    "        cnn.eval()\n",
    "        class_correct = list(0. for i in range(1000))\n",
    "        class_total = list(0. for i in range(1000))\n",
    "        with torch.no_grad():\n",
    "            for (test_data, test_target) in test_loader:\n",
    "                test_data, test_target = test_data.to(device), test_target.to(device)\n",
    "                outputs, temp = cnn(test_data)\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                c = (predicted == test_target).squeeze()\n",
    "                for i in range(test_target.size(0)):\n",
    "                    label = test_target[i]\n",
    "                    class_correct[label] += c[i].item()\n",
    "                    class_total[label] += 1\n",
    "\n",
    "        for i in range(dataset.CLASSES):\n",
    "            TEST_RESULTS[0,i] = class_correct[i] / dataset.TESTED_ELEMENTS[i]\n",
    "            print('Class: ',i,' accuracy: ', TEST_RESULTS[0,i])\n",
    "            print('Class: ',i,' correct: ', class_correct[i])\n",
    "        percent = (TEST_RESULTS[0,0]+TEST_RESULTS[0,1])/2\n",
    "        print('Final percentage: ',percent)\n",
    "    \n",
    "        CreditCost = int((1 - TEST_RESULTS[0,0]) * dataset.TESTED_ELEMENTS[0] + (1 - TEST_RESULTS[0,1]) * dataset.TESTED_ELEMENTS[1] * 5)\n",
    "    \n",
    "        if TEST_RESULTS[0,0] == 0 or TEST_RESULTS[0,1] == 0 :\n",
    "            CreditCost = CreditCost + 300\n",
    "    \n",
    "        print('Last epoch: ', epoch)\n",
    "        print('Credit Cost: ',CreditCost)\n",
    "    \n",
    "        if os.path.exists('checkpoint.pt'):  \n",
    "            os.remove('checkpoint.pt') \n",
    "\n",
    "        print()\n",
    "        torch.cuda.empty_cache()\n",
    "        print()\n",
    "        \n",
    "        return CreditCost\n",
    "    \n",
    "    #not working #res_gp = gp_minimize(objective, dimensions=dimensions, n_calls=TRIALS, random_state=1, verbose=True, acq_func='gp_hedge', acq_optimizer='auto', n_jobs=1)\n",
    "    res_gp = forest_minimize(objective, dimensions=dimensions, base_estimator='RF', n_calls=TRIALS, n_random_starts=RANDOM_STARTS, acq_func='EI', x0=None, y0=None, random_state=None, verbose=True, callback=None, n_points=10000, xi=0.01, kappa=1.5, n_jobs=4)\n",
    "    #res_gp = gbrt_minimize(objective, dimensions=dimensions, base_estimator='ET', n_calls=TRIALS+RANDOM_STARTS, n_random_starts=RANDOM_STARTS, acq_func='LCB', x0=None, y0=None, random_state=None, verbose=True, callback=None, n_points=100, xi=0.01, kappa=1.96, n_jobs=1)\n",
    "    #res_gp = dummy_minimize(objective, dimensions=dimensions, n_calls=TRIALS, x0=None, y0=None, random_state=None, verbose=True, callback=None)      \n",
    "\n",
    "    \"Best score=%.4f\" % res_gp.fun\n",
    "    print(\"\"\"Best parameters: - optimization=%d\"\"\" % (res_gp.x[0]))\n",
    "  \n",
    "    print(res_gp)\n",
    "    plot_convergence(res_gp)\n",
    "    #plot_evaluations(res_gp)\n",
    "    #plot_objective(res_gp)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "if OPTIMIZATION_PLUGIN == 'Bayesian' :\n",
    "    from bayes_opt import BayesianOptimization\n",
    "    \n",
    "    #def black_box_function(x, y):\n",
    "    def objective(SCI_RELU, SCI_BIAS, SCI_loss_type,\n",
    "                  SCI_optimizer, SCI_LR, SCI_MM, \n",
    "                  SCI_REGULARIZATION, SCI_EPOCHS, SCI_BATCH_SIZE, \n",
    "                  SCI_DROPOUT, SCI_L_SECOND, SCI_BN_MOMENTUM, SCI_SGD_MOMENTUM, SCI_LINEARITY):\n",
    "        #global device, MaxCredit  , SCI_REGULARIZATION, SCI_DROPOUT, SCI_L_SECOND, SCI_EPOCHS, SCI_BN\n",
    "        global count, CreditVector, CreditVec, device, MaxCredit\n",
    "\n",
    "        \n",
    "        SCI_BATCH_SIZE = int(SCI_BATCH_SIZE)                    # integer between 4 and 256\n",
    "        SCI_MM = round(SCI_MM,3)                                # real with three decimals between (0.001, 0.999)\n",
    "        #SCI_REGULARIZATION = round(SCI_REGULARIZATION,3)        # real with three decimals between (0.001, 0.7)\n",
    "        SCI_LR = round(SCI_LR,5)                                # real with five decimals between(1e-4, 7e-1)            \n",
    "        SCI_DROPOUT = round(SCI_DROPOUT,2)                      # real with two decimals between (0, 0.4)\n",
    "        SCI_L_SECOND = int(SCI_L_SECOND)                        # integer between 2 and 64\n",
    "        SCI_EPOCHS = int(SCI_EPOCHS)                            # integer between (100, 500)\n",
    "        SCI_BN_MOMENTUM = round(SCI_BN_MOMENTUM,2)              # real with two decimals between (0, 0.99)\n",
    "        SCI_SGD_MOMENTUM = round(SCI_SGD_MOMENTUM,2)            # real with two decimals between (0, 0.99) \n",
    "        #SCI_optimizer = int(SCI_optimizer)                      # integer between 1 and 4\n",
    "        SCI_loss_type = int(SCI_loss_type)                      # integer between 1 and 3 ('CrossEntropyLoss', 'MultiMarginLoss','NLLLoss')\n",
    "        SCI_LINEARITY = int(SCI_LINEARITY)\n",
    "        if int(SCI_RELU) == 1 :                                 # integer between 1 and 2 ('True', 'False')\n",
    "            SCI_RELU = True      \n",
    "        else:\n",
    "            SCI_RELU = False      \n",
    "        if int(SCI_BIAS) == 1 :                                 # integer between 1 and 2 ('True', 'False')\n",
    "            SCI_BIAS = True      \n",
    "        else:\n",
    "            SCI_BIAS = False  \n",
    " \n",
    "        SCI_REGULARIZATION = float(str(SCI_REGULARIZATION))\n",
    "        \n",
    "        cnn = CNN6(L_FIRST, SCI_L_SECOND, KERNEL_X,\n",
    "                   SCI_BIAS, SCI_BN_MOMENTUM, SCI_RELU,\n",
    "                   SCI_DROPOUT, dataset.CLASSES, SCI_LINEARITY)     \n",
    "\n",
    "        optimizer = Utillities.optimization_algorithms(SCI_optimizer,cnn, SCI_LR, SCI_SGD_MOMENTUM,\n",
    "                                                       SCI_REGULARIZATION)\n",
    "        \n",
    "        if GPU_SELECT == 2:\n",
    "            if torch.cuda.device_count() > 1:\n",
    "                cnn = nn.DataParallel(cnn,device_ids=[0, 1], dim = 0) \n",
    "            cnn = cnn.cuda()                \n",
    "        if GPU_SELECT == 1:\n",
    "            cnn.to(device)  \n",
    "        if GPU_SELECT == 0:\n",
    "            cnn.to(device)        \n",
    "\n",
    "        cnn.apply(CNN6.weights_reset)        \n",
    "        cnn.share_memory()\n",
    "     \n",
    "        loss_func = nn.CrossEntropyLoss()\n",
    "\n",
    "        def create_loss(LOSS):   \n",
    "            print('*** LOSS ******:',  LOSS)\n",
    "            if LOSS == 1:\n",
    "                loss_func = nn.CrossEntropyLoss()\n",
    "                print('*********  CrossEntropyLoss')\n",
    "            if LOSS == 2:\n",
    "                loss_func = nn.MultiMarginLoss()\n",
    "                print('*********  MMLoss')                               \n",
    "            if LOSS == 3:\n",
    "                loss_func = nn.NLLLoss() \n",
    "                print('*********  NLLLoss')                 \n",
    "            return loss_func\n",
    "\n",
    "        MM = float(str(SCI_MM))\n",
    "\n",
    "        LR = float(str(SCI_LR))\n",
    "        train_losses = []         # to track the training loss as the model trains\n",
    "        output = 0\n",
    "        loss = 0\n",
    "        accuracy = 0\n",
    "        early_stopping.counter = 0\n",
    "        early_stopping.best_score = None\n",
    "        early_stopping.early_stop = False\n",
    "        early_stopping.verbose = False  \n",
    "        TEST_RESULTS = torch.zeros(1,2)\n",
    "    \n",
    "        loss_type = create_loss(SCI_loss_type)\n",
    "    \n",
    "        Utillities.listing(optimizer, SCI_SGD_MOMENTUM, SCI_BN_MOMENTUM, \n",
    "                           SCI_L_SECOND, SCI_LR, SCI_RELU, \n",
    "                           SCI_BIAS, SCI_loss_type, SCI_REGULARIZATION, \n",
    "                           SCI_BATCH_SIZE, SCI_DROPOUT, SCI_LINEARITY)\n",
    "\n",
    "    \n",
    "        # Data Loader for easy mini-batch return in training\n",
    "        SCI_BATCH_SIZE = int(SCI_BATCH_SIZE)\n",
    "        train_loader = Data.DataLoader(dataset = dataset.train_dataset, batch_size = SCI_BATCH_SIZE, shuffle = True, num_workers = 0, drop_last=True, pin_memory=True)\n",
    "        validation_loader = Data.DataLoader(dataset = dataset.validation_dataset, batch_size = 144, shuffle = True, num_workers = 0, drop_last=True, pin_memory=True)    \n",
    "        test_loader = Data.DataLoader(dataset = dataset.test_dataset, batch_size = 599, shuffle = True, num_workers = 0, drop_last=True, pin_memory=True)\n",
    "    \n",
    "        for epoch in range(SCI_EPOCHS):\n",
    "            loss = None        \n",
    "            cnn.train().cuda()\n",
    "            for step, (train_data, train_target) in enumerate(train_loader):   \n",
    "                train_data, train_target = train_data.to(device), train_target.to(device)\n",
    "                output, temp = cnn(train_data)                # forward pass: compute predicted outputs by passing inputs to the model     \n",
    "                loss = loss_func(output, train_target)\n",
    "                train_losses.append(loss.item())              # record training loss \n",
    "                loss.backward()                               # backward pass: compute gradient of the loss with respect to model parameters\n",
    "                optimizer.zero_grad()\n",
    "                optimizer.step()                              # perform a single optimization step (parameter update)\n",
    "      \n",
    "            cnn.eval().cuda()                 # switch to evaluation (no change) mode           \n",
    "            valid_loss = 0\n",
    "            accuracy = 0\n",
    "            running_loss = 0.0\n",
    "            with torch.no_grad():\n",
    "                for step, (validation_data, validation_target) in enumerate(validation_loader):\n",
    "                    validation_data, validation_target = validation_data.to(device), validation_target.to(device)\n",
    "                    output, temp = cnn(validation_data)            # forward pass: compute predicted outputs by passing inputs to the model\n",
    "                    valid_loss += loss_func(output, validation_target).item()\n",
    "                    #ps = torch.exp(output)\n",
    "                    #equality = (validation_target[0].data == ps.max(dim=1)[1])\n",
    "                    #accuracy += equality.type(torch.FloatTensor).mean()    \n",
    "                    #print('valid_loss: ', valid_loss)                    \n",
    "                    # print statistics\n",
    "                running_loss += valid_loss\n",
    "                if epoch % 100 == 0: \n",
    "                    print('average loss: %.6f' %(running_loss))\n",
    "                    running_loss = 0.0\n",
    "                   \n",
    "            train_losses = []\n",
    "            early_stopping(valid_loss, cnn)\n",
    "        \n",
    "            if early_stopping.early_stop:\n",
    "                if os.path.exists('checkpoint.pt'):\n",
    "                    #cnn = TheModelClass(*args, **kwargs)\n",
    "                    print(\"Loaded the model with the lowest Validation Loss!\")\n",
    "                    cnn.load_state_dict(torch.load('checkpoint.pt'))  # Choose whatever GPU device number you want\n",
    "                    cnn.to(device)\n",
    "                break\n",
    "      \n",
    "        cnn.eval()\n",
    "        class_correct = list(0. for i in range(1000))\n",
    "        class_total = list(0. for i in range(1000))\n",
    "        with torch.no_grad():\n",
    "            for (test_data, test_target) in test_loader:\n",
    "                test_data, test_target = test_data.to(device), test_target.to(device)\n",
    "                outputs, temp = cnn(test_data)\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                c = (predicted == test_target).squeeze()\n",
    "                for i in range(test_target.size(0)):\n",
    "                    label = test_target[i]\n",
    "                    class_correct[label] += c[i].item()\n",
    "                    class_total[label] += 1\n",
    "\n",
    "        for i in range(dataset.CLASSES):\n",
    "            TEST_RESULTS[0,i] = class_correct[i] / dataset.TESTED_ELEMENTS[i]\n",
    "            print('Class: ',i,' accuracy: ', TEST_RESULTS[0,i])   \n",
    "            print('Class: ',i,' correct: ', class_correct[i],' of ',dataset.TESTED_ELEMENTS[i])\n",
    "        percent = (TEST_RESULTS[0,0]+TEST_RESULTS[0,1])/2\n",
    "        print('Final percentage: ',percent)\n",
    "    \n",
    "        CreditCost = int((1 - TEST_RESULTS[0,0]) * dataset.TESTED_ELEMENTS[0] + (1 - TEST_RESULTS[0,1]) * dataset.TESTED_ELEMENTS[1] * 5)\n",
    "        \n",
    "        if TEST_RESULTS[0,0] == 0 or TEST_RESULTS[0,1] == 0 :\n",
    "            CreditCost = CreditCost + 300\n",
    "    \n",
    "        print('Last epoch: ', epoch)\n",
    "        print('Credit Cost: ',-CreditCost)\n",
    "        #list(cnn.parameters())\n",
    "    \n",
    "        if os.path.exists('checkpoint.pt'):  \n",
    "            os.remove('checkpoint.pt') \n",
    "\n",
    "        print()\n",
    "        \n",
    "        \n",
    "        print()\n",
    "        \n",
    "        if -CreditCost > MaxCredit : \n",
    "            MaxCredit = -CreditCost\n",
    "        print('Best Score So Far: ',MaxCredit)    \n",
    "        \n",
    "        CreditVector[count] = MaxCredit    \n",
    "        CreditVec[count] = count\n",
    "        # plot the data\n",
    "        fig = plt.figure()\n",
    "        ax = fig.add_subplot(1, 1, 1)\n",
    "        ax.plot(CreditVec, -CreditVector, color='tab:blue')\n",
    "        #print(CreditVec, -CreditVector)\n",
    "        count = count + 1\n",
    "        # display the plot\n",
    "        plt.show()\n",
    "        \n",
    "        return -CreditCost\n",
    "    \n",
    "    \n",
    "    optimizer = BayesianOptimization(\n",
    "        f=objective,\n",
    "        #pbounds=pbounds,\n",
    "        pbounds={'SCI_RELU': (1,2.99), \n",
    "                 'SCI_BIAS': (1,2.99), \n",
    "                 'SCI_loss_type': (1, 4.99), \n",
    "                 'SCI_optimizer': (1, 9.99),\n",
    "                 'SCI_LR': (0.01, 0.4), \n",
    "                 'SCI_MM': (0.001, 0.999), \n",
    "                 'SCI_REGULARIZATION': (0.0001, 0.7), \n",
    "                 'SCI_EPOCHS': (1000, 2000), \n",
    "                 'SCI_BATCH_SIZE': (4, 128), \n",
    "                 'SCI_DROPOUT': (0, 0.3), \n",
    "                 'SCI_L_SECOND': (2, 32), \n",
    "                 'SCI_BN_MOMENTUM': (0, 0.99), \n",
    "                 'SCI_SGD_MOMENTUM': (0, 0.99), \n",
    "                 'SCI_LINEARITY': (1,3.99)},\n",
    "        verbose=2, # verbose = 1 prints only when a maximum is observed, verbose = 0 is silent\n",
    "        random_state=1,\n",
    "    )\n",
    "        \n",
    "\n",
    "    #optimizer.maximize(\n",
    "        #n_iter=TRIALS, acq=\"ucb\", kappa=0.1\n",
    "    #)\n",
    "    \n",
    "    \n",
    "    optimizer.maximize(\n",
    "        init_points = RANDOM_STARTS,\n",
    "        n_iter = TRIALS,\n",
    "        #acq=\"ucb\", kappa=0.1\n",
    "        \n",
    "        acq=\"ei\", xi=1e-4\n",
    "    )\n",
    "    \n",
    "    \n",
    "    print(optimizer.max)\n",
    "    \n",
    "    for i, res in enumerate(optimizer.res):\n",
    "        print(\"Iteration {}: \\n\\t{}\".format(i, res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SCI_loss_type:  tensor([[3.]], requires_grad=True)\n",
      "SCI_SGD_MOMENTUM:  tensor([0.4829], requires_grad=True)\n",
      "SCI_BATCH_SIZE:  tensor([[228.]], requires_grad=True)\n",
      "SCI_L_SECOND:  tensor([[95.]], requires_grad=True)\n",
      "SCI_optimizer:  tensor([[8.]], requires_grad=True)\n",
      "SCI_DROPOUT:  tensor([0.4118], requires_grad=True)\n",
      "SCI_LR:  tensor([0.6938], requires_grad=True)\n",
      "SCI_LR:  0.2312646508216858\n",
      "SCI_LR type:  <class 'float'>\n",
      "*** LOSS ******: 3\n",
      "*********  NLLLoss\n",
      "LOSS FUNCTION IS:  NLLLoss()\n",
      "Optimization:  Adamax (\n",
      "Parameter Group 0\n",
      "    betas: (0.9, 0.999)\n",
      "    eps: 1e-08\n",
      "    lr: 0.2312646508216858\n",
      "    weight_decay: 0.03\n",
      ")\n",
      "Batch Normalization Momentum:  0.1\n",
      "Nodes:  95\n",
      "LR:  0.2312646508216858\n",
      "RELU:  True\n",
      "BIAS:  True\n",
      "Loss Type:  3\n",
      "REGULARIZATION:  0.03\n",
      "BATCH_SIZE:  228\n",
      "Dropout:  0.20591309666633606\n",
      "Final Linear Layers:  2\n",
      "Loaded the model with the lowest Validation Loss!\n",
      "Class:  0  accuracy:  tensor(0.5832)\n",
      "Class:  0  correct:  291.0\n",
      "Class:  1  accuracy:  tensor(0.5700)\n",
      "Class:  1  correct:  57.0\n",
      "Final percentage:  tensor(0.5766)\n",
      "Last epoch:  30\n",
      "\n",
      "\n",
      "Credit Cost:  tensor([[423.3347]], grad_fn=<AddBackward0>)\n",
      "Best Score So Far:  tensor([[-423.3347]], grad_fn=<NegBackward>)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t = 0, loss = 173.33468627929688, SCI_DROPOUT = [0.41181666], SCI_SGD_MOMENTUM = 0.48276662826538086, SCI_BATCH_SIZE = [[227.99905]], SCI_L_SECOND = [[94.99905]], SCI_optimizer = [[7.9991417]], SCI_loss_type = [[2.999428]], SCI_LR = [0.69379395]\n",
      "SCI_LR:  0.2312646508216858\n",
      "SCI_LR type:  <class 'float'>\n",
      "*** LOSS ******: 2\n",
      "*********  MMLoss\n",
      "LOSS FUNCTION IS:  MultiMarginLoss()\n",
      "Optimization:  Rprop (\n",
      "Parameter Group 0\n",
      "    etas: (0.5, 1.2)\n",
      "    lr: 0.2312646508216858\n",
      "    step_sizes: (1e-06, 50)\n",
      ")\n",
      "Batch Normalization Momentum:  0.1\n",
      "Nodes:  94\n",
      "LR:  0.2312646508216858\n",
      "RELU:  True\n",
      "BIAS:  True\n",
      "Loss Type:  2\n",
      "REGULARIZATION:  0.03\n",
      "BATCH_SIZE:  227\n",
      "Dropout:  0.20590832829475403\n",
      "Final Linear Layers:  2\n",
      "Class:  0  accuracy:  tensor(0.5752)\n",
      "Class:  0  correct:  287.0\n",
      "Class:  1  accuracy:  tensor(0.3700)\n",
      "Class:  1  correct:  37.0\n",
      "Final percentage:  tensor(0.4726)\n",
      "Last epoch:  21\n",
      "\n",
      "\n",
      "Credit Cost:  tensor([[527.3347]], grad_fn=<AddBackward0>)\n",
      "Best Score So Far:  tensor([[-423.3347]], grad_fn=<NegBackward>)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t = 1, loss = 277.334716796875, SCI_DROPOUT = [0.4118071], SCI_SGD_MOMENTUM = 0.4826766550540924, SCI_BATCH_SIZE = [[227.9981]], SCI_L_SECOND = [[94.99809]], SCI_optimizer = [[7.99828]], SCI_loss_type = [[2.9988534]], SCI_LR = [0.69379395]\n",
      "SCI_LR:  0.2312646508216858\n",
      "SCI_LR type:  <class 'float'>\n",
      "*** LOSS ******: 2\n",
      "*********  MMLoss\n",
      "LOSS FUNCTION IS:  MultiMarginLoss()\n",
      "Optimization:  Rprop (\n",
      "Parameter Group 0\n",
      "    etas: (0.5, 1.2)\n",
      "    lr: 0.2312646508216858\n",
      "    step_sizes: (1e-06, 50)\n",
      ")\n",
      "Batch Normalization Momentum:  0.1\n",
      "Nodes:  94\n",
      "LR:  0.2312646508216858\n",
      "RELU:  True\n",
      "BIAS:  True\n",
      "Loss Type:  2\n",
      "REGULARIZATION:  0.03\n",
      "BATCH_SIZE:  227\n",
      "Dropout:  0.2059035450220108\n",
      "Final Linear Layers:  2\n",
      "Class:  0  accuracy:  tensor(0.4569)\n",
      "Class:  0  correct:  228.0\n",
      "Class:  1  accuracy:  tensor(0.3700)\n",
      "Class:  1  correct:  37.0\n",
      "Final percentage:  tensor(0.4135)\n",
      "Last epoch:  21\n",
      "\n",
      "\n",
      "Credit Cost:  tensor([[586.3347]], grad_fn=<AddBackward0>)\n",
      "Best Score So Far:  tensor([[-423.3347]], grad_fn=<NegBackward>)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t = 2, loss = 336.33465576171875, SCI_DROPOUT = [0.4117975], SCI_SGD_MOMENTUM = 0.48258668184280396, SCI_BATCH_SIZE = [[227.99713]], SCI_L_SECOND = [[94.99713]], SCI_optimizer = [[7.997415]], SCI_loss_type = [[2.998277]], SCI_LR = [0.69379395]\n",
      "SCI_LR:  0.2312646508216858\n",
      "SCI_LR type:  <class 'float'>\n",
      "*** LOSS ******: 2\n",
      "*********  MMLoss\n",
      "LOSS FUNCTION IS:  MultiMarginLoss()\n",
      "Optimization:  Rprop (\n",
      "Parameter Group 0\n",
      "    etas: (0.5, 1.2)\n",
      "    lr: 0.2312646508216858\n",
      "    step_sizes: (1e-06, 50)\n",
      ")\n",
      "Batch Normalization Momentum:  0.1\n",
      "Nodes:  94\n",
      "LR:  0.2312646508216858\n",
      "RELU:  True\n",
      "BIAS:  True\n",
      "Loss Type:  2\n",
      "REGULARIZATION:  0.03\n",
      "BATCH_SIZE:  227\n",
      "Dropout:  0.20589874684810638\n",
      "Final Linear Layers:  2\n",
      "Class:  0  accuracy:  tensor(0.4449)\n",
      "Class:  0  correct:  222.0\n",
      "Class:  1  accuracy:  tensor(0.4700)\n",
      "Class:  1  correct:  47.0\n",
      "Final percentage:  tensor(0.4574)\n",
      "Last epoch:  21\n",
      "\n",
      "\n",
      "Credit Cost:  tensor([[542.3347]], grad_fn=<AddBackward0>)\n",
      "Best Score So Far:  tensor([[-423.3347]], grad_fn=<NegBackward>)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-bcde172170ff>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    219\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRANDOM_STARTS\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mTRIALS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m         \u001b[0moptim_alg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 221\u001b[0;31m         \u001b[0my_predicted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobjective\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSCI_SGD_MOMENTUM\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSCI_DROPOUT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSCI_BATCH_SIZE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSCI_L_SECOND\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSCI_optimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLINEARITY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSCI_loss_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSCI_LR\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m         \u001b[0mcurrent_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_predicted\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpected\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0mcurrent_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-bcde172170ff>\u001b[0m in \u001b[0;36mobjective\u001b[0;34m(SCI_SGD_MOMENTUM, SCI_DROPOUT, SCI_BATCH_SIZE, SCI_L_SECOND, SCI_optimizer, LINEARITY, SCI_loss_type, SCI_LR)\u001b[0m\n\u001b[1;32m    194\u001b[0m         \u001b[0mcount\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcount\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m         \u001b[0;31m# display the plot\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m         \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mCreditCost\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mshow\u001b[0;34m(*args, **kw)\u001b[0m\n\u001b[1;32m    261\u001b[0m     \"\"\"\n\u001b[1;32m    262\u001b[0m     \u001b[0;32mglobal\u001b[0m \u001b[0m_show\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 263\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_show\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/ipykernel/pylab/backend_inline.py\u001b[0m in \u001b[0;36mshow\u001b[0;34m(close, block)\u001b[0m\n\u001b[1;32m     37\u001b[0m             display(\n\u001b[1;32m     38\u001b[0m                 \u001b[0mfigure_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m                 \u001b[0mmetadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_fetch_figure_metadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigure_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m             )\n\u001b[1;32m     41\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/IPython/core/display.py\u001b[0m in \u001b[0;36mdisplay\u001b[0;34m(include, exclude, metadata, transient, display_id, *objs, **kwargs)\u001b[0m\n\u001b[1;32m    304\u001b[0m             \u001b[0mpublish_display_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    305\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 306\u001b[0;31m             \u001b[0mformat_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmd_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minclude\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minclude\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexclude\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexclude\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    307\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mformat_dict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    308\u001b[0m                 \u001b[0;31m# nothing to display (e.g. _ipython_display_ took over)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/IPython/core/formatters.py\u001b[0m in \u001b[0;36mformat\u001b[0;34m(self, obj, include, exclude)\u001b[0m\n\u001b[1;32m    178\u001b[0m             \u001b[0mmd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mformatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m             \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m                 \u001b[0;31m# FIXME: log the exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m</home/pauld/anaconda3/lib/python3.7/site-packages/decorator.py:decorator-gen-9>\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, obj)\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/IPython/core/formatters.py\u001b[0m in \u001b[0;36mcatch_format_error\u001b[0;34m(method, self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    222\u001b[0m     \u001b[0;34m\"\"\"show traceback on failed format call\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    225\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m         \u001b[0;31m# don't warn on NotImplementedErrors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/IPython/core/formatters.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    339\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    340\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 341\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mprinter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    342\u001b[0m             \u001b[0;31m# Finally look for special method names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    343\u001b[0m             \u001b[0mmethod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_real_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_method\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/IPython/core/pylabtools.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(fig)\u001b[0m\n\u001b[1;32m    242\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m'png'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mformats\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 244\u001b[0;31m         \u001b[0mpng_formatter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfor_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFigure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mprint_figure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'png'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    245\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m'retina'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mformats\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m'png2x'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mformats\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m         \u001b[0mpng_formatter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfor_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFigure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mretina_figure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/IPython/core/pylabtools.py\u001b[0m in \u001b[0;36mprint_figure\u001b[0;34m(fig, fmt, bbox_inches, **kwargs)\u001b[0m\n\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m     \u001b[0mbytes_io\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m     \u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_figure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbytes_io\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbytes_io\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfmt\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'svg'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/matplotlib/backend_bases.py\u001b[0m in \u001b[0;36mprint_figure\u001b[0;34m(self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, **kwargs)\u001b[0m\n\u001b[1;32m   2058\u001b[0m                     \u001b[0mbbox_artists\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"bbox_extra_artists\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2059\u001b[0m                     bbox_inches = self.figure.get_tightbbox(renderer,\n\u001b[0;32m-> 2060\u001b[0;31m                             bbox_extra_artists=bbox_artists)\n\u001b[0m\u001b[1;32m   2061\u001b[0m                     \u001b[0mpad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"pad_inches\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2062\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mpad\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/matplotlib/figure.py\u001b[0m in \u001b[0;36mget_tightbbox\u001b[0;34m(self, renderer, bbox_extra_artists)\u001b[0m\n\u001b[1;32m   2364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2365\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0martists\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2366\u001b[0;31m             \u001b[0mbbox\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_tightbbox\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2367\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbbox\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbbox\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwidth\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mbbox\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheight\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2368\u001b[0m                 \u001b[0mbb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbbox\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36mget_tightbbox\u001b[0;34m(self, renderer, call_axes_locator, bbox_extra_artists)\u001b[0m\n\u001b[1;32m   4346\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4347\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxison\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4348\u001b[0;31m             \u001b[0mbb_xaxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxaxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_tightbbox\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4349\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbb_xaxis\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4350\u001b[0m                 \u001b[0mbb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbb_xaxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/matplotlib/axis.py\u001b[0m in \u001b[0;36mget_tightbbox\u001b[0;34m(self, renderer)\u001b[0m\n\u001b[1;32m   1161\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1163\u001b[0;31m         \u001b[0mticks_to_draw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_ticks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1165\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_label_position\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/matplotlib/axis.py\u001b[0m in \u001b[0;36m_update_ticks\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1078\u001b[0m         \u001b[0mthe\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m.\u001b[0m  \u001b[0mReturn\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mlist\u001b[0m \u001b[0mof\u001b[0m \u001b[0mticks\u001b[0m \u001b[0mthat\u001b[0m \u001b[0mwill\u001b[0m \u001b[0mbe\u001b[0m \u001b[0mdrawn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1079\u001b[0m         \"\"\"\n\u001b[0;32m-> 1080\u001b[0;31m         \u001b[0mmajor_locs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_majorticklocs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1081\u001b[0m         \u001b[0mmajor_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmajor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformatter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat_ticks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmajor_locs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1082\u001b[0m         \u001b[0mmajor_ticks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_major_ticks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmajor_locs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/matplotlib/axis.py\u001b[0m in \u001b[0;36mget_majorticklocs\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1323\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_majorticklocs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1324\u001b[0m         \u001b[0;34m\"\"\"Get the array of major tick locations in data coordinates.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1325\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmajor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlocator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1326\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1327\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_minorticklocs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/matplotlib/ticker.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2076\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2077\u001b[0m         \u001b[0mvmin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvmax\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_view_interval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2078\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtick_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvmin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvmax\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2079\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2080\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtick_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvmin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvmax\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/matplotlib/ticker.py\u001b[0m in \u001b[0;36mtick_values\u001b[0;34m(self, vmin, vmax)\u001b[0m\n\u001b[1;32m   2084\u001b[0m         vmin, vmax = mtransforms.nonsingular(\n\u001b[1;32m   2085\u001b[0m             vmin, vmax, expander=1e-13, tiny=1e-14)\n\u001b[0;32m-> 2086\u001b[0;31m         \u001b[0mlocs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_raw_ticks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvmin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvmax\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2087\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2088\u001b[0m         \u001b[0mprune\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_prune\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/matplotlib/ticker.py\u001b[0m in \u001b[0;36m_raw_ticks\u001b[0;34m(self, vmin, vmax)\u001b[0m\n\u001b[1;32m   2023\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nbins\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'auto'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2024\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxis\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2025\u001b[0;31m                 nbins = np.clip(self.axis.get_tick_space(),\n\u001b[0m\u001b[1;32m   2026\u001b[0m                                 max(1, self._min_n_ticks - 1), 9)\n\u001b[1;32m   2027\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/matplotlib/axis.py\u001b[0m in \u001b[0;36mget_tick_space\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2173\u001b[0m         \u001b[0mends\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransAxes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2174\u001b[0m         \u001b[0mlength\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mends\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mends\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdpi\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m72\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2175\u001b[0;31m         \u001b[0mtick\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tick\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2176\u001b[0m         \u001b[0;31m# There is a heuristic here that the aspect ratio of tick text\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2177\u001b[0m         \u001b[0;31m# is no more than 3:1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/matplotlib/axis.py\u001b[0m in \u001b[0;36m_get_tick\u001b[0;34m(self, major)\u001b[0m\n\u001b[1;32m   1904\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1905\u001b[0m             \u001b[0mtick_kw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_minor_tick_kw\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1906\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mXTick\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmajor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmajor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mtick_kw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1907\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1908\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_label\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/matplotlib/axis.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, axes, loc, label, size, width, color, tickdir, pad, labelsize, labelcolor, zorder, gridOn, tick1On, tick2On, label1On, label2On, major, labelrotation, grid_color, grid_linestyle, grid_linewidth, grid_alpha, **kw)\u001b[0m\n\u001b[1;32m    162\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_text2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 164\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgridline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_visible\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgridOn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    165\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtick1line\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_visible\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtick1On\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtick2line\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_visible\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtick2On\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/matplotlib/artist.py\u001b[0m in \u001b[0;36mset_visible\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    886\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstale\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    887\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 888\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0mset_visible\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    889\u001b[0m         \"\"\"\n\u001b[1;32m    890\u001b[0m         \u001b[0mSet\u001b[0m \u001b[0mthe\u001b[0m \u001b[0martist\u001b[0m\u001b[0;31m'\u001b[0m\u001b[0ms\u001b[0m \u001b[0mvisibility\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if OPTIMIZATION_PLUGIN == 'GradDescent' :\n",
    "    import pandas as pd\n",
    "    import matplotlib.pyplot as plt\n",
    "    import torch\n",
    "    import torch.optim as optim\n",
    "    from torch.autograd import Variable\n",
    "    from Utillities import Utillities\n",
    "    from cnn_model import CNN6      \n",
    "\n",
    "    #SCI_LR = 0.2\n",
    "    SCI_REGULARIZATION = 0.03\n",
    "    SCI_EPOCHS = 200\n",
    "    SCI_RELU = 'True'\n",
    "    SCI_BIAS = 'True'\n",
    "    SCI_BN_MOMENTUM = 0.1\n",
    "    \n",
    "    \n",
    "    SCI_loss_type = torch.randint(3, 4, (1,1), dtype=torch.float, requires_grad=True) \n",
    "    print('SCI_loss_type: ',SCI_loss_type)    \n",
    "    SCI_SGD_MOMENTUM = torch.rand(1, requires_grad=True)\n",
    "    print('SCI_SGD_MOMENTUM: ', SCI_SGD_MOMENTUM)\n",
    "    SCI_BATCH_SIZE   = torch.randint(128, 256, (1,1), dtype=torch.float, requires_grad=True) \n",
    "    print('SCI_BATCH_SIZE: ',SCI_BATCH_SIZE)\n",
    "    SCI_L_SECOND   = torch.randint(80, 96, (1,1), dtype=torch.float, requires_grad=True) \n",
    "    print('SCI_L_SECOND: ',SCI_L_SECOND)\n",
    "    SCI_optimizer   = torch.randint(6, 11, (1,1), dtype=torch.float, requires_grad=True) \n",
    "    print('SCI_optimizer: ',SCI_optimizer)    \n",
    "    SCI_DROPOUT      = torch.rand(1, requires_grad=True)    \n",
    "    print('SCI_DROPOUT: ',SCI_DROPOUT)   \n",
    "    SCI_LR      = torch.rand(1, requires_grad=True)    \n",
    "    print('SCI_LR: ',SCI_LR) \n",
    "    \n",
    "\n",
    "    def objective(SCI_SGD_MOMENTUM, SCI_DROPOUT, SCI_BATCH_SIZE, SCI_L_SECOND, SCI_optimizer, LINEARITY, SCI_loss_type, SCI_LR):\n",
    "        global SCI_REGULARIZATION, SCI_EPOCHS, SCI_RELU\n",
    "        global SCI_BIAS, SCI_BN_MOMENTUM, device, MaxCredit, count, CreditVector, CreditVec\n",
    "        \n",
    "        SCI_SGD_MOMENTUM = SCI_SGD_MOMENTUM/10\n",
    "        DROPOUT = (SCI_DROPOUT/2).item()\n",
    "        if SCI_DROPOUT < 0 :\n",
    "            DROPOUT = 0\n",
    "            \n",
    "        if SCI_BATCH_SIZE < 2 :\n",
    "            SCI_BATCH_SIZE = 64            \n",
    "\n",
    "        BATCH_SIZE = int(SCI_BATCH_SIZE)\n",
    "        \n",
    "        if SCI_L_SECOND < 4 :\n",
    "            SCI_L_SECOND = 64\n",
    "            \n",
    "        \n",
    "        L_SECOND = int(SCI_L_SECOND)\n",
    "        \n",
    "        def create_loss(LOSS):   \n",
    "            print('*** LOSS ******:',  LOSS)\n",
    "            if LOSS == 1:\n",
    "                loss_func = nn.CrossEntropyLoss()\n",
    "                print('*********  CrossEntropyLoss')\n",
    "            if LOSS == 2:\n",
    "                loss_func = nn.MultiMarginLoss()\n",
    "                print('*********  MMLoss')                               \n",
    "            if LOSS == 3:\n",
    "                loss_func = nn.NLLLoss() \n",
    "                print('*********  NLLLoss')                 \n",
    "            return loss_func\n",
    "\n",
    "        SCI_LR = SCI_LR.item() / 3\n",
    "        print('SCI_LR: ', SCI_LR)\n",
    "        print('SCI_LR type: ', type(SCI_LR))\n",
    "\n",
    "\n",
    "        \n",
    "        loss_type = int(SCI_loss_type)\n",
    "        loss_func = create_loss(loss_type)\n",
    "        print('LOSS FUNCTION IS: ',loss_func)\n",
    "\n",
    "        REGULARIZATION = float(str(SCI_REGULARIZATION))\n",
    "\n",
    "        cnn = CNN6(L_FIRST, L_SECOND, KERNEL_X, SCI_BIAS, SCI_BN_MOMENTUM, SCI_RELU, DROPOUT, dataset.CLASSES, LINEARITY)     \n",
    "\n",
    "        optimizer1 = Utillities.optimization_algorithms(SCI_optimizer.detach().numpy(),cnn, SCI_LR, SCI_SGD_MOMENTUM, SCI_REGULARIZATION)\n",
    "        \n",
    "        if GPU_SELECT == 2:\n",
    "            if torch.cuda.device_count() > 1:\n",
    "                cnn = nn.DataParallel(cnn,device_ids=[0, 1], dim=0) \n",
    "            cnn = cnn.cuda()\n",
    "        if GPU_SELECT == 1:\n",
    "            cnn.to(device)  \n",
    "        if GPU_SELECT == 0:\n",
    "            cnn.to(device)        \n",
    "\n",
    "        cnn.apply(CNN6.weights_reset)\n",
    "        cnn.share_memory()\n",
    "\n",
    "\n",
    "        train_losses = []         # to track the training loss as the model trains\n",
    "        output = 0\n",
    "        loss = 0\n",
    "        accuracy = 0\n",
    "        early_stopping.counter = 0\n",
    "        early_stopping.best_score = None\n",
    "        early_stopping.early_stop = False\n",
    "        early_stopping.verbose = False  \n",
    "        TEST_RESULTS = torch.zeros(1,2)\n",
    "\n",
    "    \n",
    "        Utillities.listing(optimizer1, SCI_SGD_MOMENTUM, SCI_BN_MOMENTUM, L_SECOND, SCI_LR, SCI_RELU, SCI_BIAS, loss_type, REGULARIZATION, BATCH_SIZE, DROPOUT, LINEARITY)\n",
    "\n",
    "        train_loader = Data.DataLoader(dataset = dataset.train_dataset, batch_size = BATCH_SIZE, shuffle = False, num_workers = 0, drop_last=True, pin_memory=True)\n",
    "        validation_loader = Data.DataLoader(dataset = dataset.validation_dataset, batch_size = 144, shuffle = False, num_workers = 0, drop_last=True, pin_memory=True)    \n",
    "        test_loader = Data.DataLoader(dataset = dataset.test_dataset, batch_size = 599, shuffle = False, num_workers = 0, pin_memory=True, drop_last=True)\n",
    "    \n",
    "        for epoch in range(SCI_EPOCHS):\n",
    "            loss = None        \n",
    "            cnn.train().cuda()\n",
    "            for step, (train_data, train_target) in enumerate(train_loader):   \n",
    "                train_data, train_target = train_data.to(device), train_target.to(device)\n",
    "                output, temp = cnn(train_data)                   \n",
    "                loss = loss_func(output, train_target)\n",
    "                train_losses.append(loss.item())            \n",
    "                loss.backward()                             \n",
    "                optimizer1.zero_grad()\n",
    "                optimizer1.step()                           \n",
    "      \n",
    "            cnn.eval().cuda()                   \n",
    "            valid_loss = 0\n",
    "            accuracy = 0\n",
    "            with torch.no_grad():\n",
    "                for step, (validation_data, validation_target) in enumerate(validation_loader):\n",
    "                    validation_data, validation_target = validation_data.to(device), validation_target.to(device)\n",
    "                    output, temp = cnn(validation_data)            # forward pass: compute predicted outputs by passing inputs to the model\n",
    "                    valid_loss += loss_func(output, validation_target).item()  \n",
    "               \n",
    "            train_losses = []\n",
    "            early_stopping(valid_loss, cnn)\n",
    "       \n",
    "            if early_stopping.early_stop:\n",
    "                if os.path.exists('checkpoint.pt'):\n",
    "                    print(\"Loaded the model with the lowest Validation Loss!\")\n",
    "                    cnn.load_state_dict(torch.load('checkpoint.pt', map_location=\"cuda:1\"))  # Choose whatever GPU device number you want\n",
    "                    cnn.to(device)\n",
    "                break\n",
    "      \n",
    "        cnn.eval()\n",
    "        class_correct = list(0. for i in range(1000))\n",
    "        class_total = list(0. for i in range(1000))\n",
    "        with torch.no_grad():\n",
    "            for (test_data, test_target) in test_loader:\n",
    "                test_data, test_target = test_data.to(device), test_target.to(device)\n",
    "                outputs, temp = cnn(test_data)\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                c = (predicted == test_target).squeeze()\n",
    "                for i in range(test_target.size(0)):\n",
    "                    label = test_target[i]\n",
    "                    class_correct[label] += c[i].item()\n",
    "                    class_total[label] += 1\n",
    "\n",
    "        for i in range(dataset.CLASSES):\n",
    "            TEST_RESULTS[0,i] = class_correct[i] / dataset.TESTED_ELEMENTS[i]\n",
    "            print('Class: ',i,' accuracy: ', TEST_RESULTS[0,i])\n",
    "            print('Class: ',i,' correct: ', class_correct[i])\n",
    "        percent = (TEST_RESULTS[0,0]+TEST_RESULTS[0,1])/2\n",
    "        print('Final percentage: ',percent)\n",
    "    \n",
    "        CreditCost = (1 - TEST_RESULTS[0,0]) * dataset.TESTED_ELEMENTS[0] + (1 - TEST_RESULTS[0,1]) * dataset.TESTED_ELEMENTS[1] * 5\n",
    "    \n",
    "        if TEST_RESULTS[0,0] == 0 or TEST_RESULTS[0,1] == 0 :\n",
    "            CreditCost = CreditCost + 300\n",
    "    \n",
    "        print('Last epoch: ', epoch)\n",
    "   \n",
    "        if os.path.exists('checkpoint.pt'):  \n",
    "            os.remove('checkpoint.pt') \n",
    "\n",
    "        print()\n",
    "        torch.cuda.empty_cache()\n",
    "        print()\n",
    "        \n",
    "        CreditCost = CreditCost + (SCI_SGD_MOMENTUM + SCI_DROPOUT + SCI_BATCH_SIZE + SCI_L_SECOND + SCI_optimizer + SCI_loss_type+ SCI_LR)/1000\n",
    "        print('Credit Cost: ',CreditCost)\n",
    "        \n",
    "        \n",
    "        if -CreditCost > MaxCredit : \n",
    "            MaxCredit = -CreditCost\n",
    "        print('Best Score So Far: ',MaxCredit)   \n",
    "        \n",
    "        CreditVector[count] = MaxCredit    \n",
    "        CreditVec[count] = count\n",
    "        # plot the data\n",
    "        fig = plt.figure()\n",
    "        ax = fig.add_subplot(1, 1, 1)\n",
    "        ax.plot(CreditVec, -CreditVector, color='tab:orange')\n",
    "        #print(CreditVec, -CreditVector)\n",
    "        count = count + 1\n",
    "        # display the plot\n",
    "        plt.show()\n",
    "             \n",
    "        return CreditCost\n",
    "\n",
    "    \n",
    "    def loss(y_predicted, expected):\n",
    "        return (y_predicted - expected).sum()\n",
    "            \n",
    "    \n",
    "    expected = 250\n",
    "    \n",
    "    optim_alg = optim.Adadelta([       \n",
    "        {'params': SCI_SGD_MOMENTUM, 'lr': 0.9},\n",
    "        {'params': SCI_DROPOUT, 'lr': 1e-2},\n",
    "        {'params': SCI_BATCH_SIZE, 'lr': 1},\n",
    "        {'params': SCI_L_SECOND, 'lr': 1},\n",
    "        {'params': SCI_optimizer, 'lr': 0.9},\n",
    "        {'params': SCI_loss_type, 'lr': 0.6}, \n",
    "        {'params': SCI_LR, 'lr': 0.1}   \n",
    "        ]) \n",
    "    \n",
    "    LINEARITY = 2\n",
    "    # Main optimization loop\n",
    "    for t in range(RANDOM_STARTS + TRIALS):\n",
    "        optim_alg.zero_grad()\n",
    "        y_predicted = objective(SCI_SGD_MOMENTUM, SCI_DROPOUT, SCI_BATCH_SIZE, SCI_L_SECOND, SCI_optimizer, LINEARITY, SCI_loss_type, SCI_LR)\n",
    "        current_loss = loss(y_predicted, expected)\n",
    "        current_loss.backward()\n",
    "        optim_alg.step()\n",
    "        print(f\"t = {t}, loss = {current_loss}, SCI_DROPOUT = {SCI_DROPOUT.detach().numpy()}, SCI_SGD_MOMENTUM = {SCI_SGD_MOMENTUM.item()}, SCI_BATCH_SIZE = {SCI_BATCH_SIZE.detach().numpy()}, SCI_L_SECOND = {SCI_L_SECOND.detach().numpy()}, SCI_optimizer = {SCI_optimizer.detach().numpy()}, SCI_loss_type = {SCI_loss_type.detach().numpy()}, SCI_LR = {SCI_LR.detach().numpy()}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "end.record()\n",
    "\n",
    "#print('Minimum Credit Cost: ',Min_Credit_Cost)\n",
    "\n",
    "print()\n",
    "print('Total execution time (minutes): ',start.elapsed_time(end)/60000)\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "if GET_STATS:\n",
    "    pr.disable()\n",
    "    s = io.StringIO()\n",
    "    sortby = SortKey.CUMULATIVE\n",
    "    ps = pstats.Stats(pr, stream=s).sort_stats(sortby)\n",
    "    ps.print_stats()\n",
    "    print(s.getvalue())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
